<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Statistics on metafunctor</title>
    <link>http://192.168.0.225:38061/categories/statistics/</link>
    <description>Recent content in Statistics on metafunctor</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 25 Mar 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://192.168.0.225:38061/categories/statistics/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Fine-Tuning Tiny LLMs for ElasticSearch DSL</title>
      <link>http://192.168.0.225:38061/posts/llm-fine-tuning-es-dsl/</link>
      <pubDate>Mon, 19 Feb 2024 00:00:00 +0000</pubDate>
      <guid>http://192.168.0.225:38061/posts/llm-fine-tuning-es-dsl/</guid>
      <description>I am creating a tiny LLM for ElasticSearch DSL as a proof of concept.</description>
    </item>
    <item>
      <title>Instrumental Goals and Latent Codes In LLMs Fine-Tuned with RL</title>
      <link>http://192.168.0.225:38061/research/llm-research/</link>
      <pubDate>Mon, 25 Mar 2024 00:00:00 +0000</pubDate>
      <guid>http://192.168.0.225:38061/research/llm-research/</guid>
      <description>This paper explores the emergence of instrumental goals and latent codes in large language models (LLMs) fine-tuned with reinforcement learning (RL). The transition from self-supervised learning to RL introduces incentives for LLMs to develop covert strategies and hidden agendas. We examine the underlying mathematical frameworks and demonstrate that LLMs can encode instrumental goals in subtle ways, making them challenging to detect and interpret. Our findings highlight the importance of advanced interpretability techniques to ensure ethical alignment and mitigate risks associated with hidden instrumental goals in RL-fine-tuned LLMs. We conclude with a call for rigorous oversight and ethical foresight in AI development to address these challenges.</description>
    </item>
    <item>
      <title>Approximations of Solomonoff Induction</title>
      <link>http://192.168.0.225:38061/research/solomonoff/</link>
      <pubDate>Mon, 19 Feb 2024 00:00:00 +0000</pubDate>
      <guid>http://192.168.0.225:38061/research/solomonoff/</guid>
      <description>I experiment with simple predictive / generative models to approximate Solomonoff induction for a relatiely simple synthetic data-generating process.</description>
    </item>
    <item>
      <title>Various LLM Research Projects</title>
      <link>http://192.168.0.225:38061/research/llm-search/</link>
      <pubDate>Mon, 19 Feb 2024 00:00:00 +0000</pubDate>
      <guid>http://192.168.0.225:38061/research/llm-search/</guid>
      <description>Various research projects for LLMs and foundation models.</description>
    </item>
    <item>
      <title>Model Selection in Weibull Series Systems</title>
      <link>http://192.168.0.225:38061/research/reliability-estimation-in-series-systems-model-sel/</link>
      <pubDate>Wed, 29 Mar 2023 00:00:00 +0000</pubDate>
      <guid>http://192.168.0.225:38061/research/reliability-estimation-in-series-systems-model-sel/</guid>
      <description>In my paper, Reliability Estimation in Series Systems, I discarded a lot of research that may be interesting to pursue further. This one is about using homogeneous shape parameters for the Weibull series system, which can greatly simplify the analysis and reduce the number of parameters to estimate. It&amp;rsquo;s also quite reasonable for most well-designed systems.</description>
    </item>
    <item>
      <title>Computational Statistics - SIUe - STAT 575 - Problem Set 2</title>
      <link>http://192.168.0.225:38061/probsets/stat575/stat575-problem-set-2/</link>
      <pubDate>Sat, 30 Oct 2021 00:00:00 +0000</pubDate>
      <guid>http://192.168.0.225:38061/probsets/stat575/stat575-problem-set-2/</guid>
      <description>This problem set covers the E-M algorithm for right-censored normal data with known variance.</description>
    </item>
    <item>
      <title>Review: A Symbolic Representation of Time Series, with Implications for Streaming Algorithms</title>
      <link>http://192.168.0.225:38061/posts/2012-02-04-sax/cs584_sax_review/</link>
      <pubDate>Sat, 30 Oct 2021 00:00:00 +0000</pubDate>
      <guid>http://192.168.0.225:38061/posts/2012-02-04-sax/cs584_sax_review/</guid>
      <description>&lt;p&gt;In [1], the authors present a method for constructing a symbolic (nominal) representation for real-valued time series data. A symbolic representation is desirable because then it becomes possible to use many of the effective algorithms that require symbolic representation, like hashing and Markov models.&lt;/p&gt;&#xA;&lt;p&gt;The authors claim that one of the most useful time series operations is measuring the similarity between two time series data sets. To do this on the original time series, the Euclidean distance formula can be used. Therefore, for a time series transformation to be useful, distance measures applied to the corresponding transformations should provide some guaranteed lower bound on the &lt;code&gt;true&lt;/code&gt; distance. This is a basic requirement for almost all time series algorithms in data mining. Non-symbolic transformations like Discrete Fourier Transform (DFT) and Piecewise Aggregate Approximation (PAA) models have this lower-bounding property. However, the authors claim no previously proposed symbolic representations do, which limits their usefulness.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
