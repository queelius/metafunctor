<!DOCTYPE html>
<html lang="en-us" dir="ltr">
  <head>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <script src="https://unpkg.com/lunr/lunr.js"></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>ngram-projections | metafunctor</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="Stars: 0 | Forks: 0 | Open Issues: 0
Languages: Python, Jupyter Notebook
Contributors

queelius (5 commits)

README
Autoregressive Models: Inductive Biases and Projections
This paper investigates how inductive biases, particularly projections onto training data, can be utilized in autoregressive (AR) models to improve out-of-distribution (OOD) generalization.
Our approach consists of the following steps:


Infini-gram Model Exploration: We begin by considering the infinite-gram model, which uses suffix arrays to efficiently handle arbitrary input (context) lengths. Infinite-gram models are noteworthy due to their ability to scale to any Markov order. For reference, see the paper Infini-gram: An Engine for n-gram / ∞-gram Language Modeling with Trillion-Token Corpora by Jiacheng Liu et al. (https://huggingface.co/papers/2401.17377). A brute-force approach could involve storing the training data as-is and searching for the longest matching suffix in the input sequence.">
    <meta name="generator" content="Hugo 0.145.0">
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    
      <meta name="author" content = "Alex Towell">
    

    
<link rel="stylesheet" href="/metafunctor/ananke/css/main.min.d05fb5f317fcf33b3a52936399bdf6f47dc776516e1692e412ec7d76f4a5faa2.css" >




    


    
      <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)'], ['$', '$']]      
    }
  };
</script>
        
    
    
      

    

    

    
      <link rel="canonical" href="https://queelius.github.io/metafunctor/projects/ngram-projections/">
    

    <meta property="og:url" content="https://queelius.github.io/metafunctor/projects/ngram-projections/">
  <meta property="og:site_name" content="metafunctor">
  <meta property="og:title" content="ngram-projections">
  <meta property="og:description" content="Stars: 0 | Forks: 0 | Open Issues: 0
Languages: Python, Jupyter Notebook
Contributors queelius (5 commits) README Autoregressive Models: Inductive Biases and Projections This paper investigates how inductive biases, particularly projections onto training data, can be utilized in autoregressive (AR) models to improve out-of-distribution (OOD) generalization.
Our approach consists of the following steps:
Infini-gram Model Exploration: We begin by considering the infinite-gram model, which uses suffix arrays to efficiently handle arbitrary input (context) lengths. Infinite-gram models are noteworthy due to their ability to scale to any Markov order. For reference, see the paper Infini-gram: An Engine for n-gram / ∞-gram Language Modeling with Trillion-Token Corpora by Jiacheng Liu et al. (https://huggingface.co/papers/2401.17377). A brute-force approach could involve storing the training data as-is and searching for the longest matching suffix in the input sequence.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="projects">
    <meta property="article:published_time" content="2024-06-21T11:50:22+00:00">
    <meta property="article:modified_time" content="2024-06-21T11:50:22+00:00">
    <meta property="article:tag" content="GitHub">
    <meta property="article:tag" content="Project">

  <meta itemprop="name" content="ngram-projections">
  <meta itemprop="description" content="Stars: 0 | Forks: 0 | Open Issues: 0
Languages: Python, Jupyter Notebook
Contributors queelius (5 commits) README Autoregressive Models: Inductive Biases and Projections This paper investigates how inductive biases, particularly projections onto training data, can be utilized in autoregressive (AR) models to improve out-of-distribution (OOD) generalization.
Our approach consists of the following steps:
Infini-gram Model Exploration: We begin by considering the infinite-gram model, which uses suffix arrays to efficiently handle arbitrary input (context) lengths. Infinite-gram models are noteworthy due to their ability to scale to any Markov order. For reference, see the paper Infini-gram: An Engine for n-gram / ∞-gram Language Modeling with Trillion-Token Corpora by Jiacheng Liu et al. (https://huggingface.co/papers/2401.17377). A brute-force approach could involve storing the training data as-is and searching for the longest matching suffix in the input sequence.">
  <meta itemprop="datePublished" content="2024-06-21T11:50:22+00:00">
  <meta itemprop="dateModified" content="2024-06-21T11:50:22+00:00">
  <meta itemprop="wordCount" content="366">
  <meta itemprop="keywords" content="GitHub,Project">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="ngram-projections">
  <meta name="twitter:description" content="Stars: 0 | Forks: 0 | Open Issues: 0
Languages: Python, Jupyter Notebook
Contributors queelius (5 commits) README Autoregressive Models: Inductive Biases and Projections This paper investigates how inductive biases, particularly projections onto training data, can be utilized in autoregressive (AR) models to improve out-of-distribution (OOD) generalization.
Our approach consists of the following steps:
Infini-gram Model Exploration: We begin by considering the infinite-gram model, which uses suffix arrays to efficiently handle arbitrary input (context) lengths. Infinite-gram models are noteworthy due to their ability to scale to any Markov order. For reference, see the paper Infini-gram: An Engine for n-gram / ∞-gram Language Modeling with Trillion-Token Corpora by Jiacheng Liu et al. (https://huggingface.co/papers/2401.17377). A brute-force approach could involve storing the training data as-is and searching for the longest matching suffix in the input sequence.">

	
  </head>

  <body class="ma0 avenir bg-near-white">

    

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l center items-center justify-between">
    <a href="/metafunctor/" class="f3 fw2 hover-white white-90 dib no-underline">
      
        metafunctor
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/metafunctor/social/" title="Social page">
              Social
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/metafunctor/about/" title="About Me page">
              About Me
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/metafunctor/ghprojects/" title="GitHub Projects page">
              GitHub Projects
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/metafunctor/post/" title="News page">
              News
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/metafunctor/probsets/" title="Problem Sets page">
              Problem Sets
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/metafunctor/projects/" title="Projects page">
              Projects
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/metafunctor/publications/" title="Publications page">
              Publications
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/metafunctor/research/" title="Research page">
              Research
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white white-90 no-underline" href="/metafunctor/search/" title="Search page">
              Search
            </a>
          </li>
          
        </ul>
      
      <div class="ananke-socials"></div>

    </div>
  </div>
</nav>

    </div>
  </header>


    <main class="pb7" role="main">
      
<section class="project-section" style="padding: 2rem; background-color: #f9f9f9;">
  <div class="container" style="max-width: 1200px; margin: 0 auto;">
    
    <div style="display: grid; grid-template-columns: 2fr 1fr; gap: 2rem;">
      
      
      <div>
        
        <header style="margin-bottom: 2rem;">
          <h1 style="font-size: 2.5rem; font-weight: 700; color: #333;">ngram-projections</h1>
          <p style="color: #555; font-size: 1.1rem; margin-bottom: 0.5rem;">
             | June 21, 2024 | <a href="mailto:" style="color: #007acc;"></a>
          </p>

          
          <div style="overflow: hidden;">
            
            <p style="font-size: 1.25rem; color: #666;"></p>
          </div>
        </header>

        
        
        <section style="margin-bottom: 1rem;">
          <div style="display: flex; gap: 1rem; flex-wrap: wrap;">
            
            <a href="https://github.com/queelius/ngram-projections" target="_blank" style="padding: 0.75rem 1.5rem; background-color: #007acc; color: white; border-radius: 5px; text-decoration: none; transition: background-color 0.3s ease; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
              GitHub
            </a>
            
            
            <a href="https://twitter.com/intent/tweet?text=ngram-projections&url=https%3a%2f%2fqueelius.github.io%2fmetafunctor%2fprojects%2fngram-projections%2f" target="_blank" style="padding: 0.75rem .75rem; background-color: #1DA1F2; color: white; border-radius: 5px; text-decoration: none; transition: background-color 0.3s ease;">
              <i class="fab fa-twitter"></i>
            </a>

            
            <a href="https://www.linkedin.com/sharing/share-offsite/?url=https%3a%2f%2fqueelius.github.io%2fmetafunctor%2fprojects%2fngram-projections%2f" target="_blank" style="padding: 0.75rem .75rem; background-color: #0077B5; color: white; border-radius: 5px; text-decoration: none; transition: background-color 0.3s ease;">
              <i class="fab fa-linkedin"></i>
            </a>

            
            <a href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fqueelius.github.io%2fmetafunctor%2fprojects%2fngram-projections%2f" target="_blank" style="padding: 0.75rem .75rem; background-color: #1877F2; color: white; border-radius: 5px; text-decoration: none; transition: background-color 0.3s ease;">
              <i class="fab fa-facebook"></i>
            </a>
          </div>
        </section>
        

        
        <section style="margin-bottom: 3rem;">
          <h2 style="font-size: 1.75rem; font-weight: 600; color: #007acc;">Project Description</h2>
          <p style="font-size: 1.1rem; color: #555; line-height: 1.8;">
            <p><strong>Stars</strong>: 0 | <strong>Forks</strong>: 0 | <strong>Open Issues</strong>: 0</p>
<p><strong>Languages</strong>: Python, Jupyter Notebook</p>
<h2 id="contributors">Contributors</h2>
<ul>
<li>queelius (5 commits)</li>
</ul>
<h2 id="readme">README</h2>
<h1 id="autoregressive-models-inductive-biases-and-projections">Autoregressive Models: Inductive Biases and Projections</h1>
<p>This paper investigates how inductive biases, particularly projections onto training data, can be utilized in autoregressive (AR) models to improve out-of-distribution (OOD) generalization.</p>
<p>Our approach consists of the following steps:</p>
<ol>
<li>
<p><strong>Infini-gram Model Exploration</strong>: We begin by considering the infinite-gram model, which uses suffix arrays to efficiently handle arbitrary input (context) lengths. Infinite-gram models are noteworthy due to their ability to scale to any Markov order. For reference, see the paper <em>Infini-gram: An Engine for n-gram / ∞-gram Language Modeling with Trillion-Token Corpora</em> by Jiacheng Liu et al. (<a href="https://huggingface.co/papers/2401.17377)">https://huggingface.co/papers/2401.17377)</a>. A brute-force approach could involve storing the training data as-is and searching for the longest matching suffix in the input sequence.</p>
</li>
<li>
<p><strong>Projection-Based Inductive Biases</strong>: We explore a subset of inductive biases where inputs are projected onto the training data. Additionally, we consider mapping output tokens from the training data back onto the context to maintain coherence. For example, if the input is &ldquo;the king demanded&rdquo; and &ldquo;king&rdquo; is substituted with &ldquo;dictator,&rdquo; we could implement a token mapping to revert &ldquo;dictator&rdquo; to &ldquo;king&rdquo; in subsequent outputs. However, this approach introduces potential challenges in maintaining consistency.</p>
</li>
<li>
<p><strong>Exploring Variations and Extensions</strong>: In the default implementation, the model finds the longest matching suffix, exhibiting a recency bias. However, there are many possible variations to consider. Given the rich history of n-gram models, revisiting these concepts in the context of Infini-gram models and modern LLMs is worthwhile. While we do not expect to match the OOD generalization capabilities of models like GPT, we anticipate developing more sophisticated projection functions that surpass the simple longest-suffix matching approach.</p>
</li>
</ol>
<p>By framing OOD generalization as a projection problem, we propose strategies to optimize these projections using machine learning techniques. Additionally, we explore the integration of classical information retrieval methods and pre-trained language model embeddings to improve the semantic relevance of these projections.</p>
<p>We are also developing code for a Python library to experiment with various inductive biases. This library will enable running these simpler models alongside more powerful neural generative models like GPTs, where these models &ldquo;learn&rdquo; by simply accumulating more training data.</p>

          </p>
        </section>
      </div>

    
    


      
      <aside>
        
        
        
        <section style="margin-bottom: 1rem;">
          <h2 style="font-size: 1.5rem;">Related</h2>
          <div style="display: flex; flex-direction: column; gap: 1rem;">
            
            <a href="https://queelius.github.io/metafunctor/ghprojects/ngram-projections/">ngram-projections</a>
            
            <a href="https://queelius.github.io/metafunctor/projects/treeprog/">treeprog</a>
            
            <a href="https://queelius.github.io/metafunctor/ghprojects/treeprog/">treeprog</a>
            
            <a href="https://queelius.github.io/metafunctor/ghprojects/random_oracles/">random_oracles</a>
            
            <a href="https://queelius.github.io/metafunctor/projects/random_oracles/">random_oracles</a>
            
          </div>
        </section>
        

        
        
        <section style="margin-bottom: 1rem;">
          <h2 style="font-size: 1.5rem">Tags</h2>
          <div style="display: flex; gap: 0.5rem; flex-wrap: wrap;">
            
            <a href="/tags/github" style="display: inline-block; padding: 0.5rem 1rem; background-color: #f0f0f0; border-radius: 20px; font-size: 1rem; text-decoration: none; color: #007acc; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);">
              GitHub
            </a>
            
            <a href="/tags/project" style="display: inline-block; padding: 0.5rem 1rem; background-color: #f0f0f0; border-radius: 20px; font-size: 1rem; text-decoration: none; color: #007acc; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);">
              project
            </a>
            
          </div>
        </section>
        
      </aside>

    </div>
  </div>

</section>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white white-70 dn dib-ns pv2 ph3 no-underline" href="https://queelius.github.io/metafunctor/" >
    &copy;  metafunctor 2025 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

  </body>
</html>
