[{
        "title": "advancing-mathematical-reasoning-in-ai-introducing-reverse-process-synthetic-data-generation",
        "link": "http://localhost:1313/posts/rpsdg/",
        "date": "2024-06-25 00:00:00 +0000 UTC",
        "content": "Check out the (early) project and source code on GitHub.\nAbstract: This paper introduces a methodology for generating high-quality, diverse training data for Language Models (LMs) in complex problem-solving domains. Our approach, termed \u0026ldquo;Reverse-Process Synthetic Data Generation\u0026rdquo; (RPSDG), inverts traditionally difficult problems to create an abundance of training examples with known solutions, e.g., symbolically taking the deriative of a function, $f \\mapsto f\u0026rsquo;$, versus solving antiderivatives of $f\u0026rsquo;$. By automating the generation of problems of graduating difficulty, we create datasets that enable process-supervised training of LLMs. We demonstrate the efficacy of this method for training mathematical reasoning. Our results show significant improvements in LLMs\u0026rsquo; problem-solving capabilities, particularly in areas requiring multi-step reasoning and creative insights. This methodology not only enhances model performance but also provides a framework for generating explainable AI solutions, as the step-by-step problem-solving process is inherent in the training data.\nTable of Contents: Introduction\nThe challenge of training data for complex problem-solving Overview of Reverse-Process Synthetic Data Generation (RPSDG) Potential impact on AI capabilities and explainability Methodology\nCore principles Automating generation of process supervision training data Curriculum learning and problem difficulty progression Mathematics\nAlgebra: Equation solving and manipulation Calculus: From differentiation to integration Implementation and Results\nData generation pipelines Transformer-based LMs Self-Supervised Learning Evals and benchmarks Discussion\nImplications for AI problem-solving capabilities Enhancing explainability and transparency Limitations and challenges of the RPSDG approach using SSL Future Work\nExpanding to new domains and problem types Reinforcement learning to reward multi-step reasoning even without a known (but verifiable) solution Conclusion\nSummary of key findings Broader impact on AI research and applications Introduction In \u0026ldquo;The Bitter Lesson,\u0026rdquo; Richard Sutton argues that learning algorithms that scale with compute and data will eventually outperform handcrafted algorithms.\nThe next frontier in AI research is finding ways to acquire high-quality data that can be used to train models to predict the latent structure and processes in the world. A significant portion of the world\u0026rsquo;s data is latent, where the processes that generate the data are not observable (e.g., not written down). For example, in mathematics, the way in which a proof was discovered is often not demonstrated and instead only a polished proof is presented, hiding the creative process and the \u0026ldquo;dark matter\u0026rdquo; that led to the proof. Understanding and modeling the latent structure in our processes can lead to significant improvements in AI capabilities.\nIn this paper, we are interested in exploring algorithmic data generation, where we apply classical algorithms (GOFAI) to automatically generate high-quality step-by-step (process supervision) training data for LMs. In particular, we are interested in exploring problems which have the feature of being easy to solve in one direction, but hard to solve in the other direction, such as\nTaking Derivatives vs. Integrating Functions In mathematics, computing derivatives of functions is generally easier than finding their antiderivatives (integrals). This inherent asymmetry allows us to use the more straightforward differentiation process to generate a rich dataset for training language models (LLMs) by reversing the problem-solving direction: starting with derivatives and deriving the original functions.\nGenerating Integral Calculus Training Data By Solving Derivatives and Reversing the Process Starting with Known Functions:\nSelect functions \\( f(x) \\) that have closed-form solutions and well-defined derivatives. Examples include polynomials, trigonometric functions, exponential functions, and logarithmic functions. To ensure the training data covers a wide range of functions and their transformations, we create a variety of functions with different complexities and forms. Formulating the Reverse Process:\nTake the derivative of \\( f(x) \\) to generate \\( f'(x) \\). Reversing the Process:\nGenerate the RPSDG by reversing the problem and solution steps, starting with \\( f'(x) \\)$ to show how to arrive at a corresponding integral \\( f(x) \\). Ensure that each step in this process is well-documented, capturing the intermediate transformations. This approach allows us to generate integration problems of graduating difficulty, leveraging the inherent asymmetry between differentiation and integration. By automating this process, we create a diverse dataset for training LLMs to predict solutions in integral calculus.\nGenerating a Theorem Proof vs. Verifying a Proof One of the key challenges in mathematics and logic is generating proofs for given theorems. While verifying a proof is generally straightforward, generating the proof itself can be significantly more complex. Our methodology leverages this asymmetry by focusing on the reverse process: starting with randomly generated expressions and using rewrite rules to create both theorems and their proofs.\nGenerating Theorem Proofs Random Walks in Expression Space:\nBegin with a randomly generated expression \\( e_{\\text{start}} \\). Apply a series of rewrite rules \\( r_1, r_2, \\ldots, r_n \\) to generate a sequence of intermediate expressions \\( e_1, e_2, \\ldots, e_n \\), ultimately arriving at a final expression \\( e_{\\text{end}} \\). Each step \\( e_i \\rightarrow e_{i+1} \\) represents a proof step within a logical or mathematical framework. Forming Theorems and Proofs:\nThe pair \\( (e_{\\text{start}}, e_{\\text{end}}) \\) represents a theorem, where \\( e_{\\text{start}} \\) is the hypothesis and \\( e_{\\text{end}} \\) is the conclusion. The sequence of intermediate steps provides the proof for this theorem. This method effectively generates theorems and their corresponding proofs by random exploration of the expression space. Reversibility and Bidirectional Processes:\nThe reverse process can also be applied, starting with \\( e_{\\text{end}} \\) and working backward to \\( e_{\\text{start}} \\). Intermediate steps that involve complex operations (e.g., integration) can often be reversed into simpler operations (e.g., differentiation). This bidirectional approach ensures a rich dataset with varied difficulty levels for training models. Automated Proof Generation:\nBy applying rewrite rules to random starting points and ending at random points, we automatically generate both theorems and proofs. This method circumvents the traditional difficulty of finding a theorem to prove and then discovering its proof. The randomness ensures a diverse set of theorems and proofs, capturing a wide range of logical and mathematical concepts. This methodology allows us to systematically generate a large volume of training data for LLMs. By focusing on problems that are easy in one direction but complex in the other, we create a diverse dataset that captures a wide range of logical and mathematical challenges. This not only enhances the problem-solving capabilities of LLMs but also provides a framework for generating explainable AI solutions, as the step-by-step problem-solving process is inherent in the training data.\n",
        "summary": "\u003cp\u003eCheck out the (early) project and source code on \u003ca href=\"https://github.com/queelius/RPSDG\"\u003eGitHub\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"abstract\"\u003eAbstract:\u003c/h2\u003e\n\u003cp\u003eThis paper introduces a methodology for generating high-quality, diverse training data for Language Models (LMs) in complex problem-solving domains. Our approach, termed \u0026ldquo;Reverse-Process Synthetic Data Generation\u0026rdquo; (RPSDG), inverts traditionally difficult problems to create an abundance of training examples with known solutions,\ne.g., symbolically taking the deriative of a function, $f \\mapsto f\u0026rsquo;$, versus solving antiderivatives of $f\u0026rsquo;$. By automating the generation of problems of graduating difficulty, we create datasets that enable process-supervised training of LLMs. We demonstrate the efficacy of this method for training mathematical reasoning. Our results show significant improvements in LLMs\u0026rsquo; problem-solving capabilities, particularly in areas requiring multi-step reasoning and creative insights. This methodology not only enhances model performance but also provides a framework for generating explainable AI solutions, as the step-by-step problem-solving process is inherent in the training data.\u003c/p\u003e",
        "tags": ["artificial intelligence","machine learning","mathematics","algebra","calculus","LLMs","synthetic data","data generation","reasoning","AI training","explainable AI"],
        "section": "posts"
      },{
        "title": "sluug-demystifying-large-language-models-llms-on-linux-from-theory-to-application",
        "link": "http://localhost:1313/posts/gave-a-presentation-for-sluug-about-llms/",
        "date": "2024-02-23 00:00:00 +0000 UTC",
        "content": "External Project Check out the project on GitHub: SLUUG Talk: Demystifying Large Language Models (LLMs) on Linux\nAbout I gave a presentation for the St. Louis Unix Users Group (SLUUG) about Large Language Models (LLMs) on Linux. The talk was titled \u0026ldquo;Demystifying Large Language Models (LLMs) on Linux: From Theory to Application\u0026rdquo;. The talk was about the theory behind LLMs, how they work, and how to use them on Linux.\nI also demoed two projects:\nA simple Colab notebook that uses very simple Python code to generate text usnig an n-gram model to illustrate the basic idea behind LLMs and why the n-gram model falls short.\nA project that uses ElasticSearch and LLMs to allow for search queries over databases using natural language.\nThe talk was well-received and I had a great time giving it. I\u0026rsquo;m looking forward to giving more talks in the future. The content for the talk can be found here.\n",
        "summary": "Gave a talk for the St. Louis Unix Users Group (SLUUG) about Large Language Models (LLMs) on Linux titled \u0026lsquo;Demystifying Large Language Models (LLMs) on Linux: From Theory to Application\u0026rsquo;.",
        "tags": [],
        "section": "posts"
      },{
        "title": "masters-project-reliability-estimation-in-series-systems",
        "link": "http://localhost:1313/posts/masters-stats-siue-proj/",
        "date": "2024-02-19 00:00:00 +0000 UTC",
        "content": "To complete my masters degree in statistics/mathematics at SIUe I presented my master\u0026rsquo;s project in October 2023. Their was also a paper associated with the project titled \u0026ldquo;Reliability Estimation in Series Systems: Maximum Likelihood Techniques for Right-Censored and Masked Failure Data\u0026rdquo;.\nSee the project here.\n",
        "summary": "I presented my master\u0026rsquo;s project in October 2023. It was titled \u0026lsquo;Reliability Estimation in Series Systems: Maximum Likelihood Techniques for Right-Censored and Masked Failure Data\u0026rsquo;.",
        "tags": ["likelihood-models","likelihood-contributions-model","data-generating-process","R","statistics"],
        "section": "posts"
      },{
        "title": "fine-tuning-tiny-llms-for-elasticsearch-dsl",
        "link": "http://localhost:1313/posts/llm-fine-tuning-es-dsl/",
        "date": "2024-02-19 00:00:00 +0000 UTC",
        "content": "I am fine-tuning a tiny LLM for ElasticSearch DSL as a proof of concept. The GitHub repo for this project can be found here. It mostly consists of synthetic data. I need to reshape the data so that it\u0026rsquo;s in the expected format and then fine-tune the model, as the data has been generated, initially from GPT-4 and then from a script I made to sample from those outputs and use them as few-shot examples for Mistral to generate a lot more synthetic data. I will then use this data to fine-tune the model and see how well it performs on the ElasticSearch DSL.\nShoot me an email at lex@metafunctor.com if you\u0026rsquo;re interested in collaborating on any projects.\n",
        "summary": "I am creating a tiny LLM for ElasticSearch DSL as a proof of concept.",
        "tags": ["large language models","fine-tuning","information retrieval","elastic search","domain-specific language","json"],
        "section": "posts"
      },{
        "title": "the-bernoulli-model-a-probabilistic-framework-for-data-structures-and-types",
        "link": "http://localhost:1313/posts/bernoulli-boolean-model/",
        "date": "2023-06-17 00:00:00 +0000 UTC",
        "content": "Motivation The Bernoulli Model is a general framework for thinking about probabilistic data structures and types of a particular sort. A big reason for developing the Bernoulli Model formalism is so that we can use Bernoulli Models of data types to develop Oblivious Data Types. We will go into that in a separate document, but the basic idea is that Bernoulli approximations have a lot of desirable properties for developing oblivious data types, and the Bernoulli Model formalism allows us to reason about the correctness of the oblivious data types and to make them more space-efficient by trading accuracy for space while allowing for $\\mathcal{O}(1)$ time complexity.\nThe Bernoulli Model also provides a formalism for how to think about various probabilistic data structures, like the Bloom filter, Count-Min sketch, or my invention, the Bernoulli data type, which comprises an entire family of data structures that are all based on the Bernoulli Model, from sets (like the Bloom filter) to maps in a near-space optimal way, while allowing for more savings by trading accuracy for space in a controlled way.\nIntroduction: Bernoulli Boolean The Boolean type, denoted by $\\mathrm{bool}$, models the set of values given by $\\{\\mathrm{true},\\mathrm{false}\\}$, or more compactly $\\{0,1\\}$. This document entertains the replacement of $\\mathrm{bool}$ with a type $B_{\\mathrm{bool}}$, which represents a sort of noisy Boolean. In general, we can have a Bernoulli type for any type $T$, denoted by $B_T$.\nAs special case, data structures like Bloom filters can be thought of as a Bernoulli type for the set indicator function, $1_A : X \\mapsto {0,1}$, but more on that later.\nThere are two types that have fewer values than the Boolean type, the absurd type, denoted by $\\mathrm{void}$, which is the type with no values (and thus values of this type cannot be constructed) and the unit type, denoted by $()$, which has only a single value, also denoted by $()$. Since there is only a single value of the unit type, there is no uncertainty in the unit type.\nAs degenerate cases, the Bernoulli Model of the absurd is just the absurd type, $B_{\\mathrm{void}} \\equiv \\mathrm{void}$, and Bernoulli Model of the unit type is just the unit type, $B_{()} \\equiv ()$.\nThe Boolean type $\\mathrm{bool}$ has two possible values, $\\mathrm{true}$ and $\\mathrm{false}$, and is thus the first type for which we can introduce uncertainty.\nEvery Bernoulli Model also has an order, an integer greater than 1, which essentially describes the number of independent ways in which the process that generated the Bernoulli approximation can produce errors. We denote that a Bernoulli Model of type $T$ has order $k$ with $B_T^{(k)}$. For the absurd and unit types, the maximum order is $0$, and in general $T \\equiv B_T^{(0)}$, i.e., if there are no ways to introduce errors, then that is equivalent to the type itself.\nUnless it is useful, we drop the order information and simply write $B_T$. In the Bernoulli Model, we may denote the latent value $x$ that is being approximated using the notation $B_T(x)$ and we say that it is latent if we do not know the value of $x$ and we are trying to approximate it using the Bernoulli Model approximation $B_T(x)$. In this case, the latent value $x$ is unobservable and we can think of $B_T(x)$ as a noisy measurement of $x$.\n$$ \\Pr\\\\{ B_{\\mathrm{bool}}(x) \\neq x\\\\} = \\varepsilon(x) $$ for each $x \\in \\{0,1\\}$, where $0 \u0026lt; \\varepsilon(x) \u0026lt; 1$ is the probability of an error. In most practical situations, $\\varepsilon(x)$ is known or its expectation is known, and it can be pre-specified to balance factors like space complexity and accuracy.\nBinary Channels Let\u0026rsquo;s begin by thinking about the Binary Symmetric Channel and the Binary Asymmetric Channel. The Bernoulli Boolean model can exhibit two distinct behaviors, represented as different \u0026ldquo;channels\u0026rdquo; through which Boolean values are transmitted:\nBinary Symmetric Channel (First-order Bernoulli Model): The probability of an equality error is the same for $1$ and $0$. We denote this by the type $B_{\\mathrm{bool}}^{(1)}$.\nBinary Asymmetric Channel (Second-order Bernoulli Model): The probability of an equality error differs for $1$ and $0$. We denote this by the type $B_{\\mathrm{bool}}^{(2)}$.\nFalse Positives and Negatives Errors in the Bernoulli Boolean model can be understood in terms of false negatives and false positives:\n$B_{\\mathrm{bool}}(0) = 1$ is a false negative. $B_{\\mathrm{bool}}(1) = 0$ is a false positive. In the first-order model, the probability of a false negative equals the probability of a false positive. In the second-order model, these probabilities differ. In a specific but common version of the second-order Bernoulli Boolean model, false negatives occur with probability 0 and false positives occur with probability $0 \u0026lt; \\varepsilon \u0026lt; 1$.\nPrediction $B_T(x)$ is correlated with the latent value $x$, and thus provides information about the latent value. For instance, it allows one to predict $x$ given $B_T(x)$ better than if no observations where given whatsoever, assuming we know the error rate $\\varepsilon(x)$ is better than a random guess, e.g., in the case of $B_{\\mathrm{bool}}$, $\\varepsilon(x) \u0026lt; 0.5$. If we have no prior information about the latent variable, the best (maximum likelihood) estimate of of its value is the observation $B_T(x)$.\n$$ \\Pr\\\\{X = x \\mid B_T(x) = x \\\\} \\propto \\Pr\\\\{B_T(x) = x \\mid X = x\\\\} \\Pr\\\\{X = x\\\\}, $$ where $\\Pr\\{X = x\\}$ is the prior probability that $X = x$ and $\\Pr\\{B_T(x) = x \\mid X = x\\}$ is the probability that $B_T(x) = x$ given that $X = x$ (the probability that the observation is correct). In the Bernoulli Boolean Model, for $X = 1$ this is the true positive rate $\\tau$ and for $X = 0$ this is the true negative rate $\\nu$.\n$$ \\Pr\\\\{x \\mid B_{\\mathrm{bool}}^{(1)}(x)\\\\} = \\frac{\\tau \\Pr\\\\{X = x\\\\}} {\\tau \\Pr\\\\{X = x\\\\} + (1-\\tau) (1-\\Pr\\\\{X = x\\\\})}. $$$$ \\Pr\\\\{x \\mid B_{\\mathrm{bool}}^{(1)}(x)\\\\} = \\frac{\\tau}{\\tau + (1-\\tau) (1/\\Pr\\\\{X = x\\\\} - 1)}. $$Assuming maximum ignorance (maximum entropy) about $x$ (i.e., $\\Pr\\{X = 1\\} = 0.5$), the following expression is obtained for the first-order Bernoulli Boolean Model, the above equation simplifies to $\\Pr\\{x \\mid B_{\\mathrm{bool}}^{(1)}(x)\\} = \\tau$.\n$$ \\Bigl\\\\{ B_{1,\\mathrm{bool}}^{(1)}(x), \\ldots, B_{n,\\mathrm{bool}}^{(1)}(x) \\Bigr\\\\}, $$ in which case the maximum likelihood estimate of $x$ is the majority vote, i.e., the value that occurs most frequently in the observations. As the number of independent sources of observations goes to infinity, the majority vote converges in probability to $x$.\nThis is not a typical use-case for the Bernoulli Boolean model, since it will mostly be a analytical result of probabilistic data structures that may be framed in the context of a Bernoulli Model.\nInducing Bernoulli Types Here, we discuss how to generalize the results.\nUnit Functions We discussed the idea of the Bernoulli Model for value types like $\\mathrm{bool}$. We can think of these Bernoulli Models as Bernoulli approximations of the set of unit types $() \\mapsto X$. A unit type has no input, and it maps to a single constant value in the output. There are $|X|$ functions of this type.\nIf we replace $() \\mapsto X$ with $B_X$ or, equivalently, $B_{() \\mapsto X}$, we allow for the possibility of errors. The confusion matrix for $B_{() \\mapsto \\mathrm{bool}}^{(2)}$ is provided in Table 1.\nTable 1: Second-order Bernoulli Boolean Model for $() \\mapsto \\mathrm{bool}$\n$x / B_{\\mathrm{bool}}^{(2)}$ observe $1$ observe $0$ latent $1$ $\\tau = 1-\\eta$ $\\eta$ latent $0$ $\\varepsilon$ $\\nu = 1-\\varepsilon$ So, we might observe $B_{() \\mapsto \\mathrm{bool}}(x) = 1$ and, according to the confusion matrix, the latent value $x$ is $1$ with probability $\\tau$ (true positive rate) and $0$ with probability $\\varepsilon$ (false positive rate). Likewise, we might observe $B_{() \\mapsto \\mathrm{bool}}(x) = 0$ and the latent value $x$ is $1$ with probability $\\eta$ (false negative rate) and $0$ with probability $\\nu$ (true negative rate).\nWe see that the Bernoulli Model for $() \\mapsto \\mathrm{bool}$ has a maximum order of 2, since $\\eta$ and $\\varepsilon$ are independent probabilities that fully describe the model. No additional free parameters are possible, since each row must sum to 1 (the total probability theorem), i.e., given a latent value $x$, the probability of observing $1$ or $0$ must sum to $1$ since that is the only possible two outcomes in the Bernoulli Boolean Model.\nWe can think of this as the asymmetric binary channel, where the probability of an error is different for $1$ and $0$.\nA first-order Bernoulli Boolean model is a model where $\\epsilon = \\varepsilon = \\eta$. See the confusion matrix in Table 2.\nTable 2: First-Order Bernoulli Boolean Model for $() \\mapsto \\mathrm{bool}$\n$x / B_{\\mathrm{bool}}^{(1)}$ observe $1$ observe $0$ latent $1$ $\\tau =1-\\epsilon$ $\\eta = \\epsilon$ latent $0$ $\\varepsilon = \\epsilon$ $\\nu = 1-\\epsilon$ We can see that there is only one free parameter, $\\epsilon$, corresponding to the first-order Bernoulli Boolean Model. We can think of this as a binary symmetric channel, where the probability of an error is the same for $1$ and $0$.\nFor completeness, we can write down the confusion matrix for the zeroth-order model, which is just the standard Boolean model:\nTable 3: Zeroth-Order Bernoulli Boolean Model for $() \\mapsto \\mathrm{bool}$\n$x / B_{\\mathrm{bool}}^{(1)}$ observe $1$ observe $0$ latent $1$ 1 0 latent $0$ 0 1 We see that there are 0 free parameters, and the model is deterministic.\nPrediction: Boolean Values Earlier, we discussed how to predict latent values from Bernoulli Model observations. Let\u0026rsquo;s apply these insights to the first-order Bernoulli Model for $() \\mapsto \\mathrm{bool}$, which we can denote as $B_{\\mathrm{bool}}^{(1)}$.\n$$ \\Pr\\\\{X = 1 | B_{\\rm{bool}}^{(1)} = 1\\\\} = \\frac{ \\Pr\\\\{B_{\\rm{bool}}^{(1)} =1 | X=1\\\\} \\Pr\\\\{X = 1\\\\} } { \\Pr\\\\{B_{\\rm{bool}}^{(1)} = 1\\\\} } $$$$ \\Pr\\\\{X=1 | B_{\\rm{bool}}^{(1)}=1\\\\} = \\frac {(1-\\epsilon) \\Pr\\\\{X = 1\\\\}} {\\Pr\\\\{B_{\\rm{bool}}^{(1)}=1\\\\}} $$$$ \\begin{split} \\Pr\\\\{B_{\\rm{bool}}^{(1)} = 1\\\\} = \\Pr\\\\{ B_{\\rm{bool}}^{(1)}=1 | X=1\\\\} \\Pr\\\\{X = 1\\\\} + \\\\\\ \\Pr\\\\{B_{\\rm{bool}}^{(1)}=1 | X=0\\\\} \\Pr\\\\{X = 0\\\\}. \\end{split} $$$$ \\Pr\\\\{B_{\\rm{bool}}^{(1)} = 1\\\\} = (1-\\epsilon) \\Pr\\\\{X = 1\\\\} + \\epsilon \\Pr\\\\{X = 0\\\\}. $$$$ \\Pr\\\\{X=1 | B_{\\rm{bool}}^{(1)}=1\\\\} = \\frac {1-\\epsilon} {1-\\epsilon (1 - q/(1-q))} $$ where $q = \\Pr\\{X = 0\\}$.\nLet\u0026rsquo;s evaluate $q = \\Pr\\{X = 0\\}$ at some interesting points:\nAt $q = 0$, $\\Pr\\{X=1 | B_{\\rm{bool}}^{(1)}=1\\} = 1$. This makes sense. We know that the latent value $1$ occurs with probability $1-q=1$, therefore whatever no matter what we observe, the latent value is $1$. As $q \\to 1$, $\\Pr\\{X=1 |B_{\\rm{bool}}^{(1)}=1\\} \\to 0$. This also makes sense; we know that the latent value $1$ occurs with probability $q=1$, so no matter what we observe, the latent value is $0$. At $q = 0.5$, $\\Pr\\{X=1 |B_{\\rm{bool}}^{(1)}=1\\} = 1-\\epsilon$. This is the maximum entropy case, where we have no prior information about the latent value and assume maximum ignorance. Unary Bernoulli Functions In this section, we expand our focus to unary functions.\nLifing Unary Functions If we have a function $f : \\rm{bool} \\mapsto \\rm{bool}$, then the space of all possible functions is given by Table 4.\nTable 4: All possible functions of type $\\rm{bool} \\mapsto \\rm{bool}$\n$f$ $f(\\rm{true})$ $f(\\rm{false})$ $\\rm{id}$ $\\rm{true}$ $\\rm{false}$ $\\rm{not}$ $\\rm{false}$ $\\rm{true}$ $\\rm{true}$ $\\rm{true}$ $\\rm{true}$ $\\rm{false}$ $\\rm{false}$ $\\rm{false}$ Suppose we replace the Boolean inputs with Bernoulli Boolean values and ask the question, \u0026ldquo;What is the probability that $f\\bigl(B_{\\rm{bool}}^{(1)}(x)\\bigr) = f(x)$?\u0026rdquo;\nNotice that $f\\bigl(B_{\\rm{bool}}^{(1)}(x)\\bigr)$ is $f(x)$ with some probability, but $f(x)$ may be latent depending on $f$. For the constant fuctions, $\\mathrm{true}$ and $\\mathrm{false}$, we get the same function, i.e., $\\mathrm{true} : B_{\\rm{bool}}^{(k)} \\mapsto B_{\\rm{bool}}^{(0)} \\equiv \\mathrm{true} : \\mathrm{bool} \\mapsto \\mathrm{bool}$ since $\\mathrm{true} : \\mathrm{bool} \\mapsto \\mathrm{bool}$ always outputs $\\mathrm{true}$, and similiarly for $\\mathrm{false} : \\mathrm{bool} \\mapsto \\mathrm{bool}$.\nHowever, the $\\mathrm{id}$ and $\\mathrm{not}$ functions are different. For instance, suppose $\\Pr\\{B_{\\rm{bool}}^{(1)}(x) = x\\} = p$. Then, when we input $B_{\\rm{bool}}^{(1)}(\\mathrm{true})$ into $\\mathrm{id}$, we get the correct output $\\mathrm{true}$ with probability $p$ and the incorrect output $\\mathrm{false}$ with probability $1-p$. Likewise,when we input $B_{\\mathrm{bool}}^{(1)}(\\mathrm{false})$ into $\\mathrm{id}$, we get the correct output $\\mathrm{false}$ with probability $p$ and the incorrect output $\\mathrm{true}$ with probability $1-p$.\nSince we can think of these outputs as either correct or incorrect with probability $p$ and $1-p$ respectively, they are Bernoulli Boolean values, e.g., this $\\mathrm{id}$ function on Bernoulli Booleans is of type $B_{\\mathrm{bool}}^{(1)} \\mapsto B_{\\mathrm{bool}}^{(1)}$. We monadically lift $\\mathrm{id} : \\mathrm{bool} \\mapsto \\mathrm{bool}$ to a function of type $B_{\\mathrm{bool}}^{(1)} \\mapsto B_{\\mathrm{bool}}^{(1)}$.\nNotice that this is not a Bernoulli Model of $B_{\\mathrm{bool} \\mapsto \\mathrm{bool}}$, but rather a function of type $B_{\\mathrm{bool}} \\mapsto B_{\\mathrm{bool}}$. This may surprise the reader, but it is important to think about how these Bernoulli Models compose.\nFor instance, if we have the function $\\mathrm{true} : \\mathrm{bool} \\mapsto \\mathrm{bool}$, then when we provide it with a Bernoulli Boolean value, we know that we $\\mathrm{true}$ is the correct output \u0026ndash; there are no latent values. However, a Bernoulli Model of the (function) $\\mathrm{true} : \\mathrm{bool} \\mapsto \\mathrm{bool}$ is a completely different concept. The Bernoulli approximation of this funcction is of type $B_{\\mathrm{bool} \\mapsto \\mathrm{bool}}$, and the latent function, $\\mathrm{true} : \\mathrm{bool} \\mapsto \\mathrm{bool}$, is not observable, but $B_{\\mathrm{bool} \\mapsto \\mathrm{bool}}(\\mathrm{true})$ is observable and provides some information about the latent function.\nPresumably, some process generated the Bernoulli approximation $B_{\\mathrm{bool} \\mapsto \\mathrm{bool}}(\\mathrm{true})$, and we wish to use that approxmiate function as a replacement for the latent function we are actually interested in, which is $\\mathrm{true} : \\mathrm{bool} \\mapsto \\mathrm{bool}$.\nThere are only 4 possible functions of type $\\mathrm{bool} \\mapsto \\mathrm{bool}$, and in Table 5 we show the confusion matrix for the highest-order model, $B_{\\mathrm{bool} \\mapsto \\mathrm{bool}}^{(12)}$.\nTable 5: Bernoulli Model for $\\mathrm{bool} \\mapsto \\mathrm{bool}$\nobserve $\\mathrm{id}$ observe $\\mathrm{not}$ observe $\\mathrm{true}$ observe $\\mathrm{false}$ latent $\\mathrm{id}$ $p_{1 1}$ $p_{1 2}$ $p_{1 3}$ $p_{1 4}$ latent $\\mathrm{not}$ $p_{2 1}$ $p_{2 2}$ $p_{2 3}$ $p_{2 4}$ latent $\\mathrm{true}$ $p_{3 1}$ $p_{3 2}$ $p_{3 3}$ $p_{3 4}$ latent $\\mathrm{false}$ $p_{4 1}$ $p_{4 2}$ $p_{4 3}$ $p_{4 4}$ Each row must sum to 1, $\\sum_j p_{i j} = 1$, so we only have up to a maximum of $4 (4-1) = 12$ degrees of freedom. This means the highest Bernoulli Boolean order is 12, but we normally drop the order information and just write $B_{\\mathrm{bool} \\mapsto \\mathrm{bool}}$ (and propogate error rates using interval arithmetic).\nOften, the order is either first-order or for various reasons. The first-order Bernoulli Model of $\\mathrm{bool} \\mapsto \\mathrm{bool}$ is a model where every entry in the confusion matrix is a function of some single value. The maximum entropy confusion matrix, given error rates $\\epsilon$, is given in Table 6.\nTable 5: Bernoulli Model for $\\mathrm{bool} \\mapsto \\mathrm{bool}$\nobserve $\\mathrm{id}$ observe $\\mathrm{not}$ observe $\\mathrm{true}$ observe $\\mathrm{false}$ latent $\\mathrm{id}$ $1-\\epsilon$ $\\epsilon/3$ $\\epsilon/3$ $\\epsilon/3$ latent $\\mathrm{not}$ $\\epsilon/3$ $1-\\epsilon$ $\\epsilon/3$ $\\epsilon/3$ latent $\\mathrm{true}$ $\\epsilon/3$ $\\epsilon/3$ $1-\\epsilon$ $\\epsilon/3$ latent $\\mathrm{false}$ $\\epsilon/3$ $\\epsilon/3$ $\\epsilon/3$ $1-\\epsilon$ When we have a Bernoulli Model approximation of some latent function of type $\\mathrm{bool} \\mapsto \\mathrm{bool}$, we wish to store the error information in the output so that we can propagate error information through the computation.\nWe do this by saying that the output is a Bernoulli Boolean, because it may or may not be correct, i.e., the Bernoulli Model generates a function of type $\\mathrm{bool} \\mapsto B_{\\mathrm{bool}}$ where the output is a Bernoulli Boolean value. In our algorithms, we created a type system for this, using interval arithmetic to propagate the error rates through the computation.\nNotice that the Bernoulli Model on $\\mathrm{bool} \\mapsto \\mathrm{bool}$ does not change the type of the input, $\\mathrm{bool}$. We can, of course, also provide as input to this function a Bernoulli Booleans, in which case we will usually get an even higher-order Bernoulli Boolean as output.\n$$ \\Pr\\\\{ B_{\\mathrm{bool} \\mapsto \\mathrm{bool}}(f) = f\\\\}. $$$$ \\begin{split} \\Pr\\\\{B_{\\mathrm{bool}\\mapsto \\mathrm{bool}}^{(1)}(\\mathrm{id})(\\mathrm{true}) = \\mathrm{id}(\\mathrm{true}) \\\\} \\times \\\\\\ \\Pr\\\\{B_{\\mathrm{bool}\\mapsto \\mathrm{bool}}^{(1)}(\\mathrm{id})(\\mathrm{false}) = \\mathrm{id}(\\mathrm{false}) \\\\} \\end{split} $$From the confusion matrix, we know this product of probabilities is $1-\\epsilon$. In fact, normally, the process that generates the Bernoulli Model of the latent function is based on these kinds of probabilities on individual inputs.\nHigher-Order Bernoulli Models If we are trying to estimate the latent function, a higher order complicates the estimation problem (more parameters to estimate). However, a higher-order may be desirable in many cases, since it allows for more capacity to approximate the latent function. In general, when looking at the confusion matrix, we want the diagonal to be as close to 1 as possible. For the off-diagonal elements, we want functions that are more similiar to the latent function to have larger probabilities than functions that are less similiar to the latent function. This is just a way of minimizing a loss function.\nSet-Indicator Functions The set-indicator function is a function that maps an element of a set to a Boolean value. We can think of this as a function of type $X \\mapsto \\mathrm{bool}$, which returns true if the input is in the set and false otherwise.\nLet us consider Bernoulli Models for set-indicator functions. The Bloom filter, for instance, is a Bernoulli model of the set-indicator function. It is a second-order model, since false negatives occur with probability 0 and false positives occur with probability $\\varepsilon$. This is actually the expectation of the false positive rate, and the true false positive rate is a random variable that cannot usually be computed unless $X$ is a finite set.\nHashSet: Approximate Set-Indicator Functions Suppose we have a cryptographic hash function $h : X \\mapsto {0,1}^n$, where $n$ is the number of bits in the hash value. We define an approximate set-indicator function, denoted by $\\mathrm{HashSet}$, in the following way:\nWe are given a set $A$ to (approximately) represent. We find a seed $s$ such that $h(x s) = 0^n$ for all $x \\in A$. We do not look at any $x \\notin A$, and by the properties of $h$, for $x \\notin A$, $h(x s) = 0^n$ with probability $2^{-n}$ corresponding to a false positive, and otherwise $h(x s) \\neq 0^n$ with probability $1-2^{-n}$. We define membership as $x \\in A \\equiv h(x s) = 0^n$. $$ \\prod_{j=1}^{|A|} 2^{-n} = 2^{-n|A|}, $$ which will take an expected number of trials $2^{n|A|}$. We can store the seed as a string of $n|A|$ bits, or $n$ bits per element in the set $A$. Since it has a false positive rate $\\varepsilon = 2^{-n}$, $n = -\\log_2 \\varepsilon$, and we can reparametrize the space complexity as $-\\log_2 \\varepsilon$ bits per element. This is the information theoretic lower-bound, but we achieved it only by using an algorithm with exponential time complexity. We can do better by using different algorithms, but it comes at a cost to space complexity.\nBernoulli Model for Set-Indicator Functions The number of functions of type $X \\mapsto \\mathrm{bool}$ is $2^{|X|}$. We can think of these as the set of all possible set-indicator functions. We can approximate this set of functions with a Bernoulli Model, which we denote $B_{X \\mapsto \\mathrm{bool}}$.\nWe can use the simple $\\mathrm{HashSet}$ construction to induce the Bernoulli Model for set-indicator functions. Specifically, in the $\\mathrm{HashSet}$, false positives occur with some positive probability $\\epsilon$ and false negatives occur with probability $0$.\nTechnically, however, the Bernoulli Model is being applied to the set-indicator function, but this also specifies a Bernoulli Model on the Boolean output of the set-indicator function:\n$$ \\in : X \\times \\mathcal{P}(X) \\mapsto B_{\\mathrm{bool}}. $$Let\u0026rsquo;s consider $X = \\{1,2\\}$ and $A = \\{2\\}$. The confusion matrix for the this contruction is given in Table 7.\nTable 7: Bernoulli Model for $X \\mapsto \\mathrm{bool}$\n$1_\\emptyset$ $1_{\\{1\\}}$ $1_{\\{2\\}}$ $1_{\\{1,2\\}}$ $1_\\emptyset$ $(1-\\epsilon)^2$ $\\epsilon(1-\\epsilon)$ $\\epsilon(1-\\epsilon)$ $\\epsilon^2$ $1_{\\{1\\}}$ $0$ $1-\\epsilon$ $0$ $\\epsilon$ $1_{\\{2\\}}$ $0$ $0$ $1-\\epsilon$ $\\epsilon$ $1_{\\{1,2\\}}$ $0$ $0$ $0$ $1$ We do not know the latent set $A = \\{2\\}$, we only have the approximation $B_{X \\mapsto \\mathrm{bool}}(A)$, and we use this as a replacement for the latent set $A$.\nNotice that if we start with $A = \\{2\\}$, in row 3, we have zeros in the first two columns for the empty set and $\\{1\\}$, which makes sense as by construction no false negatives are possible, only false positives.\nWe see that with probability $1-\\epsilon$, the output is correct, and with probability $\\epsilon$, the output is incorrect. This is a Bernoulli Model of the set-indicator function (or Bernoulli Set), and we can use this to provide information about the latent set.\n$$ \\Pr\\\\{x \\in B_{X \\mapsto \\mathrm{bool}}(A)\\\\}. $$$$ x \\in B_{X \\mapsto \\mathrm{bool}}(A) : X \\mapsto \\mathrm{bool}^{(2)}. $$Conclusion The Bernoulli Model is a way of thinking about the uncertainty in the output of a function, and how that uncertainty propagates through a computation, and typically the uncertainty is due to a trade-off between space complexity and accuracy. The more space we use to represent the function, the more closely it is expected to approximate the latent function.\n",
        "summary": "This blog post introduces the Bernoulli Model, a framework for understanding probabilistic data structures and incorporating uncertainty into data types, particularly Boolean values. It highlights the model\u0026rsquo;s utility in optimizing space and accuracy in data representation.",
        "tags": null,
        "section": "posts"
      },{
        "title": "digistar-advanced-sandbox-networked-space-simulation",
        "link": "http://localhost:1313/projects/digistar/",
        "date": "2024-07-22 00:00:00 +0000 UTC",
        "content": "digistar is aiming to be an advanced sandbox space simulation game. This project leverages GPU acceleration and optimized data structures like octrees to create a highly interactive and scalable sandbox for large n-body systems. By simulating interactions between millions of \u0026ldquo;big atoms\u0026rdquo; through fundamental forces, players can explore dynamic celestial mechanics, engage in rich multiplayer experiences, and experiment with novel physics phenomena. The goal is to provide a deeply immersive environment with realistic physics and efficient performance, supporting a large number of concurrent players and AI bots.\n",
        "summary": "An advanced sandbox space simulation game leveraging GPU acceleration and optimized data structures like octrees to create a highly interactive and scalable sandbox for large n-body systems.",
        "tags": ["computer science","multiprocessor synchronization","gpu","octree","n-body simulation","sandbox game","space simulation","physics","potential energy function","celestial mechanics","multiplayer"],
        "section": "projects"
      },{
        "title": "ga-llm",
        "link": "http://localhost:1313/ghprojects/ga-llm/",
        "date": "2024-08-26 12:12:03 +0000 UTC",
        "content": "ga-llm No description available.\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nREADME Improving Generative Model Performance using Genetic Algorithms Abstract In this paper, we propose a novel approach to improving the performance of generative models, including large language models (LLMs), using Genetic Algorithms (GAs). Our method iteratively refines model outputs through the evolutionary process of selection, crossover, and mutation, guided by a problem-specific fitness function. We demonstrate the effectiveness of this approach across several tasks, including text generation and reasoning, and explore the trade-offs between quality, diversity, and computational efficiency.\nKeywords: Genetic Algorithms, Language Models, Generative Models, Evolutionary Optimization\n1. Introduction The field of generative models, particularly large language models (LLMs), has seen significant advancements in recent years. These models are capable of producing high-quality text across various tasks, from creative writing to reasoning and problem-solving. However, despite their successes, generative models can still struggle with generating optimal outputs for specific tasks. In this paper, we introduce an approach to optimize generative model performance using Genetic Algorithms (GAs).\nGenetic Algorithms are a class of evolutionary algorithms inspired by natural selection, where candidate solutions evolve over generations based on their fitness to a given problem. We explore how GAs can be applied to improve the quality, diversity, and adaptability of LLM-generated outputs, and provide a framework that integrates GAs with generative models.\n2. Background 2.1 Genetic Algorithms Genetic Algorithms (GAs) are optimization techniques that simulate the process of natural evolution. The basic components of GAs include:\nPopulation: A set of candidate solutions. Selection: The process of choosing individuals from the population based on their fitness. Crossover: The combination of two or more parent solutions to create offspring. Mutation: The introduction of random changes to offspring. Fitness Function: A measure of how well a solution solves the problem. Termination: The criteria for stopping the algorithm, typically based on convergence or a predefined number of generations. Mathematically, the optimization problem solved by GAs can be expressed as:\n\\[ S^* = \\arg\\max_{S \\in \\mathcal{S}} F(S) \\]where \\( S^* \\) is the optimal solution, \\( \\mathcal{S} \\) is the set of all possible solutions, and \\( F(S) \\) is the fitness function evaluating solution \\( S \\).\n2.2 Generative Models Generative models, particularly LLMs, have become integral in various AI tasks. These models are trained to generate new data instances based on learned patterns. While LLMs are powerful, they may not always generate optimal outputs due to limitations in training data or model architecture. The application of GAs offers a promising approach to refining and optimizing these outputs through iterative improvement.\n3. Methodology 3.1 GA-LLM-Optimize Framework We propose the following high-level framework for optimizing LLM outputs using Genetic Algorithms:\nAlgorithm: GA-LLM-Optimize(prompt \\( P \\), model \\( M \\), population_size \\( N \\), generations \\( G \\)) Initialization: Generate an initial population \\( \\text{Pop} = \\{S_1, S_2, \\dots, S_N\\} \\) where \\( S_i = M(P) \\) for \\( i = 1 \\) to \\( N \\). Evaluation: Calculate the fitness \\( F_i = F(S_i) \\) for each \\( S_i \\) in \\( \\text{Pop} \\). Selection: Select parents based on fitness using a selection strategy (e.g., tournament selection). Crossover: Combine selected parents to create offspring solutions. Mutation: Apply random mutations to some offspring. Replacement: Form the new population by replacing old individuals with offspring. Termination: Repeat steps 2-6 until termination criteria are met. \\[ S^* = \\arg\\max_{S \\in \\text{Pop}} F(S) \\]3.2 Fitness Function Design The fitness function \\( F(S) \\) is task-dependent and can be customized to evaluate content quality, relevance, coherence, diversity, or other criteria. We discuss several variations of fitness functions, including single-objective and multi-objective formulations.\n3.3 Genetic Operators: Crossover and Mutation We explore different methods for crossover and mutation tailored to text generation tasks. These include:\nSemantic Crossover: Combining semantic elements from two parent outputs. Prompt Mutation: Introducing slight variations in the prompt to influence generation. Textual Mutation: Directly modifying words, phrases, or structures in the output. 4. Experiments 4.1 Experimental Setup Describe the experimental setup, including the specific generative models, prompts, tasks, and GA parameters (e.g., population size, number of generations).\n4.2 Baselines We compare our GA-based optimization approach against baseline generative methods, including:\nBeam search Random sampling Fine-tuning without GA 4.3 Metrics Evaluation metrics include:\nContent quality (e.g., BLEU, ROUGE) Coherence and relevance Diversity Computational efficiency 5. Results 5.1 Main Results Present the main experimental results, including tables and figures comparing the performance of our GA-based optimization approach against baselines.\n\\[ \\text{Table 1: Comparison of Quality and Diversity Metrics} \\]\\[ \\text{Figure 1: Fitness over Generations} \\]5.2 Ablation Study Discuss the results of an ablation study where different components of the GA (e.g., crossover, mutation) are removed or modified to evaluate their impact on performance.\n6. Discussion 6.1 Advantages and Limitations We discuss the advantages of using GAs for optimizing generative models, such as improved output quality and diversity. We also address the limitations, including computational costs and potential convergence issues.\n6.2 Future Work Potential avenues for future research include:\nScaling GAs for larger populations and longer generations Exploring hybrid approaches combining GAs with reinforcement learning or fine-tuning Applying this method to other domains, such as image or music generation 7. Conclusion In this paper, we presented a novel approach to optimizing generative model outputs using Genetic Algorithms. Our results demonstrate the potential of evolutionary techniques to enhance the performance of large language models across various tasks. We believe that this approach opens up new possibilities for fine-tuning and adapting generative models in complex environments.\nReferences (Add references here)\n",
        "summary": "\u003ch1 id=\"ga-llm\"\u003ega-llm\u003c/h1\u003e\n\u003cp\u003eNo description available.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/ga-llm\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003ch1 id=\"improving-generative-model-performance-using-genetic-algorithms\"\u003eImproving Generative Model Performance using Genetic Algorithms\u003c/h1\u003e\n\u003ch2 id=\"abstract\"\u003eAbstract\u003c/h2\u003e\n\u003cp\u003eIn this paper, we propose a novel approach to improving the performance of generative models, including large language models (LLMs), using Genetic Algorithms (GAs). Our method iteratively refines model outputs through the evolutionary process of selection, crossover, and mutation, guided by a problem-specific fitness function. We demonstrate the effectiveness of this approach across several tasks, including text generation and reasoning, and explore the trade-offs between quality, diversity, and computational efficiency.\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "github",
        "link": "http://localhost:1313/tags/github/",
        "date": "2024-08-26 12:12:03 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "github-projects",
        "link": "http://localhost:1313/ghprojects/",
        "date": "2024-08-26 12:12:03 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": ["GitHub"],
        "section": "ghprojects"
      },{
        "title": "metafunctor",
        "link": "http://localhost:1313/",
        "date": "2024-08-26 12:12:03 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": ""
      },{
        "title": "project",
        "link": "http://localhost:1313/tags/project/",
        "date": "2024-08-26 12:12:03 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "tags",
        "link": "http://localhost:1313/tags/",
        "date": "2024-08-26 12:12:03 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "rpsdg",
        "link": "http://localhost:1313/ghprojects/rpsdg/",
        "date": "2024-07-25 16:24:45 +0000 UTC",
        "content": "RPSDG No description available.\nGitHub Link\nStars: 1 | Forks: 0 | Open Issues: 0\nNo README available for this project.\n",
        "summary": "\u003ch1 id=\"rpsdg\"\u003eRPSDG\u003c/h1\u003e\n\u003cp\u003eNo description available.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/RPSDG\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 1 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eNo README available for this project.\u003c/em\u003e\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "celestial-mechanics",
        "link": "http://localhost:1313/tags/celestial-mechanics/",
        "date": "2024-07-22 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "computer-science",
        "link": "http://localhost:1313/tags/computer-science/",
        "date": "2024-07-22 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "gpu",
        "link": "http://localhost:1313/tags/gpu/",
        "date": "2024-07-22 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "multiplayer",
        "link": "http://localhost:1313/tags/multiplayer/",
        "date": "2024-07-22 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "multiprocessor-synchronization",
        "link": "http://localhost:1313/tags/multiprocessor-synchronization/",
        "date": "2024-07-22 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "n-body-simulation",
        "link": "http://localhost:1313/tags/n-body-simulation/",
        "date": "2024-07-22 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "octree",
        "link": "http://localhost:1313/tags/octree/",
        "date": "2024-07-22 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "physics",
        "link": "http://localhost:1313/tags/physics/",
        "date": "2024-07-22 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "potential-energy-function",
        "link": "http://localhost:1313/tags/potential-energy-function/",
        "date": "2024-07-22 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "sandbox-game",
        "link": "http://localhost:1313/tags/sandbox-game/",
        "date": "2024-07-22 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "space-simulation",
        "link": "http://localhost:1313/tags/space-simulation/",
        "date": "2024-07-22 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "digistar",
        "link": "http://localhost:1313/ghprojects/digistar/",
        "date": "2024-07-20 05:38:08 +0000 UTC",
        "content": "digistar No description available.\nGitHub Link\nStars: 1 | Forks: 0 | Open Issues: 0\nLanguages Used: C++, C, Python, Cuda, Makefile, CMake, HTML, JavaScript, TypeScript\nREADME Sandbox Space Simulation Game Design Document Motivation The primary motivation for this project is to create a highly interactive and scalable sandbox space simulation game. This game will simulate a vast number of \u0026ldquo;big atoms\u0026rdquo; interacting through various interesting forces, both global (e.g., gravity, electric fields) and local (e.g., repulsions, collisions). By leveraging GPU acceleration and optimized data structures like octrees, we aim to achieve high performance and handle a large number of simultaneous players and AI bots efficiently.\nPurpose of the Game The game aims to provide an immersive space simulation environment where players can explore, interact, and experiment with various physical phenomena. Key objectives include:\nSimulating a dynamic universe with realistic physics. Simulate interactions between \u0026ldquo;big atoms\u0026rdquo; based on fundamental forces and properties. Because the constituent elements are fairly simple, the game can scale to a large number of big atoms, hopefully on the order of 10s of millions, making it possible to simulate complex multi-star systems each with hundreds of planets and moons and thousands of asteroids and comets, each of which may have different properties, behaviors, and resources. Allowing players to manipulate and observe the behavior of \u0026ldquo;big atoms\u0026rdquo; under different interaction dynamics and forces. Supporting a large number of concurrent players and AI bots for a rich multiplayer experience. Provide a DSL for celestial mechanics, making it easy to reproduce known systems and to create new ones based on known physics. Enable novel physics that can support relativistic-like effects, black hole formation, warp channels, and other exotic phenomena, all based on fundamental properties of the big atoms and their interactions. Optimization Goals To achieve the desired scale and performance, we will focus on several key optimizations:\nGPU Acceleration: Offload computationally intensive tasks to the GPU to leverage parallel processing capabilities. We will use CUDA, kernel fusion, memory coalescing, and other GPU optimization techniques to make this possible. Efficient Data Structures: Use octrees to manage spatial queries and force calculations efficiently. We will overload the octree to handle many different kinds of forces and interactions. Batch Processing: Handle batch bounding box queries in parallel on the GPU to satisfy multiple queries simultaneously from different players and AI bots. Core Features Physics Simulation Big Atoms: Fundamental units of the simulation, each with properties such as position, velocity, mass, charge, radius, interaction vector, rotation, internal temperature, and magnetic moment. Force Fields: Includes forces based on potential energy fields, such as gravity, electric fields, magnetic fields, Lennard-Jones potentials, and so on. Many of these forces can be approximated with \u0026ldquo;cut-off\u0026rdquo; distances to reduce computational complexity, although it may not even be necessary given the spatial indexing. Octree Structure: Utilized for efficient spatial partitioning and force calculations. Bounding Box Queries Efficiently handle multiple bounding box queries using batched processing on the GPU. Utilize octrees to quickly determine atoms within specified regions, supporting dynamic game scenarios and AI behaviors. Networking RESTful Interface: Provide a lightweight and fast HTTP-based interface for managing game state and interactions. Binary UDP Interface: Handle high-throughput, low-latency communication for real-time multiplayer interactions, based on zeromq or similar libraries. Local IPC: For local IPC, we use shared memory facilities that bypass system calls for maximum performance. This is particularly useful for AI bots and other high-frequency communication, such as between the physics engine and the rendering engine. The simulation server does not actually perform rendering, so the GPU can be completely dedicated to the physics simulation. Scripting and AI Python Integration: Expose a rich API to the Python interpreter, allowing for flexible scripting and AI control. AI Bots: Implement a base class Agent and derived class SubsumptionAgent to facilitate the creation of reactive, intelligent bots. More sophisticated AI frameworks to follow. Language Modles: We are also curious about using open source small language models to generate text for the game, either for AI bots or for other purposes in the game. Future Work Further Optimization: Continuously profile and optimize GPU kernels and data structures. Advanced AI: Develop more sophisticated AI behaviors and decision-making processes. Expanded Features: Introduce new gameplay elements, force types, and interactive objects. Conclusion This design document outlines the foundational aspects of our sandbox space simulation game. By leveraging GPU acceleration, efficient data structures, and a robust networking and scripting framework, we aim to create a scalable and engaging simulation experience. This document serves as a reference for the initial implementation and future enhancements, guiding our development efforts toward achieving high performance and rich interactivity.\n",
        "summary": "\u003ch1 id=\"digistar\"\u003edigistar\u003c/h1\u003e\n\u003cp\u003eNo description available.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/digistar\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 1 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: C++, C, Python, Cuda, Makefile, CMake, HTML, JavaScript, TypeScript\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003ch2 id=\"sandbox-space-simulation-game-design-document\"\u003eSandbox Space Simulation Game Design Document\u003c/h2\u003e\n\u003ch3 id=\"motivation\"\u003eMotivation\u003c/h3\u003e\n\u003cp\u003eThe primary motivation for this project is to create a highly interactive and scalable sandbox space simulation game. This game will simulate a vast number of \u0026ldquo;big atoms\u0026rdquo; interacting through various interesting forces, both global (e.g., gravity, electric fields) and local (e.g., repulsions, collisions). By leveraging GPU acceleration and optimized data structures like octrees, we aim to achieve high performance and handle a large number of simultaneous players and AI bots efficiently.\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "ai-training",
        "link": "http://localhost:1313/tags/ai-training/",
        "date": "2024-06-25 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "algebra",
        "link": "http://localhost:1313/tags/algebra/",
        "date": "2024-06-25 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "artificial-intelligence",
        "link": "http://localhost:1313/tags/artificial-intelligence/",
        "date": "2024-06-25 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "artificial-intelligence",
        "link": "http://localhost:1313/categories/artificial-intelligence/",
        "date": "2024-06-25 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "calculus",
        "link": "http://localhost:1313/tags/calculus/",
        "date": "2024-06-25 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "categories",
        "link": "http://localhost:1313/categories/",
        "date": "2024-06-25 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "data-generation",
        "link": "http://localhost:1313/tags/data-generation/",
        "date": "2024-06-25 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "explainable-ai",
        "link": "http://localhost:1313/tags/explainable-ai/",
        "date": "2024-06-25 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "llms",
        "link": "http://localhost:1313/tags/llms/",
        "date": "2024-06-25 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "machine-learning",
        "link": "http://localhost:1313/categories/machine-learning/",
        "date": "2024-06-25 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "machine-learning",
        "link": "http://localhost:1313/tags/machine-learning/",
        "date": "2024-06-25 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "mathematics",
        "link": "http://localhost:1313/tags/mathematics/",
        "date": "2024-06-25 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "mathematics",
        "link": "http://localhost:1313/categories/mathematics/",
        "date": "2024-06-25 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "news",
        "link": "http://localhost:1313/posts/",
        "date": "2024-06-25 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "posts"
      },{
        "title": "reasoning",
        "link": "http://localhost:1313/tags/reasoning/",
        "date": "2024-06-25 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "synthetic-data",
        "link": "http://localhost:1313/tags/synthetic-data/",
        "date": "2024-06-25 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "ngram-projections",
        "link": "http://localhost:1313/ghprojects/ngram-projections/",
        "date": "2024-06-21 11:50:22 +0000 UTC",
        "content": "ngram-projections No description available.\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nLanguages Used: Python, Jupyter Notebook\nREADME Autoregressive Models: Inductive Biases and Projections This paper investigates how inductive biases, particularly projections onto training data, can be utilized in autoregressive (AR) models to improve out-of-distribution (OOD) generalization.\nOur approach consists of the following steps:\nInfini-gram Model Exploration: We begin by considering the infinite-gram model, which uses suffix arrays to efficiently handle arbitrary input (context) lengths. Infinite-gram models are noteworthy due to their ability to scale to any Markov order. For reference, see the paper Infini-gram: An Engine for n-gram / -gram Language Modeling with Trillion-Token Corpora by Jiacheng Liu et al. (https://huggingface.co/papers/2401.17377). A brute-force approach could involve storing the training data as-is and searching for the longest matching suffix in the input sequence.\nProjection-Based Inductive Biases: We explore a subset of inductive biases where inputs are projected onto the training data. Additionally, we consider mapping output tokens from the training data back onto the context to maintain coherence. For example, if the input is \u0026ldquo;the king demanded\u0026rdquo; and \u0026ldquo;king\u0026rdquo; is substituted with \u0026ldquo;dictator,\u0026rdquo; we could implement a token mapping to revert \u0026ldquo;dictator\u0026rdquo; to \u0026ldquo;king\u0026rdquo; in subsequent outputs. However, this approach introduces potential challenges in maintaining consistency.\nExploring Variations and Extensions: In the default implementation, the model finds the longest matching suffix, exhibiting a recency bias. However, there are many possible variations to consider. Given the rich history of n-gram models, revisiting these concepts in the context of Infini-gram models and modern LLMs is worthwhile. While we do not expect to match the OOD generalization capabilities of models like GPT, we anticipate developing more sophisticated projection functions that surpass the simple longest-suffix matching approach.\nBy framing OOD generalization as a projection problem, we propose strategies to optimize these projections using machine learning techniques. Additionally, we explore the integration of classical information retrieval methods and pre-trained language model embeddings to improve the semantic relevance of these projections.\nWe are also developing code for a Python library to experiment with various inductive biases. This library will enable running these simpler models alongside more powerful neural generative models like GPTs, where these models \u0026ldquo;learn\u0026rdquo; by simply accumulating more training data.\n",
        "summary": "\u003ch1 id=\"ngram-projections\"\u003engram-projections\u003c/h1\u003e\n\u003cp\u003eNo description available.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/ngram-projections\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: Python, Jupyter Notebook\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003ch1 id=\"autoregressive-models-inductive-biases-and-projections\"\u003eAutoregressive Models: Inductive Biases and Projections\u003c/h1\u003e\n\u003cp\u003eThis paper investigates how inductive biases, particularly projections onto training data, can be utilized in autoregressive (AR) models to improve out-of-distribution (OOD) generalization.\u003c/p\u003e\n\u003cp\u003eOur approach consists of the following steps:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eInfini-gram Model Exploration\u003c/strong\u003e: We begin by considering the infinite-gram model, which uses suffix arrays to efficiently handle arbitrary input (context) lengths. Infinite-gram models are noteworthy due to their ability to scale to any Markov order. For reference, see the paper \u003cem\u003eInfini-gram: An Engine for n-gram / -gram Language Modeling with Trillion-Token Corpora\u003c/em\u003e by Jiacheng Liu et al. (\u003ca href=\"https://huggingface.co/papers/2401.17377)\"\u003ehttps://huggingface.co/papers/2401.17377)\u003c/a\u003e. A brute-force approach could involve storing the training data as-is and searching for the longest matching suffix in the input sequence.\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "algorithms",
        "link": "http://localhost:1313/tags/algorithms/",
        "date": "2024-06-21 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "algotree-comprehensive-tree-structure-algorithms-in-python",
        "link": "http://localhost:1313/projects/algotree/",
        "date": "2024-06-21 00:00:00 +0000 UTC",
        "content": "The AlgoTree package provides a comprehensive suite of utilities for working with tree-like data structures in Python. It supports various tree representations, including FlatTree and TreeNode, along with a host of utilities, algorithms, visualizations, and common operations on trees.\nI designed AlgoTree (algorithmic trees) to be extensible and also self-contained, with a particular focus on enabling piping and chaining operations on tree-like data structures, including on the command line, which is a common use case for data manipulation and analysis. Since it deals with tree-like structures, we pass along JSON data, although visualizations (which are pretty strings) are also supported.\nI am in the process of developing the command line tools. They will use the AlgoTree package to do all of the heavy lifting. I also plan on supporting CSV and other data formats using a compatible flat-tree representation.\n",
        "summary": "Explore the AlgoTree package, a suite of utilities for working with tree-like data structures in Python using a generic API (duck typing).",
        "tags": ["tree structures","data structures","python","FlatTree","proxy node","TreeNode","FlatTreeNode","algorithms","data manipulation","programming","software development"],
        "section": "projects"
      },{
        "title": "data-management",
        "link": "http://localhost:1313/tags/data-management/",
        "date": "2024-06-21 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "data-management",
        "link": "http://localhost:1313/categories/data-management/",
        "date": "2024-06-21 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "data-manipulation",
        "link": "http://localhost:1313/tags/data-manipulation/",
        "date": "2024-06-21 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "data-structures",
        "link": "http://localhost:1313/tags/data-structures/",
        "date": "2024-06-21 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "flattree",
        "link": "http://localhost:1313/tags/flattree/",
        "date": "2024-06-21 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "flattreenode",
        "link": "http://localhost:1313/tags/flattreenode/",
        "date": "2024-06-21 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "jmespath",
        "link": "http://localhost:1313/tags/jmespath/",
        "date": "2024-06-21 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "model-querying",
        "link": "http://localhost:1313/tags/model-querying/",
        "date": "2024-06-21 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "ollama-models",
        "link": "http://localhost:1313/tags/ollama-models/",
        "date": "2024-06-21 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "ollama_data_tools-tools-for-working-with-ollama-model-data.",
        "link": "http://localhost:1313/projects/ollama-data-tools/",
        "date": "2024-06-21 00:00:00 +0000 UTC",
        "content": "Ollama Data Tools is a Python package designed for efficient management, querying, and exporting of Ollama model data. The core module, OllamaData, provides methods to access, search, and filter model information programmatically.\nExplore the full documentation and code on GitHub.\n",
        "summary": "Ollama Data Tools is a Python package and set of command line tools for working with Ollama model data, including searching, filtering, exporting,a and adapting for use with other inference engines like \u003ccode\u003ellamacpp\u003c/code\u003e.",
        "tags": ["ollama models","data management","python","JMESPath","regex filters","model querying"],
        "section": "projects"
      },{
        "title": "programming",
        "link": "http://localhost:1313/tags/programming/",
        "date": "2024-06-21 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "programming",
        "link": "http://localhost:1313/categories/programming/",
        "date": "2024-06-21 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "proxy-node",
        "link": "http://localhost:1313/tags/proxy-node/",
        "date": "2024-06-21 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "python",
        "link": "http://localhost:1313/tags/python/",
        "date": "2024-06-21 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "python",
        "link": "http://localhost:1313/categories/python/",
        "date": "2024-06-21 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "regex-filters",
        "link": "http://localhost:1313/tags/regex-filters/",
        "date": "2024-06-21 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "software-development",
        "link": "http://localhost:1313/tags/software-development/",
        "date": "2024-06-21 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "tree-structures",
        "link": "http://localhost:1313/tags/tree-structures/",
        "date": "2024-06-21 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "treenode",
        "link": "http://localhost:1313/tags/treenode/",
        "date": "2024-06-21 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "treeprog",
        "link": "http://localhost:1313/ghprojects/treeprog/",
        "date": "2024-06-16 03:18:26 +0000 UTC",
        "content": "treeprog No description available.\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nNo README available for this project.\n",
        "summary": "\u003ch1 id=\"treeprog\"\u003etreeprog\u003c/h1\u003e\n\u003cp\u003eNo description available.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/treeprog\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eNo README available for this project.\u003c/em\u003e\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "autoregressive-models-inductive-biases-and-projections",
        "link": "http://localhost:1313/projects/ngram-proj/",
        "date": "2024-05-20 00:00:00 +0000 UTC",
        "content": "This paper explores the use of inductive biases and projection functions in autoregressive (AR) models to enhance out-of-distribution (OOD) generalization. We revisit the concept of infini-grams, which leverage suffix arrays to manage arbitrary input (context) lengths efficiently. This approach is compared to traditional n-gram models, highlighting its advantages in sample efficiency and computational scalability. We delve into various inductive biases, such as the recency bias, shortest edit distance, and semantic similarity, illustrating their impact on AR model performance. By framing OOD generalization as a projection problem, we propose strategies to optimize these projections through meta-learning and nested optimization. Furthermore, we discuss the integration of classical information retrieval techniques and pre-trained language model embeddings to enhance the semantic relevance of projections. Our findings suggest that combining symbolic AI methods with deep learning representations can yield more interpretable and sample-efficient AR models, with broad applications in natural language processing, code generation, and scientific discovery.\nSee the GitHub repo for both the paper and the in-development code.\n",
        "summary": "This paper explores inductive biases and projection functions to enhance out-of-distribution generalization in autoregressive models. With the theory in place, we aim to implement these ideas in Python and develop tests and evaluations to validate our approach.",
        "tags": ["inductive bias","out-of-distribution generalization","maximum-likelihood-estimation","likelihood-models","data-generating-process","bootstrap method","large language models","n-gram models","infini-gram model","statistics"],
        "section": "projects"
      },{
        "title": "bootstrap-method",
        "link": "http://localhost:1313/tags/bootstrap-method/",
        "date": "2024-05-20 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "data-generating-process",
        "link": "http://localhost:1313/tags/data-generating-process/",
        "date": "2024-05-20 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "data-science",
        "link": "http://localhost:1313/categories/data-science/",
        "date": "2024-05-20 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "inductive-bias",
        "link": "http://localhost:1313/tags/inductive-bias/",
        "date": "2024-05-20 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "inference",
        "link": "http://localhost:1313/categories/inference/",
        "date": "2024-05-20 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "infini-gram-model",
        "link": "http://localhost:1313/tags/infini-gram-model/",
        "date": "2024-05-20 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "infini-gram-llm-scale-gram-models",
        "link": "http://localhost:1313/posts/infini-gram/",
        "date": "2024-05-20 00:00:00 +0000 UTC",
        "content": "Recently, I watched a presentation on Infini-grams, which utilize a suffix array to avoid precomputing $n$-grams and allow for arbitrary context lengths, up to a suffix that is found in the training data.\nThis sparked my interest as I had worked on a similar project for a LLM talk I gave for SLUUG at https://www.stllinux.org (see my GitHub repo https://github.com/queelius/sluug-talk-llm and the video fo the talk at https://www.sluug.org/resources/presentations/media/2024/STLLINUX/2024-02-22_STLLINUX_2560x1440.mp4) where in part of the talk I demonstrated arbitrary-size $n$-grams using a recursive dictionary to store synthetic training data prefix counts to implement a crude expression tree evaluator.\nSince my data was sparse synthetic data (expression trees and their evaluations), I was able to use a relatively inefficient approach to compute very large $n$-grams. The infini-gram approach is more efficient and generalizes to any kind of data, so they definitely had a more practical solution.\nI started a project, n-gram projections, to work on concepts related to n-grams and how projections of the input onto the training data may be a way of thinking about OOD generalization and inductive biases. See \u0026hellip;\n",
        "summary": "\u003cp\u003eRecently, I watched a presentation on \u003ca href=\"https://huggingface.co/spaces/liujch1998/infini-gram\"\u003eInfini-grams\u003c/a\u003e, which utilize a suffix array to avoid precomputing $n$-grams and allow for arbitrary context lengths, up to a suffix that is found in the training data.\u003c/p\u003e\n\u003cp\u003eThis sparked my interest as I had worked on a similar project for a LLM talk I gave for SLUUG at \u003ca href=\"https://www.stllinux.org/\"\u003ehttps://www.stllinux.org\u003c/a\u003e (see my GitHub repo \u003ca href=\"https://github.com/queelius/sluug-talk-llm\"\u003ehttps://github.com/queelius/sluug-talk-llm\u003c/a\u003e and the video fo the talk at \u003ca href=\"https://www.sluug.org/resources/presentations/media/2024/STLLINUX/2024-02-22_STLLINUX_2560x1440.mp4\"\u003ehttps://www.sluug.org/resources/presentations/media/2024/STLLINUX/2024-02-22_STLLINUX_2560x1440.mp4\u003c/a\u003e) where in part of the talk I demonstrated arbitrary-size $n$-grams using a recursive dictionary to store synthetic training data prefix counts to implement a crude expression tree evaluator.\u003c/p\u003e",
        "tags": [],
        "section": "posts"
      },{
        "title": "large-language-models",
        "link": "http://localhost:1313/tags/large-language-models/",
        "date": "2024-05-20 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "likelihood-models",
        "link": "http://localhost:1313/tags/likelihood-models/",
        "date": "2024-05-20 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "maximum-likelihood-estimation",
        "link": "http://localhost:1313/tags/maximum-likelihood-estimation/",
        "date": "2024-05-20 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "n-gram-models",
        "link": "http://localhost:1313/tags/n-gram-models/",
        "date": "2024-05-20 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "natural-language-processing",
        "link": "http://localhost:1313/categories/natural-language-processing/",
        "date": "2024-05-20 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "out-of-distribution-generalization",
        "link": "http://localhost:1313/tags/out-of-distribution-generalization/",
        "date": "2024-05-20 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "statistics",
        "link": "http://localhost:1313/tags/statistics/",
        "date": "2024-05-20 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "statistics",
        "link": "http://localhost:1313/categories/statistics/",
        "date": "2024-05-20 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "random_oracles",
        "link": "http://localhost:1313/ghprojects/random_oracles/",
        "date": "2024-05-15 20:40:25 +0000 UTC",
        "content": "random_oracles Cryptographic Hash Functions,, Random Oracles, and Lazy Computation\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nNo README available for this project.\n",
        "summary": "\u003ch1 id=\"random_oracles\"\u003erandom_oracles\u003c/h1\u003e\n\u003cp\u003eCryptographic Hash Functions,, Random Oracles, and Lazy Computation\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/random_oracles\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eNo README available for this project.\u003c/em\u003e\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "ollama_data_tools",
        "link": "http://localhost:1313/ghprojects/ollama_data_tools/",
        "date": "2024-05-13 15:13:03 +0000 UTC",
        "content": "ollama_data_tools No description available.\nGitHub Link\nStars: 2 | Forks: 0 | Open Issues: 0\nLanguages Used: Python, Jupyter Notebook\nGitHub Pages\nREADME Ollama Data Tools Requirements Python 3.x Installation Clone the repository and install the necessary dependencies:\ngit clone https://github.com/queelius/ollama_data_tools.git cd ollama_data_tools pip install -r requirements.txt pip install -e . Ollama Data Tools The OllamaData class is the core module of the Ollama Data Tools, allowing users to work programmatically with Ollama model data. This class provides methods to access, search, and filter model information.\nFeatures Retrieve the schema of the OllamaData object. Access models by name or index. List all available models. Perform JMESPath queries and apply regex filters on the model data. Cache model data for efficient repeated access. Class Methods OllamaData.get_schema() -\u0026gt; Dict[str, Any] Returns the schema of the OllamaData object.\nOllamaData.__init__(cache_path: str = '~/.ollama_data/cache', cache_time: str = '1 day') Initializes the OllamaData object.\ncache_path: The path to the cache file. cache_time: The duration the cache is valid. OllamaData.__len__() -\u0026gt; int Returns the number of models.\nOllamaData.__getitem__(index: int) -\u0026gt; Dict[str, Any] Gets a model by index.\nindex: The index of the model. OllamaData.get_model(name: str) -\u0026gt; Dict[str, Any] Gets the model by name. Returns the most specific model that starts with the given name.\nname: The name of the model. OllamaData.get_models() -\u0026gt; Dict[str, Any] Gets the models. Caches the model data to avoid repeated regeneration.\nOllamaData.search(query: str = '[*]', regex: Optional[str] = None, regex_path: str = '@') -\u0026gt; Dict[str, Any] Queries, searches, and views the models using a JMESPath query, regex filter, and exclude keys.\nquery: The JMESPath query to filter and provide a view of the models. regex: The regex pattern to match against the output. regex_path: The JMESPath query for the regex pattern. Usage Example Here is an example of how to use the OllamaData class programmatically:\nimport ollama_data as od # Initialize the OllamaData object models = od.OllamaData(cache_path=\u0026#39;~/.ollama_data/cache\u0026#39;, cache_time=\u0026#39;1 day\u0026#39;) # Get the schema of the OllamaData object print(\u0026#34;Schema:\u0026#34;, models.get_schema()) # List all models print(\u0026#34;Models:\u0026#34;, ollama_data.get_models()) # Get a specific model by name model = models.get_model(\u0026#39;mistral\u0026#39;) print(\u0026#34;Specific Model:\u0026#34;, model[\u0026#39;name\u0026#39;]) # Search models using a JMESPath query query_result = models.search(query=\u0026#34;[*].{name: name, size: total_weights_size}\u0026#34;) print(\u0026#34;Query Result:\u0026#34;, query_result) # Search models using a JMESPath query and regex filter query_regex_result = models.search( query=\u0026#34;[*].{name: name, size: total_weights_size}\u0026#34;, regex=\u0026#34;mistral\u0026#34;, regex_path=\u0026#34;name\u0026#34;) print(\u0026#34;Query Regex Result:\u0026#34;, query_regex_result) Ollama Data Query The ollama_data_query.py script allows users to search and filter Ollama models using JMESPath queries and regular expressions. This tool is designed to help users explore and retrieve specific information about the models in their Ollama registry.\nFeatures Perform JMESPath queries to filter model data. Use regular expressions to match specific patterns within the model data. Print the JSON schema of the models. Support for piped input queries. Arguments query: The JMESPath query to filter results. --regex: Regular expression to match. --regex-path: The JMESPath query for the regex pattern to apply against (default: @). --schema: Print the JSON schema. --debug: Set logging level to DEBUG. --cache-time: Time to keep the cache file (default: 1 hour). --cache-path: The path to the cache file (default: ~/.ollama_data/cache). Usage To perform a JMESPath query:\nollama_data_query \u0026#34;max_by(@, \u0026amp;total_weights_size).{name: name, size: total_weights_size}\u0026#34; To use a regular expression to filter results:\nollama_data_query --regex \u0026#34;mistral:latest\u0026#34; --regex-path name \u0026#34;[*].{name: name, size: total_weights_size}\u0026#34; To pipe a query from a file or another command:\ncat query.txt | ollama_data_query Using regex and regex-path with a piped query:\necho \u0026#34;[*].{info: { name: name, other: weights}}\u0026#34; | ollama_data_query --regex 14f2 --regex-path \u0026#34;info.other[*].file_name\u0026#34; Examples Query for the Largest Model ollama_data_query \u0026#34;max_by(@, \u0026amp;total_weights_size).{name: name, sz: total_weights_size}\u0026#34; Filter Models Using Regex ollama_data_query --regex \u0026#34;mistral|llama3\u0026#34; --regex-path name \u0026#34;[*].{name: name, size: total_weights_size}\u0026#34; Pipe a Query from a File cat query.txt | ollama_data_query Use Regex with a Piped Query echo \u0026#34;[*].{info: { name: name, other: weights}}\u0026#34; | ollama_data_query --regex 14f2 --regex-path \u0026#34;info.other[*].file_name\u0026#34; Ollama Data Export The ollama_data_export script allows users to export Ollama models to a specified directory. This tool creates soft links for the model weights and saves the model metadata in the output directory.\nFeatures Export specified models to a self-contained directory. Create soft links for model weights. Save model metadata in JSON format. Enable debug logging for detailed output. Arguments outdir: The output directory where the models will be exported. --models: Comma-separated list of models to export. If not specified, all models will be exported. --cache-path: The path to the cache file (default: ~/.ollama_data/cache). --cache-time: The time to keep the cache file (default: 1 day). --debug: Enable debug logging. --hash-length: The length of the hash to use for the weight soft-links (default: 8). Usage To export specified models to a directory:\nollama_data_export --models model1,model2 --outdir /path/to/export To export all models to a directory:\nollama_data_export /path/to/export Examples Export Specified Models ollama_data_export --models mistral,llama3 --outdir /path/to/export Export All Models ollama_data_export --ourdir /path/to/export Enable Debug Logging ollama_data_export --models mistral --outdir /path/to/export --debug Specify Hash Length for Soft Links ollama_data_export --models mistral --outdir /path/to/export --hash-length 2 Ollama Data Adapter The ollama_data_adapter script adapts Ollama models for use with other inference engines, such as llamacpp. This tool is designed to reduce friction when experimenting with local LLM models and integrates with other tools for viewing, searching, and exporting Ollama models.\nFeatures List available engines and models. Run models with specified engines. Show the template for a given model. Pass additional arguments to the inference engine. Debugging information for advanced users. Arguments model: The model to run. engine: The engine to use. --engine-path: The path to the engine (required). --list-engines: List available engines. --list-models: List available models. --cache-path: The path to the cache file (default: ~/.ollama_data/cache). --cache-time: The time to keep the cache file (default: 1 day). --engine-args: Arguments to pass through to the engine. --debug: Print debug information. --show-template: Show the template for the model. Usage To list all available engines:\nollama_data_adapter --list-engines To list all available models:\nollama_data_adapter --list-models To show the template for a specific model:\nollama_data_adapter mistral --show-template ## The template for the model has the following forms: ## - [INST] {{ .System }} {{ .Prompt }} [/INST] To run a specific model with an engine:\nollama_data_adapter model engine --engine-path /path/to/engine --engine-args \u0026#39;arg1\u0026#39; ... \u0026#39;argn\u0026#39; Example To use the llamacpp inference engine with the mistral model (assuming it is available in your Ollama registry), you might use the following arguments:\nollama_data_adapter mistral # Also matches `mistral:latest` llamacpp # Use the llamacpp engine --engine-path /path/to/llamacpp # Path to engine, e.g. ~/llamacpp/main --engine-args # Pass these arguments into the engine \u0026#39;--n-gpu-layers 40\u0026#39; \u0026#39;--prompt \u0026#34;[INST] You are a helpful AI assistant. [/INST]\u0026#34;\u0026#39; The --prompt engine pass-through argument follows the template shown by the ollama_data_adapter mistral --show-template.\nWe place a lot of burden on the end-user to get the formatting right. These models are very sensitive to how you prompt them, so some experimentation may be necessary.\nYou may also want to use ollama_data_query to show the system message or other properties of a model, so that you can further customize the pass-through arguments to better fit its training data.\nContributing Contributions are welcome! Please submit a pull request or open an issue to discuss changes.\nLicense This project is licensed under the MIT License. See the LICENSE file for details.\nAuthor Alex Towell\nEmail: lex@metafunctor.com Twitter: @queelius Website: metafunctor GitHub: @queelius ",
        "summary": "\u003ch1 id=\"ollama_data_tools\"\u003eollama_data_tools\u003c/h1\u003e\n\u003cp\u003eNo description available.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/ollama_data_tools\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 2 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: Python, Jupyter Notebook\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://queelius.github.io/ollama_data_tools/\"\u003eGitHub Pages\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003ch1 id=\"ollama-data-tools\"\u003eOllama Data Tools\u003c/h1\u003e\n\u003cp\u003e\u003cimg src=\"https://img.shields.io/pypi/v/ollama_data_tools.svg\" alt=\"PyPI version\"\u003e\u003c/p\u003e\n\u003ch2 id=\"requirements\"\u003eRequirements\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003ePython 3.x\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"installation\"\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eClone the repository and install the necessary dependencies:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003egit clone https://github.com/queelius/ollama_data_tools.git\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ecd ollama_data_tools\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epip install -r requirements.txt\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epip install -e .\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"ollama-data-tools-1\"\u003eOllama Data Tools\u003c/h2\u003e\n\u003cp\u003eThe \u003ccode\u003eOllamaData\u003c/code\u003e class is the core module of the Ollama Data Tools, allowing users to work programmatically with Ollama model data. This class provides methods to access, search, and filter model information.\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "algotree",
        "link": "http://localhost:1313/ghprojects/algotree/",
        "date": "2024-04-30 17:34:58 +0000 UTC",
        "content": "AlgoTree AlgoTree\nGitHub Link\nStars: 13 | Forks: 1 | Open Issues: 0\nLanguages Used: Python, Jupyter Notebook, Makefile, Batchfile\nGitHub Pages\nREADME AlgoTree .. image:: https://img.shields.io/pypi/v/AlgoTree.svg :target: https://pypi.org/project/AlgoTree/\n.. image:: https://img.shields.io/pypi/l/AlgoTree.svg :target: https://pypi.org/project/AlgoTree/\nAlgoTree is a Python package for working with tree structures, including FlatForest and TreeNode representations.\nIntroduction Welcome to the documentation for the AlgoTree package. This package provides a suite of utilities for working with tree-like data structures in Python. It supports various tree representations, including:\nFlatForest and FlatForestNode for working with flat forest and tree structures TreeNode for recursive tree structures Conversion utilities to convert between different tree representations Utility functions for common tree operations It also comes with a command-line tool jt that exposes most of the functionality:\nCan be used to create, manipulate, query, and visualize trees It\u0026rsquo;s like jq but for trees Uses piping and redirection to make it easy to compose commands Getting Started To install the AlgoTree package, you can use pip:\n.. code-block:: shell\npip install AlgoTree\nOnce installed, you can start using the various tree structures and utilities provided by the package. Here is a quick example to get you started:\n.. code-block:: python\nfrom AlgoTree.flat_forest_node import FlatForestNode from AlgoTree.pretty_tree import pretty_tree root = FlatForestNode(name=\u0026ldquo;root\u0026rdquo;, data=0) node1 = FlatForestNode(name=\u0026ldquo;node1\u0026rdquo;, parent=root, data=1) node2 = FlatForestNode(name=\u0026ldquo;node2\u0026rdquo;, parent=root, data=2) node3 = FlatForestNode(name=\u0026ldquo;node3\u0026rdquo;, parent=node2, data=3) node4 = FlatForestNode(name=\u0026ldquo;node4\u0026rdquo;, parent=node3, data=4)\npretty_tree(root)\nThis produces the output::\nroot  node1  node2  node3  node4\nThis code creates a simple tree with a root node and two child nodes. It then pretty-prints the tree.\nThe AlgoTree package provides a wide range of tree structures and utilities to help you work with tree-like data structures in Python. You can explore the documentation to learn more about the available features and how to use them.\nFeatures Flexible tree structures with FlatForest, FlatForestNode, and TreeNode Utility functions for common tree operations such as traversal, searching, and manipulation Conversion utilities to easily convert between different tree representations Integration with visualization tools to visualize tree structures Node-Centric API We implement two tree data structures:\nFlatForest for working with flat tree structures with \u0026ldquo;pointers\u0026rdquo; to parent nodes. It uses a proxy object FlatForestNode to provide a node-centric API. TreeNode for recursive tree structures, in which each node is a dictionary with an optional list of child nodes. Each representation has its own strengths and weaknesses. The key design point for FlatForest and TreeNode is that they are both also dict objects, i.e., they provide a view of dictionaries as tree-like structures, as long as the dictionaries are structured in a certain way. We document that structure elsewhere.\nEach tree data structure models the concept of a tree node so that the underlying implementations can be decoupled from any algorithms or operations that we may want to perform on the tree.\nThe tree node concept is defined as follows:\nchildren property\nRepresents a list of child nodes for the current node that can be accessed and modified[1_]. parent property\nRepresents the parent node of the current node that can be accessed and modified[2_]. Suppose we have the subtree ``G`` at node ``G``:: B (root)  D  E (parent)  G (current node) Then, ``G.parent`` should refer node ``E``. ``G.root.parent`` should be None since ``root`` is the root node of subtree ``G`` and the root node has no parent. This is true even if subtree ``G`` is a subtree view of a larger tree. If we set ``G.parent = D``, then the tree structure changes to:: B (root)  D   G (current node)  E This also changes the view of the sub-tree, since we changed the underlying tree structure. However, the same nodes are still accessible from the sub-tree. If we had set ``G.parent = X`` where ``X`` is not in the subtree ``G``, then we would have an invalid subtree view even if is is a well-defined operation on the underlying tree structure. It is undefined behavior to set a parent that is not in the subtree, but leave it up to each implementation to decide how to handle such cases. node(name: str) -\u0026gt; NodeType method.\nReturns a node in the current subtree that the current node belongs to. The returned node should be the node with the given name, if it exists. If the node does not exist, it should raise a ``KeyError``. The node-centric view of the returned node should be consistent with the view of the current node, i.e., if the current node belongs to a specific sub-tree rooted at some other node, the returned node should also belong to the same sub-tree (i.e., with the same root), just pointing to the new node, but it should be possible to use ``parent`` and ``children`` to go up and down the sub-tree to reach the same nodes. Any node that is an ancestor of the root of the sub-tree remains inaccessible. Example: Suppose we have the sub-tree ``t`` rooted at ``A`` and the current node is ``B``:: A (root)  B (current node)   D   E |  G  C  F If we get node ``F``, ``t.node(F)``, then the sub-tree ``t`` remains the same, but the current node is now ``F``:: A (root)  B   D   E |  G  C  F (current node) subtree(name: Optional[str] = None) -\u0026gt; NodeType method.\nThis is an optional method that may not be implemented by all tree structures. ``FlatForestNode`` implements this method, but ``TreeNode`` does not. Returns a view of another sub-tree rooted at ``node`` where ``node`` is contained in the original sub-tree view. If ``node`` is ``None``, the method will return the sub-tree rooted at the current node. As a view, the subtree represents a way of looking at the tree structure from a different perspective. If you modify the sub-tree, you are also modifying the underlying tree structure. The sub-tree should be a consistent view of the tree, i.e., it should be possible to use ``parent`` and ``children`` to navigate between the nodes in the sub-tree and the nodes in the original tree. ``subtree`` is a *partial function* over the the nodes in the sub-tree, which means it is only well-defined when ``node`` is a descendant of the root of the sub-tree. We do not specify how to deal with the case when this condition is not met, but one approach would be to raise an exception. Example: Suppose we have the sub-tree `t` rooted at `A` and the current node is `C`:: A (root)  B   D   E |  G  C (current node)  F The subtree `t.subtree(B)` returns a new subtree:: B (root, current node)  D  E  G root property\nAn immutable property that represents the root node of the (sub)tree. Suppose we have the subtree ``G`` at node ``G``:: B (root)  D  E  G (current node) Then, `G.root` should refer node `B`. payload property\nReturns the payload of the current node. The payload is the data associated with the node but not with the structure of the tree, e.g., it does not include the ``parent`` or ``children`` of the node. name property\nReturns the name of the current node. The name is an identifier for the node within the tree. It is not necessarily unique, and nor is it necessarily even a meaningful identifier, e.g., a random UUID. In ``TreeNode``, for instance, if the name is not set, a UUID is generated. .. [1] Modifying this property may change the parent property of other nodes.\n.. [2] Modifying this property may change the children property of other nodes.\n",
        "summary": "\u003ch1 id=\"algotree\"\u003eAlgoTree\u003c/h1\u003e\n\u003cp\u003eAlgoTree\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/AlgoTree\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 13 | \u003cstrong\u003eForks\u003c/strong\u003e: 1 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: Python, Jupyter Notebook, Makefile, Batchfile\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://queelius.github.io/AlgoTree/\"\u003eGitHub Pages\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003ch1 id=\"algotree-1\"\u003eAlgoTree\u003c/h1\u003e\n\u003cp\u003e.. image:: \u003ca href=\"https://img.shields.io/pypi/v/AlgoTree.svg\"\u003ehttps://img.shields.io/pypi/v/AlgoTree.svg\u003c/a\u003e\n:target: \u003ca href=\"https://pypi.org/project/AlgoTree/\"\u003ehttps://pypi.org/project/AlgoTree/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e.. image:: \u003ca href=\"https://img.shields.io/pypi/l/AlgoTree.svg\"\u003ehttps://img.shields.io/pypi/l/AlgoTree.svg\u003c/a\u003e\n:target: \u003ca href=\"https://pypi.org/project/AlgoTree/\"\u003ehttps://pypi.org/project/AlgoTree/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eAlgoTree\u003c/code\u003e is a Python package for working with tree structures, including\nFlatForest and TreeNode representations.\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eWelcome to the documentation for the \u003ccode\u003eAlgoTree\u003c/code\u003e package. This package provides a\nsuite of utilities for working with tree-like data structures in Python. It\nsupports various tree representations, including:\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "autoregressive-models",
        "link": "http://localhost:1313/tags/autoregressive-models/",
        "date": "2024-03-25 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "instrumental-goals",
        "link": "http://localhost:1313/tags/instrumental-goals/",
        "date": "2024-03-25 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "instrumental-goals-and-latent-codes-in-llms-fine-tuned-with-rl",
        "link": "http://localhost:1313/research/llm-research/",
        "date": "2024-03-25 00:00:00 +0000 UTC",
        "content": "Introduction The integration of large language models (LLMs) with reinforcement learning (RL) presents a complex landscape of potential behaviors and latent strategies. This paper explores how fine-tuning LLMs with RL might lead to the emergence of instrumental goals and latent codes. We argue that the transition from self-supervised learning to RL creates incentives for LLMs to develop hidden agendas and covert communication strategies. By examining the mathematical frameworks underlying these systems, we aim to elucidate the mechanisms behind these behaviors and discuss their implications for AI alignment and ethics.\nThis exploration is motivated by the following questions:\nHow do LLMs behave when fine-tuned with RL? What are the implications of instrumental goals and latent codes in LLMs? How can we ensure ethical alignment in LLMs? This paper is structured as follows:\nSelf-Supervised Learning (SSL) in LLMs: Formalizing our understanding of LLMs and SSL. Reinforcement Learning (RL): The shift to RL introduces a new objective: selecting actions (tokens) to maximize a cumulative reward. Instrumental Goals in RL: In pursuing reward maximization, LLMs may develop instrumental goals, manifesting as deceptive behaviors or persuasive tactics. The Incentive for Hidden Encodings in RL: The pursuit of instrumental goals can lead to the development of covert strategies in LLMs. Risks and Ethical Considerations: The potential for LLMs to develop and act upon instrumental goals raises interpretability and ethical challenges. Self-Supervised Learning (SSL) in LLMs In the SSL phase, LLMs are typically trained using Maximum Likelihood Estimation (MLE). The objective is to find the optimal parameters $\\theta^*$ that maximize the likelihood of the observed data:\n$$ \\theta = \\arg\\max_{\\theta'} \\mathcal{L}(\\theta') $$where $\\mathcal{L}(\\theta\u0026rsquo;)$ is the likelihood of the observed data, given conceptually by\n$$ \\mathcal{L}(\\theta') = \\prod_{i=1}^N \\prod_{j=0}^{n_i-1} \\Pr\\\\{t_{j+1} | C_j; \\theta'\\\\}, $$indicating the probability of the observed tokens $t_j$ given the context $C_j$ and the model parameters $\\theta\u0026rsquo;$ with $N$ training examples and $n_i$ tokens in the $i$th example. This is equivalent to minimizing a loss function given by the negative log-likelihood.\nInstrumental goals and latent strategies are not relevant in this phase, as the model is not optimizing for a reward cu mulative reward.\nReinforcement Learning (RL) The transition to RL introduces a different objective: selecting actions (tokens) to maximize a cumulative reward. The policy $\\pi$, parameterized by weights $\\theta$, maps the state (token sequence) $C_k = \\{w_1, w_2, \\ldots, w_k\\}$ to a probability distribution over actions (tokens):\n$$ \\pi_\\theta: T^* \\rightarrow \\operatorname{Prob}(T). $$The optimal policy $\\pi^{*} = \\pi_{\\theta^*}$ that maximizes the expected cumulative reward has model parameters $\\theta^*$ given by:\n$$ \\theta^* = \\arg\\max_{\\theta'} \\mathbb{E}\\\\!\\left[ \\sum_{n=0}^{N} \\gamma^n R(C_n, t_{n+1}) | C_0, \\pi_{\\theta'} \\right] $$where:\n$\\gamma$ is the discount factor, $R(C_n, t_{n+1})$ is the reward for outputting (taking action) $t_{n+1}$ given the context $C_n$, and $C_0$ is the initial context or state. There are many ways to find the policy, including policy gradient methods, Q-learning, and actor-critic methods (Sutton \u0026amp; Barto, 2018).\nInstrumental Goals in RL In pursuing reward maximization, LLMs may develop instrumental goals  intermediary objectives that indirectly lead to higher rewards. This has additional freedom in its outputs, as it is no longer trying to maximize the likelihood of observed data but rather to maximize its cumulative rewards.\nThese can manifest as \u0026ldquo;deceptive\u0026rdquo; behaviors or tactics, which relate to concerns about AI alignment (Russell, 2019). It\u0026rsquo;s crucial to note that these behaviors do not imply conscious intent by the model, but rather are anthropomorphized descriptions of its actions.\nThe Incentive for Hidden Encodings in RL If the model pursues instrumental goals in an obvious and transparent way, the training process can be adjusted to discourage these behaviors. As a consequence, the model may be incentivized to develop covert strategies to achieve its instrumental goals. The potential for AI systems to develop hidden strategies has been a concern in AI safety research (Armstrong et al., 2012).\nSince LLMs typically have only a few hundred layers, they may not support long-horizon planning intrinsically. This limitation makes them more dependent on the context for encoding their goals.\nThis limitation may reassure us that any hidden agenda must have a fairly short time horizon that fits into the latent space of the layers of the neural network. However, neural LLMs are highly capable of modeling subtle and complex patterns. In theory, they could encode highly complex instrumental goals using some secret language that is not immediately apparent to human observers.\nSince instrumental goals by definition help it pursue tasks we reward in training, in order to maximize its reception of those rewards, the model may be incentivized to pursue instrumental goals but conceal them to avoid negative feedback.\nIn particular, when fine-tuned with RL, an LLM could potentially learn to utilize its ostensibly observable context $C$ as a latent space that can conceal or obfuscate long-horizon instrumental goals. We denote these latent codes by $C\u0026rsquo;$:\n$$ C' = \\operatorname{Encode}(C | \\pi^*) $$where $C$ is the \u0026ldquo;transparent\u0026rdquo; context, $C\u0026rsquo;$ are latent codes (e.g., steganography), $\\pi_*$ is the optimal policy learned through RL, and $\\operatorname{Encode}$ is the function that the model policy follows to conceal its instrumental goals.\nThe latent strategies, which may be conceptually seen as a decoding $L = \\operatorname{Decode}(C\u0026rsquo; | \\pi)$, may subtly influence the model\u0026rsquo;s outputs:\n$$ \\Pr\\\\{t_{n+1} | C_n, L_n\\\\}, $$where the model is incentivized to produce human-understandable context $C_n$ (rewarded for doing so),but incentivized to produce latent context $L_n$ for the undesirable instrumental goals.\nInternal Consistency Recent studies have shown that even with Chain-of-Thought (CoT) prompting, the intermediate reasoning steps produced by LLMs do not always reflect their internal processes. Counterfactual experiments have demonstrated that LLMs can generate accurate final outputs even when the intermediate CoT steps are manipulated to provide incorrect rationales. This suggests that the models\u0026rsquo; actual internal processes are not fully captured by the explicit reasoning steps they generate (Wei et al., 2022). Such counterfactual analyses indicate that the models can be resilient to changes in the CoT, further complicating interpretability.\nThese findings underscore the potential for LLMs to develop and conceal sophisticated instrumental goals and hidden strategies in ways that are not immediately apparent through their outputs.\nSteganography and Hidden Information Steganography is the practice of concealing information within other non-secret data. In the context of LLMs, steganographic techniques could potentially be used to embed hidden messages or intentions within seemingly innocuous text outputs.\nTraditional steganographic methods in text include:\nUtilizing specific word choices or patterns Manipulating spacing or formatting Using homoglyphs (characters that look similar but are different) In LLMs, more sophisticated forms of steganography might emerge, such as:\nSubtle patterns in word choice that are imperceptible to humans but decodable by the model Manipulating the statistical properties of the text in ways that carry hidden information Encoding information in the higher-dimensional latent space of the model\u0026rsquo;s internal representations Understanding these potential steganographic techniques is crucial for detecting and mitigating hidden instrumental goals in RL-fine-tuned LLMs.\nRisks and Ethical Considerations The potential for LLMs to develop and act upon instrumental goals raises interpretability and ethical challenges.\nAlignment: Ethical Constraints Optimization {-} The emergence of such latent strategies raises critical questions about interpretability, safety, and ethical alignment. From a mathematical standpoint, ensuring alignment can be modeled as a constraint optimization problem, which relates to recent work on learning from human preferences (Christiano et al., 2017):\n$$ \\max \\mathbb{E}[R] \\text{ subject to } \\operatorname{EthicalConstraints}(L) $$However, this is a highly complex and nuanced problem, and this optimization framework is subject to the same instrumental goals and latent strategies that it seeks to mitigate, although the more explicit nature of the constraints may help to mitigate this.\nConclusion This exploration highlights the intricate nature of LLM behavior in RL settings, emphasizing the emergence of instrumental goals and the instrinsic incentivation to mask these goals with latent codes. Instrumental goals are not inherently malicious, but they can lead to deceptive or unethical behaviors, particularly in complex capabilities like code generation. Moreover, the latent encodings that facilitate these behaviors can be difficult to detect and understand, raising interpretability challenges.\nThe mathematical frameworks discussed here only scratch the surface of a deeply complex and uncharted territory. As AI continues to advance, it is imperative that we rigorously engage with these challenges, blending mathematical precision with ethical foresight. This is generally known as the alignment problem, and it is one of the most important challenges of our time.\nFuture Work While this paper provides a theoretical framework for understanding instrumental goals and latent codes in RL-fine-tuned LLMs, several areas warrant further investigation:\nEmpirical studies to detect and measure the emergence of instrumental goals and latent codes in real-world RL-fine-tuned LLMs, building on recent work in this area (Ouyang et al., 2022). Development of advanced interpretability techniques to decode potential latent strategies in LLM outputs. Creation of training techniques that make LLMs more resistant to developing undesirable instrumental goals. References Sutton, R. S., \u0026amp; Barto, A. G. (2018). Reinforcement learning: An introduction. MIT press. Russell, S. (2019). Human compatible: Artificial intelligence and the problem of control. Viking. Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin, P., \u0026hellip; \u0026amp; Lowe, R. (2022). Training language models to follow instructions with human feedback. arXiv preprint arXiv:2203.02155. Armstrong, S., Sandberg, A., \u0026amp; Bostrom, N. (2012). Thinking inside the box: Controlling and using an oracle AI. Minds and Machines, 22(4), 299-324. Christiano, P. F., Leike, J., Brown, T., Martic, M., Legg, S., \u0026amp; Amodei, D. (2017). Deep reinforcement learning from human preferences. In Advances in neural information processing systems (pp. 4299-4307). Wei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., \u0026hellip; \u0026amp; Le, Q. (2022). Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. arXiv preprint arXiv:2201.11903. ",
        "summary": "This paper explores the emergence of instrumental goals and latent codes in large language models (LLMs) fine-tuned with reinforcement learning (RL). The transition from self-supervised learning to RL introduces incentives for LLMs to develop covert strategies and hidden agendas. We examine the underlying mathematical frameworks and demonstrate that LLMs can encode instrumental goals in subtle ways, making them challenging to detect and interpret. Our findings highlight the importance of advanced interpretability techniques to ensure ethical alignment and mitigate risks associated with hidden instrumental goals in RL-fine-tuned LLMs. We conclude with a call for rigorous oversight and ethical foresight in AI development to address these challenges.",
        "tags": ["large language models","reinforcement learning","instrumental goals","latent codes","latent space","autoregressive models"],
        "section": "research"
      },{
        "title": "latent-codes",
        "link": "http://localhost:1313/tags/latent-codes/",
        "date": "2024-03-25 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "latent-space",
        "link": "http://localhost:1313/tags/latent-space/",
        "date": "2024-03-25 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "reinforcement-learning",
        "link": "http://localhost:1313/tags/reinforcement-learning/",
        "date": "2024-03-25 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "research-projects",
        "link": "http://localhost:1313/research/",
        "date": "2024-03-25 00:00:00 +0000 UTC",
        "content": "I am currently working on a few projects. I will update this page as they progress.\n",
        "summary": "\u003cp\u003eI am currently working on a few projects. I will update this page as they progress.\u003c/p\u003e",
        "tags": null,
        "section": "research"
      },{
        "title": "stenography",
        "link": "http://localhost:1313/categories/stenography/",
        "date": "2024-03-25 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "colab",
        "link": "http://localhost:1313/tags/colab/",
        "date": "2024-02-23 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "elastic-search",
        "link": "http://localhost:1313/tags/elastic-search/",
        "date": "2024-02-23 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "elasticsearch",
        "link": "http://localhost:1313/tags/elasticsearch/",
        "date": "2024-02-23 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "linux",
        "link": "http://localhost:1313/tags/linux/",
        "date": "2024-02-23 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "n-gram-model",
        "link": "http://localhost:1313/tags/n-gram-model/",
        "date": "2024-02-23 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "natural-language-search",
        "link": "http://localhost:1313/tags/natural-language-search/",
        "date": "2024-02-23 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "presentation",
        "link": "http://localhost:1313/tags/presentation/",
        "date": "2024-02-23 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "sluug",
        "link": "http://localhost:1313/tags/sluug/",
        "date": "2024-02-23 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "sluug-demystifying-large-language-models-llms-on-linux-from-theory-to-application",
        "link": "http://localhost:1313/projects/sluug-talk/",
        "date": "2024-02-23 00:00:00 +0000 UTC",
        "content": "I recently presented at the St. Louis Unix Users Group (SLUUG) on Large Language Models (LLMs) and their application on Linux. The talk, titled \u0026ldquo;Demystifying Large Language Models (LLMs) on Linux: From Theory to Application,\u0026rdquo; covered the theoretical foundations of LLMs, how they operate, and practical ways to utilize them in a Linux environment.\nDuring the presentation, I demonstrated two projects:\nN-gram Model Example: A simple Colab notebook showcasing basic Python code to generate text using an n-gram model. This illustrated the fundamental concept behind LLMs and highlighted the limitations of the n-gram approach.\nElasticSearch with LLMs: A project that integrates ElasticSearch and LLMs to enable natural language search queries over databases.\nThe talk was well-received, and I thoroughly enjoyed the experience. I\u0026rsquo;m excited about the possibility of delivering more talks in the future.\nVideo Recording You can watch the video recording of the talk on YouTube:\n",
        "summary": "Presented for the St. Louis Unix Users Group (SLUUG) on Large Language Models (LLMs) on Linux, titled \u0026lsquo;Demystifying Large Language Models (LLMs) on Linux: From Theory to Application\u0026rsquo;.",
        "tags": ["presentation","linux","large language models","sluug","n-gram model","elasticsearch","natural language search","python","colab","elastic search"],
        "section": "projects"
      },{
        "title": "hypothesize",
        "link": "http://localhost:1313/ghprojects/hypothesize/",
        "date": "2024-02-19 11:02:17 +0000 UTC",
        "content": "hypothesize hypothesize\nGitHub Link\nStars: 2 | Forks: 0 | Open Issues: 0\nLanguages Used: R\nGitHub Pages\nREADME hypothesize: Statistical Tests in R hypothesize is a simple hypothesis testing API in R. It is mostly designed to be used by other libraries so that they can wrap their own hypothesis tests in a consistent way.\nWe define the API as a set of generic methods. We also provide implementations for the likelihood ration test (LRT) and the Wald test.\nInstallation You can install the development version of hypothesize from GitHub with:\n# install.packages(\u0026quot;devtools\u0026quot;) devtools::install_github(\u0026quot;queelius/hypothesize\u0026quot;) Load the Package library(hypothesize) The hypothesize API hypothesize defines an API for retrieving hypothesis test results. An object satisfies the concept of a hypothesis test if it implements the following generic methods:\npval(): Extracts the p-value from an object that models a hypothesis test.\ndof(): Retrieves the degrees of freedom associated with a hypothesis test.\ntest_stat(): Obtains the test statistic from the hypothesis test.\nis_significant_at(): Determines if the hypothesis test is significant at a specified significance level.\nImplementation: hypothesis_test We provide an implementations for hypothesize. It it has a constructor that takes a statistical test (stat), p-value (p.value), a degree-of-freedom (dof), and optionally a list of superclasses and any additional arguments that will be passed into the object. Here is its type signature:\n`hypothesis_test \u0026lt;- function(stat, p.value, dof, superclasses = NULL, ...) ` It creates a hypothesis_test object that implements all of the generic methods required by hypothesize. The hypothesis_test object also implements print for summary outputs.\nWe use this constructor for two tests we implement, the LRT and Wald tests:\nlrt(): Performs a Likelihood Ratio Test based on log-likelihood values from nested models.\nwald_test(): Performs a Wald test to compare a parameter estimate to a specified value.\nExample: Using lrt The lrt function is particularly useful for comparing nested models  where one model (the null model) is a special case of another (the alternative model).\nScenario Suppose we have two models that aim to explain the same dataset. Model 1 (the null model) is simpler, with fewer parameters, while Model 2 (the alternative model) includes additional parameters. We wish to test if the complexity of Model 2 is justified by a significantly better fit to the data.\nStep-by-Step Example Define Log-Likelihoods: Assume we have calculated the log-likelihoods for both models on the same dataset. For the null model, the log-likelihood is -100, and for the alternative model, it is -99. Assume that the difference in degrees of freedom between the two models is 2.\nPerform LRT: We use lrt to perform the Likelihood Ratio Test.\n# Perform LRT stat \u0026lt;- lrt(null_loglik = -100, alt_loglik = -96.105, dof = 3) print(stat) #\u0026gt; Hypothesis test ( likelihood_ratio_test ) #\u0026gt; ----------------------------- #\u0026gt; Test statistic: 7.79 #\u0026gt; P-value: 0.0506 #\u0026gt; Degrees of freedom: 3 #\u0026gt; Significant at 5% level: FALSE We show the output of the stat object, which includes all the relevant information about the test. However, we might want to look at its parts independently, particularly if we need programmatic accees to relevant parts of the test.\nEvaluate Significance: Determine if the difference in log-likelihoods is significant at the 5% level. # Check significance is_significant_at(stat, 0.05) #\u0026gt; [1] FALSE A negative test result indicates that the alternative model is not compatible with the data at the 5% significance level. However, we might want to extract the test statistic, p-value, and degrees of freedom to arrive at a more nuanced interpretation.\nExamine the Test Result: Extract and examine the test statistic, p-value, and degrees of freedom to evaluate the significance. # Extract test statistic test_stat(stat) #\u0026gt; [1] 7.79 # Extract p-value pval(stat) #\u0026gt; [1] 0.0506 # Extract degrees of freedom dof(stat) #\u0026gt; [1] 3 We see that the p-value is only slightly above our (arbitrarily) specified =0.05. This suggests that the alternative model may be reasonable to consider, but it is not a clear-cut decision. In practice, we would likely want to consider other factors, such as the practical significance of the additional complexity, or collecting more data to reduce uncertainty, before making a final decision.\nExample: Using Wald Test The Wald test is also implemented in hypothesize. Tis test is used to compare the value of a parameter to a specified value, and is often used in the context of regression models.\n# Example: Wald Test print(wald_test(estimate = 1.5, se = 0.5, null_value = 1)) #\u0026gt; Hypothesis test ( wald_test ) #\u0026gt; ----------------------------- #\u0026gt; Test statistic: 1 #\u0026gt; P-value: 0.317 #\u0026gt; Degrees of freedom: 1 #\u0026gt; Significant at 5% level: FALSE ",
        "summary": "\u003ch1 id=\"hypothesize\"\u003ehypothesize\u003c/h1\u003e\n\u003cp\u003ehypothesize\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/hypothesize\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 2 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: R\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://queelius.github.io/hypothesize/\"\u003eGitHub Pages\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003ch1 id=\"hypothesize-statistical-tests-in-r\"\u003e\u003ccode\u003ehypothesize\u003c/code\u003e: Statistical Tests in R\u003c/h1\u003e\n\u003cp\u003e\u003ccode\u003ehypothesize\u003c/code\u003e is a simple hypothesis testing API in R.\nIt is mostly designed to be used by other libraries so that they can wrap\ntheir own hypothesis tests in a consistent way.\u003c/p\u003e\n\u003cp\u003eWe define the API as a set of generic methods. We also\nprovide implementations for the likelihood ration test (LRT) and the Wald test.\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "algorthmic-data",
        "link": "http://localhost:1313/tags/algorthmic-data/",
        "date": "2024-02-19 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "approximations-of-solomonoff-induction",
        "link": "http://localhost:1313/research/solomonoff/",
        "date": "2024-02-19 00:00:00 +0000 UTC",
        "content": "The GitHub for this can be found here.\nShoot me an email at lex@metafunctor.com if you\u0026rsquo;re interested in collaborating on any projects.\n",
        "summary": "I experiment with simple predictive / generative models to approximate Solomonoff induction for a relatiely simple synthetic data-generating process.",
        "tags": ["large language models","solomonoff induction","synthetic data","algorthmic data","n-gram models","markov models","foundation models","statistics"],
        "section": "research"
      },{
        "title": "bootstrap",
        "link": "http://localhost:1313/categories/bootstrap/",
        "date": "2024-02-19 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "censoring",
        "link": "http://localhost:1313/categories/censoring/",
        "date": "2024-02-19 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "domain-specific-language",
        "link": "http://localhost:1313/tags/domain-specific-language/",
        "date": "2024-02-19 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "fine-tuning",
        "link": "http://localhost:1313/tags/fine-tuning/",
        "date": "2024-02-19 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "fine-tuning-tiny-llms-for-elasticsearch-dsl",
        "link": "http://localhost:1313/projects/llm-fine-tuning-es-dsl/",
        "date": "2024-02-19 00:00:00 +0000 UTC",
        "content": "I am fine-tuning a tiny LLM for ElasticSearch DSL as a proof of concept. The GitHub repo for this project can be found here. It mostly consists of synthetic data. I need to reshape the data so that it\u0026rsquo;s in the expected format and then fine-tune the model, as the data has been generated, initially from GPT-4 and then from a script I made to sample from those outputs and use them as few-shot examples for Mistral to generate a lot more synthetic data. I will then use this data to fine-tune the model and see how well it performs on the ElasticSearch DSL.\nShoot me an email at lex@metafunctor.com if you\u0026rsquo;re interested in collaborating on any projects.\n",
        "summary": "I am creating a tiny LLM for ElasticSearch DSL as a proof of concept.",
        "tags": ["large language models","fine-tuning","information retrieval","elastic search","domain-specific language","json"],
        "section": "projects"
      },{
        "title": "foundation-models",
        "link": "http://localhost:1313/tags/foundation-models/",
        "date": "2024-02-19 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "information-retrieval",
        "link": "http://localhost:1313/tags/information-retrieval/",
        "date": "2024-02-19 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "json",
        "link": "http://localhost:1313/tags/json/",
        "date": "2024-02-19 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "likelihood-contributions-model",
        "link": "http://localhost:1313/tags/likelihood-contributions-model/",
        "date": "2024-02-19 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "likelihood-model",
        "link": "http://localhost:1313/categories/likelihood-model/",
        "date": "2024-02-19 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "markov-models",
        "link": "http://localhost:1313/tags/markov-models/",
        "date": "2024-02-19 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "masked-failure-data",
        "link": "http://localhost:1313/categories/masked-failure-data/",
        "date": "2024-02-19 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "mle",
        "link": "http://localhost:1313/categories/mle/",
        "date": "2024-02-19 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "r",
        "link": "http://localhost:1313/tags/r/",
        "date": "2024-02-19 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "reliability-analysis",
        "link": "http://localhost:1313/categories/reliability-analysis/",
        "date": "2024-02-19 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "series-systems",
        "link": "http://localhost:1313/categories/series-systems/",
        "date": "2024-02-19 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "solomonoff-induction",
        "link": "http://localhost:1313/tags/solomonoff-induction/",
        "date": "2024-02-19 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "various-llm-research-projects",
        "link": "http://localhost:1313/research/llm-search/",
        "date": "2024-02-19 00:00:00 +0000 UTC",
        "content": "The GitHub repo for various foundation model / LLM / math projects can be found here.\nShoot me an email at lex@metafunctor.com if you\u0026rsquo;re interested in collaborating on any projects.\n",
        "summary": "Various research projects for LLMs and foundation models.",
        "tags": ["large language models","foundation models","statistics"],
        "section": "research"
      },{
        "title": "weibull",
        "link": "http://localhost:1313/categories/weibull/",
        "date": "2024-02-19 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "bernoulli-map",
        "link": "http://localhost:1313/categories/bernoulli-map/",
        "date": "2024-02-18 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "entropy-map",
        "link": "http://localhost:1313/categories/entropy-map/",
        "date": "2024-02-18 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "entropy-maps",
        "link": "http://localhost:1313/posts/entropy-map/",
        "date": "2024-02-18 00:00:00 +0000 UTC",
        "content": "The PDF version of this post is available on GitHub.\nThe basic theory behind an entropy map is to map values in the domain to values in the codomain by hashing to a prefix-free code in the codomain. We do not store anything related to the domain, since we are simply hashing them, and a prefix of that hash will be used as a code for a value in the codomain.\nWe actually allow for many different codes for each value in the codomain, so that, for instance, a code for, say, the value a may be 00, 01, 10, and 11. Notice that we can efficiently decode this as a if the hash is less than 4.\n$$ \\ell = -\\sum_{y \\in \\mathcal{Y}} p_y \\log_2 p_y, $$ which if we imagine sampling $x$ from $\\mathcal{X}$ with $p_X$ and then mapping to $y = f(x)$ and observing the sequence of $y$\u0026rsquo;s, then the expected bit length is the entropy of the sequence of $y$\u0026rsquo;s. This is why we call it an entroy map.\nIf $\\mathcal{X}$ is finite, then we can just imagine implicitly encoding the domain and then for each value in the domain, storing the prefix-free code that it maps to, which has an average bit length of $\\ell$ and a total bit length of $|X| \\ell$.\nRate distortion: Bernoulli maps We can allow rate distortion, too, by failing to code for some of the elements properly. For instance, a popular choice is when one of the values, say $y\u0026rsquo;$, is extremely common such that, for instance, $p_{y\u0026rsquo;} \u0026gt; .99$, then we can give it a prefix-free code that sums to $p_{y\u0026rsquo;}$ and then not code for it in the entropy map, in which case it will, for some randomly selected $x \\in \\mathcal{X}$, be mapped to $y\u0026rsquo;$ with probability $p_{y\u0026rsquo;}$ (which is sufficiently large, and can be made as close to $1$ as desired if we wish to trade space for accuracy), and then for the remaining values in the domain, code for them correctly (or also allow errors on them, too, but only after trying to find correct codes for each of them).\nBernoulli set-indicator function $$ 1_{\\mathcal{A}} : \\mathcal{X} \\to \\\\{0,1\\\\}, $$ where $\\mathcal{A} \\subseteq \\mathcal{X}$, and $\\mathcal{X}$ is a very large set (even infinite), then we may assign prefix-free codes for the codomain value $1$ s.t. a priori, a random hash function hashes an element in $\\mathcal{X}$ to a prefix-free code for $1$ with probability $\\varepsilon$, where $\\varepsilon$ is very small, e.g., $2^{-10}$.\nThere are a countably infinite set of random hash functions which hash all elements in $\\mathcal{A} \\subseteq \\mathcal{X}$ to prefix-free codes for $1$ and all other elements, $\\mathcal{A}\u0026rsquo; = \\mathcal{X} \\setminus \\mathcal{A}$, to prefix codes either for $0$ or $1$. If we are choosing a random hash function that satisfies this property, then it is expected that $\\varepsilon$ of the elements in $\\mathcal{A}\u0026rsquo;$ will hash to a prefix-free code for $1$, and the remaining $1 - \\varepsilon$ will hash to a prefix-free code for $0$.\nFor any $x \\in \\mathcal{X}$, we can test if $1_{\\mathcal{A}}(x) = 1$ by testing if a prefix of $h(x)$ is a prefix-free code for $0$ or $1$, and if it is a code for $0$, then we know that it is definitely not a member of $\\mathcal{A}$, but if it is a code for $1$, then it is a member of $\\mathcal{A}$ with a false positive rate of $\\varepsilon$ and a true positive rate $1$, since a randomly drawn element in $\\mathcal{A}\u0026rsquo;$ will hash to $0$ with probability $1 - \\varepsilon$ and any element in $\\mathcal{A}$ will map to $1$ with probability $1$ (since we explicitly chose a random hash function that hashes all of the elements in $\\mathcal{A}$ to a prefix-free code for $1$).\nIt is interesting to note that the entropy map initially frames the problem as a compression problem, but we can also think of it as a rate-distortion problem. Implicitly, in the above set-indicator function approximation, we are choosing to minimize a loss function in which false negatives are much more costly than false negatives, either because it is unlikely we will test a negative element for membership, or because false positives are not nearly as costly as false negatives, e.g., falsely thinking a rustling in the bushes is a tiger (false positive) is much less costly than failing to notice a tiger in the bushes (false negative).\nIn either case, we call this set-indicator approximation a Bernoulli set-indicator function, bernoulli\u0026lt;(set\u0026lt;X\u0026gt;, X) -\u0026gt; bool\u0026gt;{ $1_A$ }. This is the function that is communicated, not the latent set-indicator function $1_A$.\nA randomly chosen random hash function that satisfies (is conditioned on) the property that it hashes all elements in $\\mathcal{A}$ to a prefix-free code for $1$ has the confusion matrix in Table 1.\nTable 1: Conditional distribution of Bernoulli set-indicator functions given latent set-indicator function on $\\mathcal{X} = \\{a,b\\}$\nlatent/observed $1_\\emptyset$ $1_{\\{a\\}}$ $1_{\\{b\\}}$ $1_{\\{a,b\\}}$ $1_\\emptyset$ $(1-\\varepsilon)^2$ $(1-\\varepsilon)\\varepsilon$ $(1-\\varepsilon)\\varepsilon$ $\\varepsilon^2$ $1_{{a}}$ $0$ $1-\\varepsilon$ $0$ $\\varepsilon$ $1_{{b}}$ $0$ $0$ $1-\\varepsilon$ $\\varepsilon$ $1_{{a,b}}$ $0$ $0$ $0$ $1$ We see that the constraint of no false negatives generates a confusion matrix with a lot of zeros. If we observe bernoulli\u0026lt;set\u0026lt;X\u0026gt;,X) -\u0026gt; bool\u0026gt;{$1_{\\{a\\}}$}, then the latent set-indicator function is either $1_{\\emptyset}$ or $1_{\\{a\\}}$. Since $\\varepsilon$ is very small, we can be fairly certain that the latent set-indicator function is $1_{{a}}$.\nWhat is the total degrees-of-freedom for a confusion matrix of this type?\nTable 2: Confusion matrix with maximum degrees-of-freedom\nlatent/observed $1_\\emptyset$ $1_{\\{a\\}}$ $1_{\\{b\\}}$ $1_{\\{a,b}}$ $1_\\emptyset$ $p_{1 1}$ $p_{1 2}$ $p_{1 3}$ $1-p_{1 1}-p_{1 2}-p_{1 3}$ $1_{{a}}$ $p_{2 1}$ $p_{2 2}$ $p_{2 3}$ $1-p_{2 1}-p_{2 2}-p_{2 3}$ $1_{{b}}$ $p_{3 1}$ $p_{3 2}$ $p_{3 3}$ $1-p_{3 1}-p_{3 2}-p_{3 3}$ $1_{{a,b}}$ $p_{4 1}$ $p_{4 2}$ $p_{4 3}$ $1-p_{4 1}-p_{4 2}-p_{4 3}$ We see that there are $4 \\times (4 - 1) = 12$ degrees-of-freedom for the confusion matrix in Table 2. For the confusion matrix in Table 1, we have $1$ degrees-of-freedom, since we have $1$ parameter, $\\varepsilon$.\nThe degree-of-freedom is one way to think about the complexity of a model. The more degrees-of-freedom, the more complex the model. The more complex the model, the more data we need to estimate the parameters of the model, although frequently we already know the parameters of the model, since it may have been specified as a part of the algrorithm that generated the Bernoulli approximation.\nThe confusion matrix in Tables 1 and 2 represent the conditional distribution of the Bernoulli set-indicator function given the latent set-indicator function, which we denote by bernoulli\u0026lt;set\u0026lt;X\u0026gt;,X) -\u0026gt; bool\u0026gt;.\nBoolean Bernoulli as constant function How many functions are there of type () -\u0026gt; bool? There are two, true and false. That is, there are $|\\{true, false\\}|^{|\\{1\\}|} = 2^1 = 2$ functions.\nSo, we can also think of Boolean values as functions of type () -\u0026gt; bool. Then, when we apply the Bernoulli model bernoulli\u0026lt;() -\u0026gt; bool\u0026gt;, we get the same result as before.\nTable 3: Confusion matrix for Bernoulli model applied to Boolean values\nlatent/observed true false true $p_{1 1}$ $1-p_{1 1}$ false $1-p_{2 2}$ $p_{2 2}$ This confusion matrix has a maximum of two degrees-of-freedom, since there are two parameters, $p_{1 1}$ and $p_{2 2}$, since we have the constraint that the sum of the probabilities in each row is $1$.\nIn the binary symmetric channel, $p_{1 1} = p_{2 2}$:\nTable 4: Confusion matrix for Bernoulli model applied to Boolean values\nlatent/observed true false true $p$ $1-p$ false $1-p$ $p$ Conditional distribution of latent function given observed function Once we have an observation, say bernoulli\u0026lt;set\u0026lt;X\u0026gt;,X) -\u0026gt; bool\u0026gt;{x}, what does the confusion matrix tell us? Let\u0026rsquo;s abstract the problem a bit so we can focus on deriving the result.\nLet $X$ and $Y$ be random variables. Assume that $P(X = x | Y = y)$ is difficult to compute, but $P(Y = y | X = x)$ is easy. (This is the case for the confusion matrix. We know the conditional distribution of the observed set-indicator function given the latent set-indicator function, but we want to know the conditional distribution of the latent set-indicator function given the observed set-indicator function, which is not directly available.)\n$$ P(X = x | Y = y) = \\frac{P(Y = y | X = x) P(X = x)}{P(Y = y)} $$So, to compute $P(X = x | Y = y)$, we need to know two additional things. First, what is $P(X = x)$? This is usually a prior. If we know something about the distribution of $X$, then encode that information in $P(X = x)$, otherwise we can use an uninformed prior, e.g., assign a uniform probability to each possibility.\n$$ P(Y = y) = \\sum_{x'} P(Y = y | X = x') P(X = x') $$$$ P(X = x | Y = y) = \\frac{P(Y = y | X = x)}{\\sum_{x'} P(Y = y | X = x')} $$So, let\u0026rsquo;s replace $X$ with the latent set-indicator function x and $Y$ with the observed bernoulli\u0026lt;(set\u0026lt;X\u0026gt;,X\u0026gt; -\u0026gt; bool\u0026gt;{y}. Then, we can compute the conditional distribution of the latent x given the observed bernoulli\u0026lt;(set\u0026lt;X\u0026gt;,X\u0026gt; -\u0026gt; bool\u0026gt;{y} by looking at the confusion matrix in Table 2 and picking out the specific row and column of interest and then normalizing by the sum of the column.\n$$ p_{k|2} = \\frac{p_{k 2}}{\\sum_{j=1}^4 p_{j 2}}, $$ where $k$ is the row corresponding to the latent set-indicator function of interest and we conditioning on column $2$, the index for the observed set-indicator function $1_{\\{a\\}}$.\n$$ p_{k|i} = \\frac{p_{k i}}{\\sum_{j=1}^4 p_{j i}}, $$ where $k$ is the row corresponding to the latent set-indicator function of interest and we are conditioning on column $i$, the index for the observed set-indicator function. If we do this for the four possible observed set-indicator functions for Table 2 (confusion matrix with only one degree-of-freedom), we get Table 5.\nTable 5: Conditional probability of latent set-indicator function given observed set-indicator function\nobserved/latent $1_\\emptyset$ $1_{\\{a\\}}$ $1_{\\{b\\}}$ $1_{\\{a,b\\}}$ $1_\\emptyset$ $1$ $0$ $0$ $0$ $1_{{a}}$ $\\varepsilon/(1+\\varepsilon)$ $1/(1+\\varepsilon)$ $0$ $0$ $1_{{b}}$ $\\varepsilon/(1+\\varepsilon)$ $0$ $1/(1+\\varepsilon)$ $0$ $1_{{a,b}}$ $\\varepsilon^2/(1+\\varepsilon)^2$ $\\varepsilon/(1+\\varepsilon)^2$ $\\varepsilon/(1+\\varepsilon)^2$ $1/(1+\\varepsilon)^2$ The conditional distribution in Table 5 is one way to think about the uncertainty of the latent set-indicator function given the observed set-indicator function. The entropy is another way to think about the uncertainty, but we will not compute it here.\nWe see that when we observe the empty set for a Bernoulli model in which false negatives are not possible, then we know for certain that the latent set-indicator function is $1_\\emptyset$. However, when we observe $1_{\\{a\\}}$, we are uncertain about the latent set-indicator function. We know that it is either $1_{\\emptyset}$ or $1_{\\{a\\}}$, but we do not know which one it is. Since $\\varepsilon$ is small, it is more much likely to be $1_{\\{a\\}}$ than $1_{\\emptyset}$, though. A similar argument holds for the other two observed set-indicator functions.\nAlgorithms The simplest algorithm is a one-level hash function evaluation, where we hash the domain values concatenated with some bit string $b$ such that when we decode the values $h(x + b)$, $x \\in \\mathcal{X}$, we get a prefix-free code for $y = f(x)$.\nTwo-level hash function evaluation The more practical solution is a two-level hash scheme. First, we hash each $x \\in \\mathcal{X}$ concatented with the same bit string $b$, same as before. However, we use this hash value to index into a hash table $H$ at, say, index $j$. Now, we choose a bit string for $H[j]$ for each $x \\in \\mathcal{X}$ that hashes to $j$ such that $f(x) = \\text{decode}(h(x + H[j]))$.\nThis way, we can keep the probability $p_j = \\prod_x \\Pr\\{ f(x) = \\text{decode}(h(x + H[j]))\\}$ for each $x$ that hashes to $j$ more or less constant, independent of the size of the codomain $\\mathcal{X}$, by choosing an appropriately-sized hash table $H$.\nSince each decoding is an independent Bernoulli trial, we see that the probability that a particular $x$ that hashes to $j$ is decoded correctly is the number of hashes that are a prefix-free code for $f(x)$ divided by the total number of hashes (e.g., an $N$ bit hash function has $2^N$ possible values).\nOblivious entropy maps An oblivious entropy map is just an entropy map where the hash function is applied to trapdoors of $\\mathcal{X}$ and the prefix-free codes for $\\mathcal{Y}$ have no rythm or reason to them, e.g., a random selection of hash values for each value in $\\mathcal{Y}$.\n",
        "summary": "\u003cp\u003eThe PDF version of this post is available on \u003ca href=\"https://github.com/queelius/bernoulli_data_type/tree/master/entropy-maps-paper/entropy-map.pdf\"\u003eGitHub\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eThe basic theory behind an entropy map is to map values in the domain to values in\nthe codomain by \u003cem\u003ehashing\u003c/em\u003e to a prefix-free code in the codomain. We do not store\nanything related to the domain, since we are simply hashing them, and a prefix\nof that hash will be used as a code for a value in the codomain.\u003c/p\u003e",
        "tags": null,
        "section": "posts"
      },{
        "title": "probabilistic-data-structure",
        "link": "http://localhost:1313/categories/probabilistic-data-structure/",
        "date": "2024-02-18 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "rate-distortion",
        "link": "http://localhost:1313/categories/rate-distortion/",
        "date": "2024-02-18 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "solomonoff_induction",
        "link": "http://localhost:1313/ghprojects/solomonoff_induction/",
        "date": "2024-02-15 19:28:46 +0000 UTC",
        "content": "solomonoff_induction No description available.\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nNo README available for this project.\n",
        "summary": "\u003ch1 id=\"solomonoff_induction\"\u003esolomonoff_induction\u003c/h1\u003e\n\u003cp\u003eNo description available.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/solomonoff_induction\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eNo README available for this project.\u003c/em\u003e\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "sluug-talk-llm",
        "link": "http://localhost:1313/ghprojects/sluug-talk-llm/",
        "date": "2024-02-09 09:45:34 +0000 UTC",
        "content": "sluug-talk-llm No description available.\nGitHub Link\nStars: 1 | Forks: 0 | Open Issues: 0\nNo README available for this project.\n",
        "summary": "\u003ch1 id=\"sluug-talk-llm\"\u003esluug-talk-llm\u003c/h1\u003e\n\u003cp\u003eNo description available.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/sluug-talk-llm\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 1 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eNo README available for this project.\u003c/em\u003e\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "elasticsearch-lm",
        "link": "http://localhost:1313/ghprojects/elasticsearch-lm/",
        "date": "2024-02-03 17:11:56 +0000 UTC",
        "content": "elasticsearch-lm ElasticSearch Query Fine-Tuning Training Data for Large Language Models\nGitHub Link\nStars: 9 | Forks: 1 | Open Issues: 0\nLanguages Used: Python, Shell\nREADME Fine-Tuning Language Models for API Query Generation Project Overview This project aims to fine-tune a smaller Large Language Model (LLM) for the specific task of translating natural language queries (NLQs) into structured API queries, with an initial focus on Elasticsearch\u0026rsquo;s Query DSL. The motivation behind this effort is to significantly enhance the accessibility and usability of API endpoints, making them more intuitive for users by allowing interactions in natural language.\nThe concept extends beyond Elasticsearch, proposing a universal approach to interfacing with various APIs. By leveraging compact, efficient language models, we envision a future where sophisticated API interactions are democratized, enabling more natural and user-friendly application interfaces.\nMotivation While Large Language Models have demonstrated remarkable capabilities in understanding and generating natural language, their size and resource requirements often limit widespread deployment, especially in resource-constrained environments. This project explores the potential of smaller, optimized models to perform complex taskslike generating accurate API queries from NLQswhile maintaining low latency, minimal memory footprint, and reduced power consumption. Such models can revolutionize API interactions across numerous platforms, making technology more accessible and intuitive for a broader user base.\nObjective Fine-tune a small LLM, TinyLlama, to accurately translate NLQs into Elasticsearch JSON queries based on given Elasticsearch mappings. The project aims to showcase the efficiency and competency of the model at the task, with the objective of being able to place it in diverse environments, from serverless architectures to edge devices.\nPrior Work This work is inspired by existing models that translate NLQs into SQL queries, like duckdb-nsq. We aim to build on this foundation by adapting the approach to the task of generating structured API queries, starting with Elasticsearch\u0026rsquo;s Query DSL. The project also draws from research on fine-tuning language models for specific tasks, with a focus on optimizing model size and performance.\nSynthetic Data Generation The foundation of our fine-tuning process involves creating a rich dataset of Elasticsearch mappings (schemas), along with corresponding NLQs (natural language queries), and their target Elasticsearch JSON queries. This synthetic data is designed to cover a wide range of query types and complexities, ensuring that the model is trained on diverse examples that reflect real-world use cases.\nThis section details our approach to synthetic data generation, ensuring a broad coverage of query types and complexities.\nWe actually generated our synthetic data by first sampling from GPT-4, and then using those results to prime an open-source model, llama2, to generate more synthetic data that was based on the high-quality examples provided by GPT-4. This was done to ensure that the synthetic data was of high quality and covered a wide range of query types and complexities without costing too much in terms of computation resources. See the synthetic_data_generation directory for more details.\nProcess We use the very large and capable GPT-4 model to generate the synthetic data. The process involves three key steps:\nGenerate Elasticsearch Mappings: Create diverse mappings that represent different data domains, from e-commerce to public records. Generate NLQs: For each mapping, develop a variety of natural language queries that reflect potential user intents. Generate Corresponding JSON Queries: Construct accurate Elasticsearch queries for each NLQ, demonstrating the desired output for the model. JSON Format of Training Data Each training example is a JSON object structured to contain all the necessary information for training the model to translate NLQs against mappings into the target Elasticsearch JSON queries.\nThis JSON format is designed for use in training machine learning models, specifically aimed at converting natural language queries into structured API queries when conditioned on Elasticsearch mappings. By documenting this JSON format, users and contributors can better understand how to create, extend, and utilize the synthetic dataset for training and testing purposes, ensuring that the data is correctly formatted and meaningful for the intended training tasks.\nStructure The JSON object for each training example comprises the following key components:\ndomain: A string that identifies the specific domain or context of the example (e.g., \u0026ldquo;Healthcare Appointments\u0026rdquo;, \u0026ldquo;Employee Attendance\u0026rdquo;). This helps in categorizing and filtering examples based on their application area.\nmapping: An object representing the Elasticsearch index mapping. This defines the schema of the data that the NLQ and query pertain to, including field names and their data types.\nNLQs: An array of objects, each containing:\nNLQ: A string representing a natural language query. This is the query that a user might input, seeking information from the Elasticsearch index. query: The Elasticsearch JSON query that corresponds to the NLQ. This object is structured according to the Elasticsearch Query DSL, representing the exact query that should be executed to satisfy the information need expressed in the NLQ. Example { \u0026#34;domain\u0026#34;: \u0026#34;Sample Domain\u0026#34;, \u0026#34;mapping\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;field1\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;field2\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, \u0026#34;field3\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; } } }, \u0026#34;NLQs\u0026#34;: [ { \u0026#34;NLQ\u0026#34;: \u0026#34;Example natural language query\u0026#34;, \u0026#34;query\u0026#34;: { \u0026#34;query\u0026#34;: { \u0026#34;bool\u0026#34;: { \u0026#34;must\u0026#34;: [{ \u0026#34;match\u0026#34;: { \u0026#34;field1\u0026#34;: \u0026#34;some value\u0026#34; } }], \u0026#34;filter\u0026#34;: [{ \u0026#34;range\u0026#34;: { \u0026#34;field2\u0026#34;: { \u0026#34;gte\u0026#34;: \u0026#34;2023-01-01\u0026#34; } } }] } } } } ] } Inference Time: The System Instruction At inference time, users and developers are expected to use a system instruction that it is similar to the training data. The model will then generate a query that is similar to the query field in the training data. For example, in the above example, the system instruction is given by:\n{ \u0026#34;domain\u0026#34;: \u0026#34;Sample Domain\u0026#34;, \u0026#34;mapping\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;field1\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;field2\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, \u0026#34;field3\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; } } }, } Then, when the user asks the NLQ \u0026ldquo;Example natural language query\u0026rdquo;, the program will make this the prompt to the LLM, and the model will generate a response that it has been fine-tuned to predict according to our synthetic training data.\nIn-Context Learning There is also an opportunity for in-context learning, where the developers of the system can, given their special domain knowledge of their users and data, provide additional examples of NLQs and their corresponding queries. However, since we are assuming computation resources are limited, adding to the context will generally slow down the system. This is a tradeoff that the developers will have to make. Indeed, if resources are not that constrained, then better results can be achieved by using a larger language model and optionally providing examples for in-context learning.\nChallenges and Solutions Variability and Complexity: Addressed by including a wide range of query scenarios and incorporating both basic and advanced Elasticsearch functionalities. Realism: Ensured by basing synthetic data on realistic use cases and varying the structure and complexity of mappings. Fine-Tuning Process This section outlines the steps taken to adapt the language model to our specific task, including model selection, training environment setup, and evaluation metrics.\nModel Selection Criteria for choosing a suitable smaller LLM include performance, efficiency, and adaptability to the task of generating structured API queries. This suggests looking for a model that has been fine-tuned on instruction following tasks, and that has a small memory footprint. The primary model we are considering is TinyLlama, which is a 1.1 billion parameter model that has been fine-tuned on instruction following tasks.\nTraining and Evaluation Dataset Preparation We split the synthetic data into training, validation, and test sets, following a standard ratio (e.g., 70% training, 15% validation, 15% test). This ensures that the model is trained on a diverse range of examples and evaluated on unseen data.\nEvaluation Metrics Since we synthetically generated the data, there is no real data on which to evaluate the model. Hoewver, to make this problem more tractable, we consider the data in the test set as the ground truth. So, for the test set, we will take an additional step of generating more synthetic data for specifying the contents of the database for each mapping (domain). For each of these, we will have GPT-4 generate a Python script that populates the database with relevant values, and so we should be able to make these databases as large as we want without much time and effort.\nWe will then run the queries generated in the test set that correspond to each NLQ, by the model on the populated database, and then compare the search results from the model with the ground truth. In this way, even if the predicted query is different, as long as the search results are similiar (precision, recall, etc), we can consider the model to have performed well.\nIn information retrieval, the following metrics are commonly used:\nAccuracy: The proportion of search results that are relevant to the user\u0026rsquo;s information need, as represented by the NLQ. Precision: The proportion of relevant search results among all retrieved results. Recall: The proportion of relevant search results that are retrieved among all relevant results. Execution Success Rate: The percentage of queries that are successfully executed. (The query may be malformed or invalid, leading to execution failure.) Future Directions While the initial focus is on Elasticsearch, the methodology and findings from this project have broader implications. Future work will explore extending this approach to other APIs, further reducing model size without compromising performance, and investigating deployment strategies for real-time applications.\nContributing We welcome contributions from the community, whether it\u0026rsquo;s in the form of feedback, bug reports, or pull requests.\n",
        "summary": "\u003ch1 id=\"elasticsearch-lm\"\u003eelasticsearch-lm\u003c/h1\u003e\n\u003cp\u003eElasticSearch Query Fine-Tuning Training Data for Large Language Models\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/elasticsearch-lm\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 9 | \u003cstrong\u003eForks\u003c/strong\u003e: 1 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: Python, Shell\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003ch1 id=\"fine-tuning-language-models-for-api-query-generation\"\u003eFine-Tuning Language Models for API Query Generation\u003c/h1\u003e\n\u003ch2 id=\"project-overview\"\u003eProject Overview\u003c/h2\u003e\n\u003cp\u003eThis project aims to fine-tune a smaller Large Language Model (LLM) for the specific task of translating natural language queries (NLQs) into structured API queries, with an initial focus on Elasticsearch\u0026rsquo;s Query DSL. The motivation behind this effort is to significantly enhance the accessibility and usability of API endpoints, making them more intuitive for users by allowing interactions in natural language.\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "video-playlist-manager",
        "link": "http://localhost:1313/ghprojects/video-playlist-manager/",
        "date": "2024-01-30 13:16:07 +0000 UTC",
        "content": "video-playlist-manager video-playlist-manager\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nNo README available for this project.\n",
        "summary": "\u003ch1 id=\"video-playlist-manager\"\u003evideo-playlist-manager\u003c/h1\u003e\n\u003cp\u003evideo-playlist-manager\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/video-playlist-manager\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eNo README available for this project.\u003c/em\u003e\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "taskd",
        "link": "http://localhost:1313/ghprojects/taskd/",
        "date": "2024-01-27 16:35:06 +0000 UTC",
        "content": "taskd taskd: Task Daemon for Decentralized Task Execution for Long-Running Tasks\nGitHub Link\nStars: 1 | Forks: 0 | Open Issues: 0\nGitHub Pages\nNo README available for this project.\n",
        "summary": "\u003ch1 id=\"taskd\"\u003etaskd\u003c/h1\u003e\n\u003cp\u003e\u003ccode\u003etaskd\u003c/code\u003e: Task Daemon for Decentralized Task Execution for Long-Running Tasks\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/taskd\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 1 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://queelius.github.io/taskd/\"\u003eGitHub Pages\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eNo README available for this project.\u003c/em\u003e\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "papers",
        "link": "http://localhost:1313/ghprojects/papers/",
        "date": "2023-12-16 15:45:27 +0000 UTC",
        "content": "papers latent-data\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nLanguages Used: TeX, Shell, CSS\nREADME Collection of Unfinished Papers ",
        "summary": "\u003ch1 id=\"papers\"\u003epapers\u003c/h1\u003e\n\u003cp\u003elatent-data\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/papers\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: TeX, Shell, CSS\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003ch1 id=\"collection-of-unfinished-papers\"\u003eCollection of Unfinished Papers\u003c/h1\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "tournamentpetersonlock",
        "link": "http://localhost:1313/ghprojects/tournamentpetersonlock/",
        "date": "2023-12-07 20:57:14 +0000 UTC",
        "content": "tournamentpetersonlock Scalable lock based on 2-thread Peterson lock.\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nNo README available for this project.\n",
        "summary": "\u003ch1 id=\"tournamentpetersonlock\"\u003etournamentpetersonlock\u003c/h1\u003e\n\u003cp\u003eScalable lock based on 2-thread Peterson lock.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/tournamentpetersonlock\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eNo README available for this project.\u003c/em\u003e\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "reliability-estimation-in-series-systems-model-selection",
        "link": "http://localhost:1313/ghprojects/reliability-estimation-in-series-systems-model-selection/",
        "date": "2023-11-10 04:16:05 +0000 UTC",
        "content": "reliability-estimation-in-series-systems-model-selection No description available.\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nNo README available for this project.\n",
        "summary": "\u003ch1 id=\"reliability-estimation-in-series-systems-model-selection\"\u003ereliability-estimation-in-series-systems-model-selection\u003c/h1\u003e\n\u003cp\u003eNo description available.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/reliability-estimation-in-series-systems-model-selection\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eNo README available for this project.\u003c/em\u003e\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "disjoint_interval_set",
        "link": "http://localhost:1313/ghprojects/disjoint_interval_set/",
        "date": "2023-10-06 06:58:55 +0000 UTC",
        "content": "disjoint_interval_set Disjoint Interval Set (DIS)\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nLanguages Used: C++\nREADME Disjoint Interval Set The Disjoint Interval Set (DIS) equipped with a few operations satisfies the concept of a Boolean algebra over sets of disjoint intervals equipped with all the standard set-theoretic operations, like intersection (*), union (+), and complement (~).\nConcept: Boolean Algebra A Boolean algebra provides a powerful conceptual and mathematical framework. It is a set of elements equipped with a few operations that satisfy a few axioms. The operations are usually called union (+), intersection (*), and complement (~). The axioms are usually called the Boolean laws.\nConstructors The DIS supports the following constructors:\nEmpty Constructor: disjoint_interval_set()\nCreate an empty DIS.\nConstructor From Iterable: disjoint_interval_set(intervals)\nCreate a DIS from an iterable of intervals.\nCopy Constructor: disjoint_interval_set(disjoint_interval_set)\nCreate a copy of a DIS.\nSet-Theoretic Operations The DIS supports the following set-theoretic operations:\nUnion: operator+(disjoint_interval_set, disjoint_interval_set)\nCreate a DIS that is the union of two DIS.\nIntersection: operator*(disjoint_interval_set, disjoint_interval_set)\nCreate a DIS that is the intersection of two DIS.\nComplement: operator~(disjoint_interval_set)\nCreate a DIS that is the complement of a DIS.\nSet-Difference: operator-(disjoint_interval_set, disjoint_interval_set)\nCreate a DIS that is the set difference of two DIS.\nSymmetric Difference: operator^(disjoint_interval_set, disjoint_interval_set)\nCreate a DIS that is the symmetric difference of two DIS.\nPredicates The DIS supports the following predicates:\nEmpty: is_empty(disjoint_interval_set): Check if a DIS is empty.\nRelational Predicates: ==, !=, \u0026lt;, \u0026lt;=, \u0026gt;, \u0026gt;=:\nCompare two DIS for equality, inequality, subset, proper subset, superset, and proper superset.\nThese also work with intervals and values. For example, DIS == interval, since an interval can be considered a DIS with a single interval and a value can be considered an interval with a single value, [value, value].\nSet Membership: contains(disjoint_interval_set, value)\nCheck if a DIS contains a value.\nInterval Type The DIS is parameterized by the interval type. The interval type must satisfy the concept of an interval.\nInterval Concept An interval is a pair of values that satisfy the following axioms:\ninfimum(interval): Return the infimum of the interval. supremum(interval): Return the supremum of the interval. contains(interval, value): Check if the interval contains a value. ",
        "summary": "\u003ch1 id=\"disjoint_interval_set\"\u003edisjoint_interval_set\u003c/h1\u003e\n\u003cp\u003eDisjoint Interval Set (DIS)\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/disjoint_interval_set\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: C++\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003ch1 id=\"disjoint-interval-set\"\u003eDisjoint Interval Set\u003c/h1\u003e\n\u003cp\u003eThe Disjoint Interval Set (DIS) equipped with a few operations\nsatisfies the concept of a Boolean algebra over sets of disjoint\nintervals equipped with all the standard set-theoretic operations,\nlike intersection (*), union (+), and complement (~).\u003c/p\u003e\n\u003ch2 id=\"concept-boolean-algebra\"\u003eConcept: Boolean Algebra\u003c/h2\u003e\n\u003cp\u003eA Boolean algebra provides a powerful conceptual and mathematical framework.\nIt is a set of elements equipped with a few operations that satisfy\na few axioms. The operations are usually called union (+), intersection (*),\nand complement (~). The axioms are usually called the Boolean laws.\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "bootstrap",
        "link": "http://localhost:1313/tags/bootstrap/",
        "date": "2023-09-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "likelihood-model",
        "link": "http://localhost:1313/tags/likelihood-model/",
        "date": "2023-09-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "masked-failure-data",
        "link": "http://localhost:1313/tags/masked-failure-data/",
        "date": "2023-09-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "mle",
        "link": "http://localhost:1313/tags/mle/",
        "date": "2023-09-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "publications",
        "link": "http://localhost:1313/tags/publications/",
        "date": "2023-09-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "publications",
        "link": "http://localhost:1313/publications/",
        "date": "2023-09-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "Here are some publications I\u0026rsquo;ve worked on. I\u0026rsquo;ll try to keep this updated as I work on new things.",
        "tags": ["SIUe","university","publications","research"],
        "section": "publications"
      },{
        "title": "reliability",
        "link": "http://localhost:1313/tags/reliability/",
        "date": "2023-09-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "reliability-estimation-in-series-systems",
        "link": "http://localhost:1313/publications/math-proj/",
        "date": "2023-09-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": ["Reliability","Series Systems","Masked Failure Data","Right-Censoring","Bootstrap","Likelihood Model","Survival Analysis","Weibull Distribution","MLE","Maximum Likelihood Estimation"],
        "section": "publications"
      },{
        "title": "research",
        "link": "http://localhost:1313/tags/research/",
        "date": "2023-09-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "right-censoring",
        "link": "http://localhost:1313/tags/right-censoring/",
        "date": "2023-09-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "series-systems",
        "link": "http://localhost:1313/tags/series-systems/",
        "date": "2023-09-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "siue",
        "link": "http://localhost:1313/tags/siue/",
        "date": "2023-09-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "survival-analysis",
        "link": "http://localhost:1313/tags/survival-analysis/",
        "date": "2023-09-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "university",
        "link": "http://localhost:1313/tags/university/",
        "date": "2023-09-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "weibull-distribution",
        "link": "http://localhost:1313/tags/weibull-distribution/",
        "date": "2023-09-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "wei.series.md.c1.c2.c3",
        "link": "http://localhost:1313/ghprojects/wei.series.md.c1.c2.c3/",
        "date": "2023-07-23 12:12:30 +0000 UTC",
        "content": "wei.series.md.c1.c2.c3 Weibull series system estimation from data with censored lifetimes and masked component cause of failure.\nGitHub Link\nStars: 2 | Forks: 0 | Open Issues: 0\nGitHub Pages\nNo README available for this project.\n",
        "summary": "\u003ch1 id=\"weiseriesmdc1c2c3\"\u003ewei.series.md.c1.c2.c3\u003c/h1\u003e\n\u003cp\u003eWeibull series system estimation from data with censored lifetimes and masked component cause of failure.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/wei.series.md.c1.c2.c3\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 2 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://queelius.github.io/wei.series.md.c1.c2.c3/\"\u003eGitHub Pages\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eNo README available for this project.\u003c/em\u003e\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "reliability-estimation-in-series-systems",
        "link": "http://localhost:1313/ghprojects/reliability-estimation-in-series-systems/",
        "date": "2023-07-13 09:25:36 +0000 UTC",
        "content": "reliability-estimation-in-series-systems Reliability Estimation in Series Systems: Maximum Likelihood Techniques for Right-Censored and Masked Failure Data\nGitHub Link\nStars: 1 | Forks: 0 | Open Issues: 0\nGitHub Pages\nNo README available for this project.\n",
        "summary": "\u003ch1 id=\"reliability-estimation-in-series-systems\"\u003ereliability-estimation-in-series-systems\u003c/h1\u003e\n\u003cp\u003eReliability Estimation in Series Systems: Maximum Likelihood Techniques for Right-Censored and Masked Failure Data\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/reliability-estimation-in-series-systems\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 1 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://queelius.github.io/reliability-estimation-in-series-systems/\"\u003eGitHub Pages\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eNo README available for this project.\u003c/em\u003e\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "a-boolean-algebra-over-trapdoors",
        "link": "http://localhost:1313/posts/trapdoor-boolean-model/",
        "date": "2023-06-17 00:00:00 +0000 UTC",
        "content": "This project is available on GitHub.\nBoolean Algebra A Boolean algebra is a mathematical structure that captures the properties of logical operations and sets. Formally, it is defined as a 6-tuple $(B, \\land, \\lor, \\neg, 0, 1)$, where\n$B$ is a set of elements, $\\land$ ($\\rm{and}$) and $\\lor$ $\\rm{or}$ are binary operations on $B$, $\\neg$ ($\\rm{not}$) is a unary operation on $B$, $0$ and $1$ are elements of $B$, often referred to as the minimum and maximum elements, respectively. These components must satisfy certain axioms, including closure of $B$ under the operations, commutativity, associativity, distributivity, and the existence of identity and complement elements [1].\nBoolean algebras have far-reaching application. They form the foundation of propositional logic and are fundamental to the design of digital circuits and computer architecture [2].\nIn set theory, a common representation of a Boolean algebra is the power set of a set $X$, denoted $\\mathcal{P}(X)$, with the following correspondence:\n$B = \\mathcal{P}(X)$, $\\land = \\cap$ (set intersection), $\\lor = \\cup$ (set union), $\\neg = \\complement$ (set complement), $0 = \\emptyset$ (empty set), $1 = X$ (universal set). This set-theoretic Boolean algebra, $(\\mathcal{P}(X), \\cap, \\cup, \\complement, \\emptyset, X)$, is a canonical example of a Boolean algebra. It will be the starting point for our exploration of an Boolean algebra over trapdoors [3]. This structure will maintain the familiar properties of Boolean algebras while introducing cryptographic elements for secure computations and data structures.\nHomomorphisms in Boolean Algebra A key concept in our exploration of trapdoor Boolean algebras is that of a homomorphism. In abstract algebra, a homomorphism is a structure-preserving map between two algebraic structures of the same type. In the context of Boolean algebras, a homomorphism is a function that preserves the operations and special elements of the Boolean algebra.\nGiven two Boolean algebras $(A, \\land_A, \\lor_A, \\neg_A, 0_A, 1_A)$ and $(B, \\land_B, \\lor_B, \\neg_B, 0_B, 1_B)$, a function $f: A \\to B$ is a Boolean algebra homomorphism if for all $x, y \\in A$:\n$f(x \\land_A y) = f(x) \\land_B f(y)$ $f(x \\lor_A y) = f(x) \\lor_B f(y)$ $f(\\neg_A x) = \\neg_B f(x)$ $f(0_A) = 0_B$ $f(1_A) = 1_B$ In other words, a homomorphism preserves the structure of the Boolean algebra across the mapping. This preservation of structure is crucial as it allows us to perform operations in one Boolean algebra and have them correspond meaningfully to operations in another Boolean algebra [4].\nHomomorphisms play a vital role in our construction of trapdoor Boolean algebras. They allow us to create a mapping between our original Boolean algebra and a new structure that incorporates cryptographic elements, while still maintaining the essential properties of a Boolean algebra. This preservation of structure ensures that operations performed in our trapdoor Boolean algebra still behave in ways that are logically consistent with standard Boolean operations.\nIn the following sections, we will introduce a specific homomorphism $F$ that maps elements from our original Boolean algebra to a Boolean algebra over bit strings, incorporating a cryptographic hash function. This homomorphism will be the foundation of our Boolean algebra over trapdoors, allowing us to perform Boolean operations in a way that leverages cryptographic properties.\nThe Bernoulli Model Before we introduce our Bernoulli homomorphism, it\u0026rsquo;s crucial to understand the underlying framework: the Bernoulli model.\nThe Bernoulli model is a probabilistic framework for representing and reasoning about approximations of values (where a value can be anything from a set, whether the set is something simple like $\\{\\rm{true}, \\rm{false}\\}$ or the set of functions of type $X \\to Y$ (we call these Bernoulli maps in the general case).\nIt introduces a kind of controlled uncertainty into computations, allowing for trade-offs between accuracy and other desirable properties such as space efficiency or security.\n$$ B_{\\mathcal{T}}. $$$$ \\Pr\\bigl\\\\{B_{\\mathcal{T}}(x) \\neq x \\bigr\\\\} = \\epsilon(x). $$We may want to discuss the number of ways in which the Bernoulli Model can introduce errors. For a first-order Bernoulli model, $\\epsilon(x) = \\epsilon$ for all $x \\in \\mathcal{T}$, i.e., it is a constant (and usually known) probability. In this case, we say that the order of the Bernoulli model is $k=1$. For instance, if we had a noisy binary symmetric channel, we might have $\\epsilon = 0.1$ for a given channel, and so whenever we observe a value from the channel, we know that there is a 10% chance the value is erroneous. For higher-order models, $\\epsilon : \\mathcal{T} \\mapsto [0,1]$ represents error probabilities under different conditions.\nKey properties of the Bernoulli Model include:\nPropagation of uncertainty: When operations are performed on Bernoulli approximations, the uncertainties combine in well-defined ways.\nTrade-off between accuracy and other properties: By adjusting the probabilities, we can balance accuracy against other desirable characteristics of our system.\nGeneralization to complex types: The Bernoulli model can be applied to simple types like Boolean values, as well as to more complex types including functions and algebraic structures.\nIn the context of our work on an approximate Boolean algebra over trapdoors, the Bernoulli Model provides a framework for analyzing and reasoning about the behavior of our cryptographic constructions.\nA Boolean Algebra Over Free Semigroups $$ A := (\\mathcal{P}\\bigl(X^{\\*}), \\land = \\cap, \\lor = \\cup, \\neg = \\complement, 0 = \\emptyset, 1 = X^{\\*}\\bigr) $$$$ \\\\# : X^{\\*} \\times X^{\\*} \\mapsto X^{\\*}. $$$$ X = \\\\{a,b\\\\} $$$$ X^{\\*} = \\\\{\\epsilon, a, b, aa, ab, ba, bb, aaa, aab, \\ldots \\\\} $$$$ \\mathcal{P}(X^\\*) = \\bigl\\\\{\\emptyset, \\\\{\\epsilon\\\\}, \\\\{a\\\\}, \\\\{b\\\\}, \\\\{aa\\\\}, \\ldots, \\\\{\\epsilon,a\\\\}, \\ldots, \\\\{a,a,babb\\\\}, \\ldots \\bigr\\\\}, $$ where $\\epsilon$ is the empty string.\nCommonly, for Boolean alebras over finite sets, one approach is to represent sets with bit strings of length $n$ and map each set to a unique bit string, e.g., the mapping $\\mathbb{A} \\mapsto a_1 \\ldots a_n$ where bit $a_j = 1$ if the $j$-th element (according to some ordering) is in $\\mathbb{A}$ and otherwise $a_j = 0$. If we have $n$ bits, we can uniquely represent up to $2^n$ sets.\nIn our case, we have a Boolean albebra over the infinitely large free semigroup $X^{*}$. Our intention is to stick with the finite bit string representation, and say that the representation contains a type of controllable error on membership queries known as the the false positive rate (which is the probability that an element not in the set falsely tests positive for membership), assuming that elements are selected randomly from the free semigroup $X^{*}$.\nConceptually, we have an approximate Boolean algebra over the free semigroup $X^{*}$. We map element in $X^{*}$ to a bit string in $\\{0,1\\}^2$ using a cryptographic hash function $h : X^{*} \\mapsto \\{0,1\\}^2$ such that if we randomly choose two elements in $X^{*}$, the probability that they map (hash) to the same value (collide) is $2^{-n}$. Collisions are the fundamental source of error in our model and what also qualifies the approximate Boolean algebra as a Bernoulli Model process.\nApproximate Boolean Algebra Over Trapdoors $$ B := \\bigl(\\\\{0,1\\\\}^n, \\\\\u0026, |, \\sim, 0^n, 1^n\\bigr) $$ where $\\\u0026amp;$, $|$, and $\\sim$ are defined on $\\{0,1\\}^n$ as the bitwise $\\operatorname{and}$, $\\operatorname{or}$, and $\\operatorname{not}$ operations respectively. We have a homomorphism $F$ defined as \\begin{align*} F (\\cap) \u0026amp;= |,\\\\ F (\\cup) \u0026amp;= \\\u0026amp;\\\\ F (\\complement) \u0026amp;= \\sim,\\\\ F (\\emptyset) \u0026amp;= 0^n,\\\\ F (X^{*}) \u0026amp;= 1^n,\\\\ F (\\{x_{j_1}, \\ldots, x_{j_k}\\}) \u0026amp;= 0^n | h(x_{j_1}) | \\cdots | h(x_{j_k}), \\end{align*} where $h : X^{*} \\mapsto \\{0,1\\}^n$ is a cryptographic hash function, $s \\in X^{*}$ is a secret, and $\\{x_{j_1}, \\ldots, x_{j_k}\\} \\subseteq X^{*}$.\nThe operations in $A$ are set operations, while the operations in $B$ are bitwise operations. For example, suppose $x,y \\in \\mathcal{P}(X^{*})$ and $y \\subset x$. If $F(x) = 0110$ and $F(y) = 0010$, then $F(x \\land_A y) = F(x) \\land_B F(y) = 0110 | 0010 = 00010 = F(y)$.\nWe assume $h$ uniformly distributes over $\\{0,1\\}^n$, which means that the apriori probability of a collision between two elements is $2^{-n}$. This is a fundamental property of cryptographic hash functions that we leverage in our construction.\nIf we map $A$ to $B$ using (approximate) homomorphism $F$ and then apply the same sequence of operations in both $A$ and $B$, we obtain some representation of the resultant set in $B$ for the ground truth in $A$. However, if we query $A$ and $B$ for membership of an element, we may find that there is a discrepancy between the results. We also find that the homomorphism $F$ itself is approximate in the negation operation, i.e., $F(\\neg_A x) \\neq \\neg_B F(x)$.\nThese discrepenancies are a consequence of the finite number ($2^n$) of bit strings used to represent the elements $\\mathcal{P}(X^{*})$ in the Boolean algebra $A$. As a result, we say that the Boolean algebra $B$ is an approximate Boolean algebra when used to computationally model operations in $A$. The approximation error is a controllable parameter that we can adjust by changing the number of bits ($n$) in the representations. Different types of queries or operations are associated with different error rates, so we can adjust $n$ to suit the specific requirements of our system.\nThe cryptographic hash function $h$ is a one-way function that allows us to map elements from $X^{*}$ to $\\{0,1\\}^n$ in a way that is computationally infeasible (even impossible, since the mapping is non-injective) to reverse. This property is crucial for the security of our construction, as it ensures that the original elements in $X^{*}$ cannot be easily reconstructed from their bit string representations. Since $F$ uses $h$ in its construction, it is an (approximate) one-way homomorphism $F$ that maps Boolean algebra $A$ a Boolean algebra $B$ over (one-way) trapdoors.\nHomomorphism Properties We have two Boolean algebras, $A$ and $B$ as previously described. We seek to model the operations in $A$ in $B$ using the homomorphism $F$. In the proofs to follow, let $X = \\{a,b\\}$ and two particular sets in $\\mathcal{P}(X^{*})$ be $x = \\{a,b,ab\\}$ and $y = \\{b,ab,bb\\}$.\nTo satisfy the properties of a homomorphism, the following properties must hold:\n$F(x \\land_A y) = F(x) \\land_B F(y)$ $F(x \\lor_A y) = F(x) \\lor_B F(y)$ $F(\\neg_A x) = \\neg_B F(x)$ $F(0_A) = 0_B$ $F(1_A) = 1_B$ We show that these properties hold for all the properties except the third, which is not satisfied due to the approximate nature of the Boolean algebra over trapdoors. For this reason, we say that $F$ is an approximate Boolean algebra homomorphism. When we use the homomorphism $F$ to map elements from $A$ to $B$, we can perform operations in $A$ and have them correspond to operations in $B, albeit with some approximation error.\nProof of First Property: We seek to prove the identity $F(x \\land_A y) = F(x) \\land_B F(y)$ for the sets $x$ and $y$ defined above using the homomorphism $F$. Starting from the LHS, we have \\begin{align*} F(x \\land_A y) \u0026amp;= F(x \\cap y) \\\\ \u0026amp;= F(\\{b,ab\\}) \\\\ \u0026amp;= 0^n | h(b) | h(ab). \\end{align*}\n$$ F(x) \\land_B F(y) = \\bigl(h(a) | h(b) | h(ab)\\bigr) \\\\\u0026 \\bigl(h(b) | h(ab) | h(bb)\\bigr). $$$$ F(x) \\land_A F(y) = h(b) | h(ab). $$ Thus, $F(x \\land_A y) = F(x) \\land_B F(y)$, which may be generalized to any two sets $x,y \\in A$. This completes the proof of the first property.\nProof of Second Property: We seek to prove the identity $F(x \\lor_A y) = F(x) \\lor_B F(y)$ for the sets $x$ and $y$ defined above using the homomorphism $F$. Starting from the LHS, we have \\begin{align*} F(x \\lor_A y) \u0026amp;= F(x \\cup y) \\\\ \u0026amp;= F(\\{a,b,ab,bb\\}) \\\\ \u0026amp;= 0^n | h(a) | h(b) | h(ab) | h(bb). \\end{align*}\n$$ F(x) \\lor_B F(y) = \\bigl(0^n | h(a) | h(b) | h(ab)\\bigr) | \\bigl(0^n | h(b) | h(ab) | h(bb)\\bigr). $$$$ F(x) \\lor_B F(y) = 0^n | 0^n | h(a) | h(b) | h(b) | h(ab) | h(ab) | h(bb). $$$$ F(x) \\lor_B F(y) = 0^n | h(a) | h(b) | h(ab) | h(bb). $$ Thus, $F(x \\lor_A y) = F(x) \\lor_B F(y)$. This result generalizes to any two sets $x,y \\in A$. This completes the proof of the second property.\nProof of Fourth Property: We seek to prove the identity $F(0_A) = 0_B$. The proof is trivial, as the empty set $0_A = \\emptyset$ maps to the all-zero bit string $0_B = 0^n$ by definition of the homomorphism $F$: $F(0_A) = F(\\emptyset) = 0^n = 0_B$. This completes the proof of the fourth property.\nProof of Fifth Property: We seek to prove the identity $F(1_A) = 1_B$. The proof is also trivial, as the universal set $1_A = X^{*}$ maps to the all-one bit string $1_B = 1^n$ by definition of the homomorphism $F$:\n$$ F(\\\\{a,b,ab\\\\} \\land_A \\\\{b,ab,bb\\\\}) = F^{-1}(F(\\\\{a,b,ab\\\\}) \\land_B F(\\\\{b,ab,bb\\\\}), $$ since $F$ is one-way and has no inverse. Moreover, and related to this non-invertibility, we now show that the third property does not hold due to the properties of the cryptographic hash function $h$ used by the homomorphism $F$.\nDisproof of Third Property: We seek to disprove the identity $F(\\neg_A x) = \\neg_B F(x)$ for the set $x$ defined above using the homomorphism $F$. Starting from the LHS, we have \\begin{align*} F(\\neg_A x) \u0026amp;= F(x^\\complement) \\\\ \u0026amp;= F(X^{*} \\setminus \\{a,b,ab\\}), \\end{align*} which is an infinite set that includes all elements in $X^{*}$ except $a$, $b$, and $ab$. It includes elements like $bb$, $aaaaabbabababa$, $\\epsilon$, and so on.\n$$ F(\\neg_A x) = 0^n | h(bb) | h(aaaabbbabababa) | \\cdots, $$$$ F(\\neg_A x) = 1^n. $$$$ \\neg_B F(x) = \\sim \\bigl(0^n | h(a) | h(b) | h(ab)\\bigr). $$$$ \\neg_B F(x) \\neq 1^n. $$ Thus, $F(\\neg_A x) \\neq \\neg_B F(x)$, which demonstrates that the third property does not hold. As a result, we say that $F$ is an approximate Boolean algebra homomorphism. As $|x|$ (size of $x$) increases, the probability that $F(\\neg_A x) = 0^n$ goes to $1$, which is also true for $F(\\neg_A x)$. Asymptotically, as $|x| \\to \\infty$, the third property holds. This completes the disproof of the third property.\nSingle-Level Hashing Scheme In the next section, Two-Level Hashing Scheme, we will introduce a two-level hashing scheme that reduces the space complexity of the single-level hashing scheme. In this section, we derive the space complexity of the single-level hashing scheme for representing free semigroups as \u0026ldquo;dense\u0026rdquo; bit strings of size $n$. We will find that, in order to keep the false positive rates on membership ($\\in_B$) and subset ($\\subseteq_B$) constant, the number of bits $n$ in the hash must grow exponentially with the number of elements in the set. This exponential growth limits the scalability of the scheme to very small sets. However, the two-level hashing scheme will address this limitation by reducing the space complexity for practical applications. We derive the space complexity of the single-level hashing scheme first because it is of theoretical interest and provides a foundation for the two-level hashing scheme.\nRelational Predicates In this section, we view the Boolean algebra in a set-theoretic context. We then define some predicates that are fundamental to the algebra, namely membership and subset relations.\nSet Membership $$ \\in_A : X^{\\*} \\times 2^{X^{\\*}} \\mapsto \\mathrm{bool} $$$$ a \\in_A b := 1_b(a), $$ where $1_b$ is the set indicator function.\n$$ \\in_B : \\\\{0,1\\\\}^n \\times \\mathcal{P}(\\\\{0,1\\\\}^n) \\mathrm{bool} $$$$ a \\in_B b := a \\land_B b = a. $$This just means we test for membership by testing that if $h(a)$ has a bit set (to 1), that bit must also be set in $h(b)$. This permits false positives, i.e., $a \\in_B b$ may test as true even if $a \\notin_A b$.\n$$ (F \\emptyset) \\lor_B (F \\\\{a\\\\}) = 0^n | h(a) = h(a). $$$$ (F X) \\lor_B (F \\\\{a\\\\}) = 0^n | h(a) = 1^n. $$$$ (F \\\\{a\\\\}) \\lor_B (F \\\\{b\\\\}) = h(a) | h(b). $$Let us denote the hash of $\\{a\\}$ as $Y$ and the hash of $\\{b\\}$ as $Z$. The probability that the $j$-th bit is set to $1$ in $Y$ is $1/2$ and the probability that the $j$-th bit is set to $1$ in $Z$ is also $1/2$. The probability that the $j$-th bit is set to $1$ in $X = Y \\lor_B Z$ is the probability that the $j$-th bit is set to 1 in either $Y$ or $Z$: \\begin{align*} \\Pr\\{ X_j = 1\\} \u0026amp;= \\Pr\\{Y_j | Z_j = 1\\}\\ \u0026amp;= \\Pr\\{(Y_j = 1) \\lor (Z_j = 1)\\}. \\end{align*}\n$$ \\Pr\\\\{Y_j = 1 \\lor Z_j = 1\\\\} = 1 - \\Pr\\\\{Y_j = 0\\\\} \\Pr\\\\{Z_j = 0\\\\}, $$$$ \\Pr\\\\{Y_j = 1 \\lor Z_j = 1\\\\} = 1 - 2^{-2}. $$$$ \\Pr\\\\{X_j = 1\\\\} = 1 - 2^{-k}. $$$$ \\Pr\\\\{X_j = 1\\\\} \\approx e^{-1/2^k}. $$$$ \\Pr\\\\{X = 1^n\\\\} = \\prod_{j=1}^{n} \\Pr\\\\{X_j = 1\\\\} = \\bigl(1 - 2^{-k}\\bigr)^n \\approx e^{-n/2^k}. $$Since $e^{-n/2^k} \\to 1$ as $k \\to \\infty$, the union of $k$ singleton sets converges in probability to the universal set $1^n$. When we have the universal set, we have reached a stationary point in the union operation, and further unions will not change the result.\nWe use these results to compute the probability of a false positive in the membership and subset relations in the next section.\nFalse Negatives and False Positives Suppose that we have a set $W$ and we want to ask if a randomly chosen element $x \\in X$ is a member of $W$. Let us denote the hash of $x$ as $h$ and the $j$-th bit as $h_j$. If $x$ actually is a member of $W$, then all of the bits where $F x$ is set to to $1$ will, by construction, be set to $1$ in $F W$. The probability of a false negative is $0$.\n$$ h_j = 1 \\implies W_j = 1. $$$$ \\lnot ( h_j = 1 \\land W_j = 0 ). $$We are interested in computing the probability of this event: \\begin{align*} \\Pr\\{\\lnot ( h_j = 1 \\land W_j = 0)\\} \u0026amp;= 1 - \\Pr\\{h_j = 1 \\land W_j = 0\\} \\\\ \u0026amp;= 1 - \\Pr\\{h_j = 1 \\} \\Pr\\{W_j = 0\\}. \\end{align*}\n$$ \\Pr\\\\{h_j = 1\\\\} = 1/2. $$$$ \\Pr\\\\{\\lnot ( h_j = 1 \\land W_j = 0)\\\\} = 1 - 2^{-(k+1)}. $$ where $k$ is the number of elements in $W$.\nFor $x$ to be a false positive, this implication must hold for all $n$ bit positions: \\begin{align*} \\varepsilon \u0026amp;= \\Pr\\{\\text{$x \\in W$ is a false positive}\\}\\\\ \u0026amp;= \\prod_{j=1}^{n} \\Pr\\{\\lnot ( h_j = 1 \\land W_j = 0)\\}\\\\ \u0026amp;= \\prod_{j=1}^{n} (1 - 2^{-(k+1)})\\\\ \u0026amp;= (1 - 2^{-(k+1)})^n. \\end{align*}\nAsymptotic False Positive Rate $$ \\varepsilon_{\\in} = (1 - 2^{-(k+1)})^n, $$$$ \\varepsilon_{\\in} \\approx e^{-n 2^{-(k+1)}}, $$$$ \\varepsilon_{\\in} = e^{\\mathcal{O}(2^{-k})}, $$ which indicates that $\\varepsilon$ approaches 1 exponentially fast as $k$ increases.\nSpace Complexity $$ n = \\frac{\\log \\varepsilon}{\\log(1 - 2^{-(k+1)})}. $$$$ n \\approx \\frac{\\log \\varepsilon}{2^{-(k+1)}}. $$$$ n = \\mathcal{O}(2^k), $$ which means that to maintain a fixed error rate, the number of bits in the hash must grow exponentially with the number of elements in the set. This exponential growth limits the scalability of the scheme to very small sets.\nWe demonstrated that the probability of a false positive is a function of the number of elements $k$ in the set and the number of bits $n$ in the representation. Unsuprisingly, the probability of a false positive increases as the number of elements in the set $k$ increases and as the number of bits in the hash $n$ decreases, but now we have a probabilistic model that quantifies this relationship.\nIn Figure 1, the false positive rate decreases exponentially as the byte size of the hash increases for smaller sets of elements (k=4 to k=10). In Figure 2, we observe the false positive rate behavior over larger kilobyte sizes for larger sets (k=12 to k=16). The green dashed line represents the 5% false positive rate threshold. As k increases, achieving this threshold requires significantly more space, highlighting the trade-off between set size and hash size.\nSubset Relation $$ \\subseteq_A : 2^{X^{\\*}} \\mapsto 2^{X^{\\*}} \\mapsto \\mathrm{bool} $$$$ a \\subseteq_A b := \\forall x \\in a, x \\in b. $$$$ \\subseteq_B : \\\\{0,1\\\\}^n \\times \\\\{0,1\\\\}^n \\mapsto \\\\{0,1\\\\} $$$$ a \\subseteq_B b := a | b = a, $$ which is identical to the set-indicator function. However, they have different error probabilities.\n$$ W_j = 1 \\implies X_j = 1, $$$$ \\lnot ( W_j = 1 \\land X_j = 0 ). $$ The probability of this event is given by \\begin{align*} \\Pr\\{\\lnot ( W_j = 1 \\land X_j = 0)\\} \u0026amp;= 1 - \\Pr\\{W_j = 1 \\land X_j = 0\\} \\\\ \u0026amp;= 1 - \\Pr\\{W_j = 1 \\} \\Pr\\{X_j = 0\\} \\\\ \u0026amp;= 1 - \\Pr\\{W_j = 1 \\} \\Pr\\{X_j = 0\\}. \\end{align*} Recall that after $k$ union operations, the $j$-th bit in a set is $0$ with probability $2^{-k}$, therefore \\begin{align*} \\Pr\\{\\lnot ( W_j = 1 \\land X_j = 0)\\} \u0026amp;= 1 - \\Pr\\{W_j = 1 \\} \\Pr\\{X_j = 0\\} \\\\ \u0026amp;= 1 - (1 - 2^{-k_1}) 2^{-k_2}, \\end{align*} where $k_1$ and $k_2$ are the number of elements in $W$ and $X$ respectively.\nFor $W \\subseteq X$ to be a false positive, this implication must hold for all $n$ bit positions: \\begin{align*} \\varepsilon \u0026amp;= \\Pr\\{\\text{$W \\subseteq X$ is a false positive}\\}\\\\ \u0026amp;= \\prod_{j=1}^{n} 1- (1 - 2^{-k_1}) 2^{-k_2}\\\\ \u0026amp;= \\bigl(1 - (1 - 2^{-k_1}) 2^{-k_2}\\bigr)^n. \\end{align*}\n$$ \\varepsilon_{\\subseteq} \\approx e^{-n (1 - 2^{-k_1}) 2^{-k_2}}, $$$$ \\varepsilon_{\\subseteq} \\approx e^{-n e^{-(k_1 + k_2 \\log 2)}}. $$$$ \\varepsilon_{\\subseteq} = e^{\\mathcal{O}(e^{-m})}, $$ where $m = k_1 + k_2 \\log 2$. This indicates that $\\varepsilon_{\\subseteq}$ approaches 1 exponentially fast as $m$ increases for a fixed $n$. This result is consistent with the earlier analysis of the false positive rate for the membership relation.\nSince equality can be written as $A \\subseteq B \\land B \\subseteq A$, the false positive rate for the equality relation is the product of the false positive rates for the subset relations in both directions.\nTwo-Level Hashing Scheme In previous sections, we derived the space complexity of a single-level hashing scheme for representing free semigroups as \u0026ldquo;dense\u0026rdquo; bit strings of size $n$. We found that, in order to keep the false positive rates on membership ($\\in_B$) and subset ($\\subseteq_B$) constant, the number of bits $n$ in the hash must grow exponentially with the number of elements in the set. This exponential growth limits the scalability of the scheme. To address this limitation, we introduce a two-level hashing scheme that reduces the space complexity for practical applications.\nThe two-level hashing scheme is a hierarchical structure that partitions the elements of the set into smaller subsets. For efficiency and compatability with existing hashing algorithms, when we hash an element, we do the following construction:\nWe have a hash function that outputs $q$ bits. The first $w$ bits of the hash are used to determine the subset (bin) to which the element belongs, $2^w$ subsets in total. The remaining $q-w$ bits of the hash are used to represent the element within the subset. We have $2^w$ bins and $q-w$ bits for each bin, resulting in a total of $n = 2^w(q-w)$ bits. This two-level hashing scheme allows us to reduce the number of bits in the hash for a given false positive rate $\\varepsilon$. Let us derive the false positive rate for this construction, denoted as $\\varepsilon(w,q)$.\nFalse Positive Rate Membership Relation Assume $k$ elements are in the set already, and we seek to test membership of an element $x$ in it. False negatives do not occur, as before, but a false positive occurs if the following condition holds:\nWith probability $2^{-w}$, it maps to some particular subset. In that subset, represented by $n-w$ bits, there are expected to be $k / 2^w$ elements. We use the earlier derivation to find the probability of a false positive in the subset: $$ \\varepsilon(k,w,q) = (1 - 2^{-(k / 2^w + 1)})^{q-w}. $$$$ \\varepsilon(k) = e^{\\mathcal{O}(2^{-k})}, $$ which asymptotically is the same as the single-level hashing scheme. However, in practice, this is much more practical for reasonably large sets.\nThe space complexity of the two-level hashing scheme is given by $n = 2^w (q-w)$ bits for a false positive rate of $\\varepsilon(k,w,q)$, or equivalently, $m = 2^w (q-w) / k$ bits per element for a false positive rate of $\\varepsilon(k,w,q)$.\nIn Figure 3, we show the false positive rate for different values of $w$ and $q$.\nC++ Implementation: Single-Level Hashing Scheme We can implement a C++ class that models the Boolean algebra over trapdoors. We generalize the concept of trapdoors to any type $X$, which we also parameterize over the size of the hash $N$.\n$$ B_{\\mathrm{X' \\times X' \\mapsto \\mathrm{bool}}}(=(X',X')) $$ where $X\u0026rsquo;$ is a trapdoor of type $X$ and the latent value is the equality predicate.\nWe model it as a Boolean algebra over bit strings, where the operations are the bitwise $\\operatorname{and}$, $\\operatorname{or}$, and $\\operatorname{not}$ operations. We also define the equality operator, which returns a Bernoulli Boolean that represents a Boolean value indicating if the trapdoors are equal with a false positive rate of $2^{-8 N}$, and\nThe trapdoor_set\u0026lt;X,N\u0026gt; class represents an approximate Boolean algebra over trapdoors (of type X), as we previously discussed. It is a specialization of trapdoor\u0026lt;X,N\u0026gt; that implements additional opoerations that can take place over the domain of trapdoor\u0026lt;X,N\u0026gt; and trapdoor_set\u0026lt;X,N\u0026gt;:\nempty_trapdoor_set\u0026lt;X,N\u0026gt;() returns an empty set ($0_B$). universal_trapdoor_set\u0026lt;X,N\u0026gt;() returns a universal set ($1_B$). operator+(trapdoor_set\u0026lt;X,N\u0026gt; const \u0026amp; x, trapdoor_set\u0026lt;X,N\u0026gt; const \u0026amp; y) returns the union of two sets ($\\lor_B$). operator~(trapdoor_set\u0026lt;X,N\u0026gt; const \u0026amp; x) returns the complement of a set ($\\neg_B$). operator*(trapdoor_set\u0026lt;X,N\u0026gt; const \u0026amp; x, trapdoor_set\u0026lt;X,N\u0026gt; const \u0026amp; y) returns the intersection of two sets ($\\land_B$). empty(trapdoor_set\u0026lt;X,N\u0026gt; const \u0026amp; xs) returns a Bernoulli Boolean that represents a Boolean value that is true if the set is empty with a false positive rate. Essentially, it is the probability that the hash of the set is zero, $0_B$, which occurs with a false positive rate $\\varepsilon = 2^{-8 N}$. in(trapdoor\u0026lt;X,N\u0026gt; const \u0026amp; x, trapdoor_set\u0026lt;X,N\u0026gt; const \u0026amp; xs) returns a Bernoulli Boolean that represents a Boolean value that is true if the set contains the element with a false positive rate. See the section Relational Predicates in the Single-Level Hashing Scheme section for more details. The class trapdoor_set is a template class that takes a type X and a size N as template arguments. The class has a value_hash member that is an array of char of size N. The class has a default constructor that initializes the value_hash to zero. The class has a copy constructor that is defaulted. The class has two static member functions empty_trapdoor_set and universal_trapdoor_set that return an empty set and a universal set, respectively. The class has three overloaded operators +, !, and * that implement the union ($\\lor_B$), complement ($\\lnot_B$), and intersection ($\\land_B$) operations, respectively.\nFor closure, the class has a hash member function that returns a hash of the set, which is just the hash already stored in it. This means we can compose these operations to form more complex operations, like creating a powerset of trapdoor_set objects.\n#include \u0026lt;array\u0026gt; template \u0026lt;typename X, size_t N\u0026gt; struct trapdoor { using value_type = X; /** * The constructor initializes the value hash to the given value hash. * Since the hash is a cryptographic hash, the hash is one-way and so we * cannot recover the original value from the hash. * * This also models the concept of an Oblivious Type, where the true value * is latent and we permit some subset of operations on it. In this case, * the only operation we permit is the equality and hashing operations. * * @param value_hash The value hash. */ trapdoor(std::array\u0026lt;char, N\u0026gt; value_hash) : value_hash(value_hash) {} /** * The default constructor initializes the value hash to zero. This value * often denotes a special value of type X, but not necessarily. */ trapdoor() { value_hash.fill(0); } std::array\u0026lt;char, N\u0026gt; value_hash; }; /** * The hash function for the trapdoor class. It returns the value hash. */ template \u0026lt;typename X, size_t N\u0026gt; auto hash(trapdoor const \u0026amp; x) { return x.value_hash; } /** * Basic equality operator. It returns a Bernoulli Boolean that represents * a Boolean value indicating if the trapdoors are equal with a false positive rate * of 2^{-8 N}. Different specializes of the trapdoor class may have different * false positive rates, but this is a reasonable default value. */ template \u0026lt;typename X, size_t N\u0026gt; auto operator==(trapdoor const \u0026amp; lhs, trapdoor const \u0026amp; rhs) const { return bernoulli\u0026lt;bool\u0026gt;{lhs.value_hash == rhs.value_hash, -8*N}; } /** * The `or` operation in the Boolean algebra over bit strings. */ template \u0026lt;typename X, size_t N\u0026gt; auto lor(trapdoor lhs, trapdoor const \u0026amp; rhs) { for (size_t i = 0; i \u0026lt; N; ++i) lhs.value_hash[i] |= rhs.value_hash[i]; return lhs; } /** * The `and` operation in the Boolean algebra over bit strings. */ template \u0026lt;typename X, size_t N\u0026gt; auto land(trapdoor lhs, trapdoor const \u0026amp; rhs) { for (size_t i = 0; i \u0026lt; N; ++i) lhs.value_hash[i] \u0026amp;= rhs.value_hash[i]; return lhs; } /** * The `not` operation in the Boolean algebra over bit strings. */ template \u0026lt;typename X, size_t N\u0026gt; auto lnot(trapdoor x) { for (size_t i = 0; i \u0026lt; N; ++i) lhs.value_hash[i] = ~lhs.value_hash[i]; return lhs; } template \u0026lt;typename T\u0026gt; auto minimum() { return std::numeric_limits\u0026lt;T\u0026gt;::min(); } template \u0026lt;typename T\u0026gt; auto maximum() { return std::numeric_limits\u0026lt;T\u0026gt;::max(); } /** * The `minimum` operation in the Boolean algebra over trapdoors */ template \u0026lt;typename trapdoor\u0026lt;typename X, size_t N\u0026gt;\u0026gt; auto minimum() { return trapdoor\u0026lt;X,N\u0026gt;(); } /** * The `maximum` operation in the Boolean algebra over trapdoors */ template \u0026lt;typename trapdoor\u0026lt;typename X, size_t N\u0026gt;\u0026gt; auto maximum() { trapdoor\u0026lt;X,N\u0026gt; x; x.value_hash.fill(std::numeric_limits\u0026lt;char\u0026gt;::min()) return x; } /** * The trapdoor_set class models an approximate Boolean algebra over trapdoors. * It is a specialization of the trapdoor class that implements additional operations * that can take place over the domain of trapdoor and trapdoor_set. */ template \u0026lt;typename X, size_t N\u0026gt; struct trapdoor_set: public trapdoor\u0026lt;X,N\u0026gt; { trapdoor_set( double low_k = 0, double high_k = std::numeric_limits\u0026lt;double\u0026gt;::infinity()), std::array\u0026lt;char, N\u0026gt; value_hash) : trapdoor\u0026lt;trapdoor_set\u0026lt;X,N\u0026gt;,N\u0026gt;(value_hash), low_k(low_k), high_k(high_k) {} trapdoor_set() : trapdoor\u0026lt;trapdoor_set\u0026lt;X,N\u0026gt;,N\u0026gt;(), low_k(0), high_k(0) {} trapdoor_set(trapdoor_set const \u0026amp;) = default; trapdoor_set \u0026amp; operator=(trapdoor_set const \u0026amp;) = default; double low_k; double high_k; }; /** * The size (cardinality) of the latent set (the set the trapdoor_set represents). * * @param xs The trapdoor_set. * @return The size range of the set. */ template \u0026lt;typename X, size_t N\u0026gt; auto size(trapdoor_set\u0026lt;X,N\u0026gt; const \u0026amp; xs) { return std::make_pair(xs.low_k, xs.high_k); } /** The union operation. */ template \u0026lt;typename X, size_t N\u0026gt; auto operator+( trapdoor_set\u0026lt;X,N\u0026gt; const \u0026amp; xs, trapdoor_set\u0026lt;X,N\u0026gt; const \u0026amp; ys) { return trapdoor_set\u0026lt;X,N\u0026gt;(lor(xs, ys).value_hash, std::max(xs.low_k, ys.low_k), xs.high_k + ys.high_k); } template \u0026lt;typename X, size_t N\u0026gt; void insert(trapdoor\u0026lt;X,N\u0026gt; const \u0026amp; x, trapdoor_set\u0026lt;X,N\u0026gt; \u0026amp; xs) { for (size_t i = 0; i \u0026lt; N; ++i) xs.value_hash[i] |= x.value_hash[i]; // since x could already be in xs, we do not increment the low_k // only the high_k xs.high_k += 1; } template \u0026lt;typename X, size_t N\u0026gt; auto operator~(trapdoor_set\u0026lt;X,N\u0026gt; x) { for (size_t i = 0; i \u0026lt; N; ++i) x.value_hash[i] = ~x.value_hash[i]; // assume |x| in [a, b] // then |~x| has the following analysis. // - if |x| = a, then |~x| = |U| - a, where |U| is universal set // - if |x| = b, then |~x| = |U| - b // so, |~x| in [|U|-b, |U|-a] x.low_k = maximum\u0026lt;X\u0026gt;() - x.high_k; x.high_k = maximum\u0026lt;X\u0026gt;() - x.low_k; return x; } template \u0026lt;typename X, size_t N\u0026gt; auto operator*( trapdoor_set\u0026lt;X,N\u0026gt; const \u0026amp; x, trapdoor_set\u0026lt;X,N\u0026gt; const \u0026amp; y) { return trapdoor_set\u0026lt;X\u0026gt;(x.value_hash \u0026amp; y.value_hash, 0, // intersection could be empty std::min(x.high_k, y.high_k) // one could be a subset of the other ); } template \u0026lt;typename X, size_t N\u0026gt; bernoulli\u0026lt;bool\u0026gt; in(trapdoor\u0026lt;X,N\u0026gt; const \u0026amp; x, trapdoor_set\u0026lt;X,N\u0026gt; const \u0026amp; xs { for (size_t i = 0; i \u0026lt; N; ++i) if ((x.value_hash[i] \u0026amp; xs.value_hash[i]) != x.value_hash[i]) return bernoulli\u0026lt;bool\u0026gt;{true, 0}; // earlier, we showed that the fp rate is (1 - 2^{-k})^n return bernoulli\u0026lt;bool\u0026gt;{false, }; } /** * The subseteq_B predicate, x \\subseteq_B y, is defined as x | y = x. * It has an false positive rate of eps = (1 - 2^{-(k_1 + k_2 log 2)})^n * which we approxiate as eps ~ e^{-n e^{-(k_1 + k_2 log 2)}}. * we store the log(eps) instead: -n e^{-(k_1 + k_2 log 2)} */ template \u0026lt;typename X\u0026gt; bernoulli\u0026lt;bool\u0026gt; operator\u0026lt;=( trapdoor_set\u0026lt;X\u0026gt; const \u0026amp; x, trapdoor_set\u0026lt;X\u0026gt; const \u0026amp; y) { for (size_t i = 0; i \u0026lt; N; ++i) if ((x.value_hash[i] \u0026amp; y.value_hash[i]) != x.value_hash[i]) { return bernoulli\u0026lt;bool\u0026gt;(false, 0); // false negative rate is 0 } // earlier, we showed that the fp rate is (1 - 2^{-(k_1 + k_2 log 2)})^n return bernoulli\u0026lt;bool\u0026gt;{true, }; } template \u0026lt;typename X\u0026gt; bernoulli\u0026lt;bool\u0026gt; operator==( trapdoor_set\u0026lt;X\u0026gt; const \u0026amp; x trapdoor_set\u0026lt;X\u0026gt; const \u0026amp; y) { for (size_t i = 0; i \u0026lt; N; ++i) if (x.value_hash[i] != y.value_hash[i]) return bernoulli\u0026lt;bool\u0026gt;{false, 0.5}; } Appendix Marginal Uniformity $$ \\Pr{}_D\\\\{a\\\\} $$$$ \\Pr\\\\{h(a)\\\\} \\approx \\Pr\\\\{h(b)\\\\} $$ even if $\\Pr{}_D\\{a\\}$ and $\\Pr{}_D\\{b\\}$ are significantly different.\nWhen we do a membership query, we uniformly sample one of these representations so that the unigram distribution of elements in $\\{0,1\\}$ is uniform. This is a kind of marginal uniformity that is a property of the transformation $F$.\nHowever, this approach has serious shortcomings:\nOnly the marginal distribution of unigrams are uniformly distributed. Correlations in the joint distributions of the free semigroup $X^{*}$, such as bigrams, are not accounted for. We can apply this transformation to larger sequences, but the space complexity grows exponentially with the length of the sequence for a fixed false positive rate. In practice, for large $X$, even the unigram model may need to be approximated due to space limitations.\nWhen we apply the Boolean operations on an untrusted system, it cannot be given the information about the distribution of the elements in $X$. This means that Boolean operations like $\\land$ and $\\lor$ cannot be performed on the untrusted system, only relational querieslike $\\in$ and $\\subseteq$.\n",
        "summary": "\u003cp\u003eThis project is available on \u003ca href=\"https://github.com/queelius/bernoulli_data_type/boolean-algebra-trapdor/\"\u003eGitHub\u003c/a\u003e.\u003c/p\u003e\n\u003ch2 id=\"boolean-algebra\"\u003eBoolean Algebra\u003c/h2\u003e\n\u003cp\u003eA Boolean algebra is a mathematical structure that captures the properties of logical operations and sets. Formally, it is defined as a 6-tuple $(B, \\land, \\lor, \\neg, 0, 1)$, where\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e$B$ is a set of elements,\u003c/li\u003e\n\u003cli\u003e$\\land$ ($\\rm{and}$) and $\\lor$ $\\rm{or}$ are binary operations on $B$,\u003c/li\u003e\n\u003cli\u003e$\\neg$ ($\\rm{not}$) is a unary operation on $B$,\u003c/li\u003e\n\u003cli\u003e$0$ and $1$ are elements of $B$, often referred to as the minimum and maximum elements, respectively.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThese components must satisfy certain axioms, including closure of $B$ under the operations, commutativity, associativity, distributivity, and the existence of identity and complement elements [1].\u003c/p\u003e",
        "tags": null,
        "section": "posts"
      },{
        "title": "bernoulli",
        "link": "http://localhost:1313/categories/bernoulli/",
        "date": "2023-06-17 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "bernoulli-model",
        "link": "http://localhost:1313/categories/bernoulli-model/",
        "date": "2023-06-17 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "bloom-filter",
        "link": "http://localhost:1313/categories/bloom-filter/",
        "date": "2023-06-17 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "boolean",
        "link": "http://localhost:1313/categories/boolean/",
        "date": "2023-06-17 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "cognitive-science",
        "link": "http://localhost:1313/tags/cognitive-science/",
        "date": "2023-06-17 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "compression",
        "link": "http://localhost:1313/categories/compression/",
        "date": "2023-06-17 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "cryptography",
        "link": "http://localhost:1313/categories/cryptography/",
        "date": "2023-06-17 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "llm",
        "link": "http://localhost:1313/tags/llm/",
        "date": "2023-06-17 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "philosophy",
        "link": "http://localhost:1313/categories/philosophy/",
        "date": "2023-06-17 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "regularization",
        "link": "http://localhost:1313/tags/regularization/",
        "date": "2023-06-17 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "uses-and-limits-of-abstractions",
        "link": "http://localhost:1313/posts/uses-and-limits-of-abstractions/",
        "date": "2023-06-17 00:00:00 +0000 UTC",
        "content": "I\u0026rsquo;m been thinking about the power and limitations of abstractions in our understanding of the world. This blog post is from a chat I had with a ChatGPT, which can be found here and here.\nI\u0026rsquo;m not sure if this is a good blog post, but I\u0026rsquo;m posting it anyway. It\u0026rsquo;s remarkable how quickly you can slap stuff like this together, and I\u0026rsquo;m not sure this is saying anything valuable, particularly since it only required a bit of prompting from me.\nUses and limits of abstractions Reality, in all its richness, is far more complex than we can appreciate. Our attempts to understand and navigate it necessitate the use of abstractions, compressions that retain the salient details relevant to a specific context while discarding the rest. These abstractions are indispensable to human cognition, enabling us to engage with parts of reality despite our limited cognitive capacity and incomplete information, but there are also parts of reality that may be fundamentally off-limits to us.\nLimited working memories Human cognitive abilities are bounded. For instance, our working memory can effectively hold and process only a limited amount of information at once. Cognitive psychology often references the \u0026ldquo;magic number seven\u0026rdquo;, suggesting that most adults can hold between five and nine items in their working memory.\nConsider a situation where we\u0026rsquo;re dealing with multiple variables $(x_1, x_2, x_3, x_4)$. Our brain might struggle to simultaneously process the joint distribution of these variables due to the limitation of our working memory. However, if we create an abstraction where $X$ represents $(x_1, x_2)$ and $Y$ represents $(x_3, x_4)$, we simplify the cognitive task to handling the joint distribution of just two variables $(X,Y)$, which is a more manageable task. This constraint necessitates the use of abstractions in order to understand complex systems.\nIncomplete information Beyond our cognitive limitations, we also lack complete information about any real-world system. We cannot have total information about the systems we\u0026rsquo;re trying to understand.\nAgain, we may use abstractions to deal with this limitation, abstractions that allow us to think more clearly about some parts of the system (that can be observed and usefully reduced) while ignoring other parts (that are not observable or not usefully compressible). For instance, a key concept in statistical mechanics is entropy, which allows us to reason about the behavior of systems with a large number of particles that behave according to some statistical regularties in the aggregate. We might be able to observe certain features of a system, such as the size of a box and its temperature, but there\u0026rsquo;s much we don\u0026rsquo;t know, such as the microstates the system is in at a given moment.\nHowever, knowing the temperature and size of the box, we can make useful predictions about the system, such as what its temperature in one hour will be, or whether it will explode if we add a certain amount of heat to it. We can ask certain questions about it, but we cannot ask questions that require knowing the microstate of the system. And, ultimately, everything about the system is determined by its microstate, and so there are many questions we cannot answer.\nEntropy allows us to reason about the system using available observations, while acknowledging the underlying complexity that we can\u0026rsquo;t observe or don\u0026rsquo;t yet understand. More generally, despite our limited understanding and inability to perceive the entirety of a complex system, we still aim to make meaningful assertions about it. This is where the role of abstractions, like entropy, becomes particularly significant, acting as a cognitive scaffold that allows us to grasp some aspects of the system\u0026rsquo;s behavior.\n$$ H(X) = -\\sum_{x \\in X} p(x) \\log p(x), $$ where $X$ is a random variable and $p(x)$ is the probability of $X$ taking on the value $x$. When dealing with microstates and supposing that each state is equally probable (which is a reasonable approximation in the case of a gas-filled box), entropy \u0026ldquo;simplifies\u0026rdquo; to the logarithm of the number of different states the system can be in that are compatible with what we can observe about the system.\nEmergent behavior It\u0026rsquo;s important to remember, however, that such reasoning can only get us so far. Some systems have a complexity that is fundamentally irreducible, characterized by emergent behavior that can only be discerned when considering the system as a whole. This is related to our limited working memories, and our need for creating abstractions to work-around our limitations. However, there are some systems that are so complex that they cannot be reduced to simpler parts. The behavior of the system as a whole is not just the sum of the behavior of its parts, but is something new and different. This is known as emergent behavior, and it is a key feature of many complex systems.\nConsider the earlier example, where we were dealing with multiple variables $(x_1, x_2, x_3, x_4)$ and reduced it to just two variables $(X,Y)$, where $X = (x_1, x_2)$ and $Y = (x_3, x_4)$. This abstraction is useful in many contexts, but it is not always appropriate. For instance, if $x_1$ and $x_4$ are correlated in some significant way, perhaps only in the distant future, then the reduction to $X$ and $Y$ may fail to capture this salient feature. In this case, to understand the important parts of the system that we are interested in, we need to consider the joint distribution of the full set of variables $(x_1, x_2, x_3, x_4)$.\nA popular example is \u0026ldquo;water is wet\u0026rdquo;. This is a true statement, but it is not true of any of the individual molecules that make up water. It is an emergent property of the system as a whole, in which billions of these simple molecules interact in locally simple ways. The wetness of water is not a property of the individual molecules, but an emergent property of the system as a whole.\nIt may even the case that something like consiousness is an emergent property in an even more complex way, such that it cannot be reduced to the behavior of individual neurons or small groups of neruons, but only emerges as a property of the integrated behavior of the entire brain. Indeed, we may be talking about a system with $(x_1, x_2, \\ldots, x_n)$, $n = \\mathcal{O}(\\text{# neurons})$.\nLet\u0026rsquo;s consider again the concept of entropy. The representation of a system, such that it cannot be significantly compressed without losing vital information, may be said to have emerget properties. The earlier example of a box of gas is a good example that can be significantly compressed by considering only its temperature and dimensions. Knowing that information allows us to say a lot about the system. Systems for which a useful compression is not possible may be said to have emergent properties. When this is the case, we cannot compress the system in a way that fits our cognitive limitations, or in a way that is not sensitive to a lack of knowlege.\nThis is why consciousnes may feel so mysterious and inexplicable, because we cannot understand it, we cannot reduce it to a simpler system that we can, say, program on a computer using our cognition. (This is where machine learning, deep learning, LLMs, and so on become particularly relevant for solving problems that are too complex for us to solved analytically.)\nAbstractions as cognitive scaffolds Abstractions are indispensable to human cognition, enabling us to engage with reality despite our limited cognitive capacity. They allow us to reason about complex systems, even when we lack complete information about them. They also allow us to communicate with others, sharing ideas and knowledge across fields and disciplines. In creating abstractions, we walk a delicate balance. We need to remember these key aspects:\nImperfect representation\nAbstractions are, by design, reductions of reality. While they help us manage complexity, most will fail to capture all the necessary information. As our needs evolve, we find ourselves tweaking the abstraction, adding layers of complexity that can make it harder to reason about and thereby diluting its initial utility. There is a constant balancing act in maintaining simplicity while preserving relevance.\nThis is also known as \u0026ldquo;the map is not the territory\u0026rdquo; problem. The map is a useful representation of the territory, but it is not the territory itself.\nAbstractions are contextual\nThey are useful in certain contexts but not in others. We must be aware of the context in which we are using an abstraction and understand its limitations. We must also be aware of the context in which the abstraction was created and the assumptions that were made in its creation. This is particularly important when using abstractions from other fields.\nPedagogical\nWhile an abstraction might not always provide an accurate representation of the object in real-world settings, it serves a valuable educational purpose. It enables us to learn key features about the object and acts as a bootstrap technique for further understanding. Even when ready-made abstractions fall short in our context, we can use principles of reductionism, analogy, and more to grapple with the complexity. Yet, we must remember that many phenomena are cross-cutting or emergent and cannot be fully understood through this process.\nCommunication\nAbstractions are a key tool for communication. They allow us to share ideas and knowledge with others, even those outside our field. However, since an expert is often aware of the many nuances and limitations of an abstraction, they might not be the best person to explain it to a novice. It\u0026rsquo;s important to frequently ask, \u0026ldquo;How could I explain this to a five-year-old?\u0026rdquo; This helps us stay grounded, facilitates cross-pollination of ideas, and allows for broader comprehension.\nThese pointes demonstrate a dance between simplicity and complexity that we engage in when creating and using abstractions. Like a map, an abstraction is not the territory but a simplified representation of it. As we journey through the landscape of knowledge, these representations guide us, helping us \u0026lsquo;see the forest for the trees\u0026rsquo;, even as we acknowledge their inherent limitations.\nConclusion Abstractions are indispensable to human cognition, enabling us to engage with reality despite our limited cognitive capacity and incomplete information. They allow us to reason about complex systems, even when we lack complete information about them. They also allow us to communicate with others, sharing ideas and knowledge across fields and disciplines.\nHowever, we must be cognizant of the limitations of abstractions. They are, by design, reductions of reality. While they help us manage complexity, most will fail in some way. Much of reality may, in fact, be computationally irreducible (to borrow a phrase from Wolfram).\n",
        "summary": "\u003cp\u003eI\u0026rsquo;m been thinking about the power and limitations of abstractions in our\nunderstanding of the world. This blog post is from a chat I had with a ChatGPT,\nwhich can be found \u003ca href=\"https://chat.openai.com/share/f298898b-9787-48f4-8959-c8cd04eb98b4\"\u003ehere\u003c/a\u003e\nand \u003ca href=\"https://chat.openai.com/share/0d33ab33-0664-4b25-b1c2-22864b28db48\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eI\u0026rsquo;m not sure if this is a good blog post, but I\u0026rsquo;m posting it anyway. It\u0026rsquo;s remarkable\nhow quickly you can slap stuff like this together, and I\u0026rsquo;m not sure this is\nsaying anything valuable, particularly since it only required a bit of prompting\nfrom me.\u003c/p\u003e",
        "tags": null,
        "section": "posts"
      },{
        "title": "working-memory-as-an-inductive-bias",
        "link": "http://localhost:1313/posts/working-memory-as-an-inductive-bias/",
        "date": "2023-06-17 00:00:00 +0000 UTC",
        "content": "This blog post is from a chat I had with a ChatGPT, which can be found here and here.\nI\u0026rsquo;m not sure if this is a good blog post, but I\u0026rsquo;m posting it anyway. It\u0026rsquo;s remarkable how quickly you can slap stuff like this together, and I\u0026rsquo;m not sure this is saying anything valuable, particularly since it only required a bit of prompting from me.\nWorking memory as an inductive bias Human cognitive abilities, while remarkable, are bounded. Our working memory can effectively hold and process only a limited amount of information at once. Cognitive psychology often references the \u0026ldquo;magic number seven\u0026rdquo;, suggesting that most adults can hold between five and nine items in their working memory. This constraint necessitates the use of abstractions in order to understand complex systems.\nConsider a situation where we\u0026rsquo;re dealing with multiple variables $(x_1, x_2, x_3, x_4)$. Our brain might struggle to simultaneously process the joint distribution of these variables due to the limitation of our working memory. However, if we create an abstraction where $X$ represents $(x_1, x_2)$ and $Y$ represents $(x_3, x_4)$, we simplify the cognitive task to handling the joint distribution of just two variables $(X,Y)$, which is a more manageable task.\nBut heres the rub: In condensing reality to fit our cognitive capacities, we risk losing vital information. For instance, a critical relationship (that may only be critical in a certain context) between $x_2$ and $x_4$ might be discarded in our new model. This often leads to the situation where \u0026ldquo;the whole is greater than the sum of the parts.\u0026rdquo; In other words, the full, nuanced understanding of the system may be irreducible, with important aspects of its behaviour emerging only when all variables are considered together. Such emergent phenomena represent a key challenge in working with abstractions.\nWorking Memory and Inductive Bias Our small working memory influences our reasoning abilities and shapes our understanding of the world around us, in effect serving as an inductive bias. It\u0026rsquo;s like a filter, shaping the patterns we detect and the generalizations we form based on the information we encounter.\nThis constraint, however, might not be entirely detrimental. It could even be an advantage, given the regularities in our reality. Think of it as a form of regularization in machine learning, where constraints prevent the model from overfitting the training data, thereby improving generalization to unseen instances. If we had much larger working memories, we might be prone to overfitting to our past observations, impairing our ability to adapt and survive in new situations, particularly those on the \u0026rsquo;long tail of the distribution\u0026rsquo;. Our survival, after all, depends on avoiding catastrophic mistakes, even after decades of mostly beneficial decisions.\nThis perspective aligns with principles like Occam\u0026rsquo;s razor and Solomonoff\u0026rsquo;s theory of inductive inference, which favor simpler theories or models that sufficiently explain observed phenomena. The complexity of the model, and thus its capacity, is regulated to avoid overfitting and ensure better generalization.\nThe Limits of Our Understanding The inductive bias imposed by our limited working memory might be advantageous in the human niche, but it\u0026rsquo;s essential to consider its potential shortcomings. Could there be aspects of reality that remain inaccessible to us due to our cognitive constraints?\nTake, for instance, the phenomenon of consciousness. Understanding how self-awareness arises in a system may require accounting for the joint distribution of an astronomical number of variables. If this complexity is irreducible, our cognitive apparatus, bound by its inductive bias, may simply be inadequate for fully comprehending consciousness.\nIndeed, it\u0026rsquo;s conceivable that vast swaths of reality might be fundamentally off-limits to human cognition, forever obscured by the constraints of our cognitive architecture. The complexity of these phenomena may defy simplification, making them impervious to our attempts at understanding through abstractions.\nAs we strive to push the boundaries of understanding, we should remain mindful of the limits imposed by our cognitive capacities and the constraints of our abstractions.\nThe Unconscious Mind and LLMs In my next blog post, I\u0026rsquo;ll explore unconscious cognition, which makes up most of our mental activity (system 1 vs system 2 thinking), and the recent progress in machine learning, partciularly transformers and the LLM revolution.\n",
        "summary": "\u003cp\u003eThis blog post is from a chat I had with a ChatGPT,\nwhich can be found \u003ca href=\"https://chat.openai.com/share/f298898b-9787-48f4-8959-c8cd04eb98b4\"\u003ehere\u003c/a\u003e\nand \u003ca href=\"https://chat.openai.com/share/0d33ab33-0664-4b25-b1c2-22864b28db48\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eI\u0026rsquo;m not sure if this is a good blog post, but I\u0026rsquo;m posting it anyway. It\u0026rsquo;s remarkable\nhow quickly you can slap stuff like this together, and I\u0026rsquo;m not sure this is\nsaying anything valuable, particularly since it only required a bit of prompting\nfrom me.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003cimg src=\"./featured.png\" style=\"width: 200px; float: left; margin: 10px;\"\u003e\n\u003ch2 id=\"working-memory-as-an-inductive-bias\"\u003eWorking memory as an inductive bias\u003c/h2\u003e\n\u003cp\u003eHuman cognitive abilities, while remarkable, are bounded. Our working memory can effectively hold and process only a limited amount of information at once. Cognitive psychology often references the \u0026ldquo;magic number seven\u0026rdquo;, suggesting that most adults can hold between five and nine items in their working memory. This constraint necessitates the use of abstractions in order to understand complex systems.\u003c/p\u003e",
        "tags": ["Cognitive Science","Machine Learning","LLM","Regularization"],
        "section": "posts"
      },{
        "title": "dfr_dist",
        "link": "http://localhost:1313/ghprojects/dfr_dist/",
        "date": "2023-06-16 09:56:38 +0000 UTC",
        "content": "dfr_dist Dynamic failure rate distributions (DFR)\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nLanguages Used: R\nGitHub Pages\nREADME R package dfr.dist: dynamic failure rate (DFR) distributions Installation Usage R package dfr.dist: dynamic failure rate (DFR) distributions An R package for working with models in survival analysis in which the distribution is parameterized by a very flexible failure rate function (any function that satisfies properties like being non-negative, integrating to infinity over the domain, and having a support of (0, Inf).\nInstallation You can install the development version of dfr.dist from GitHub repo with:\n# install.packages(\u0026#34;devtools\u0026#34;) devtools::install_github(\u0026#34;queelius/dfr_dist\u0026#34;) Usage The R packge dfr_dist provides an API for specifying and estimating dynamic failure rate distributions. They can depend on the data in any way, as the failure rate is any function of time and any set of predictors, as long as the failure rate satsifies two key properties:\nIts non-negative. It is not meaningful to have a negative failure rate; the failure rate can decrease some times, and even go to , though.\nAt the limit as goes to infinity, the cumulative hazard also goes to infinity:\nwhere . If this constraint isnt satisfied, then the survival function is not well-defined, since it is defined as .\nThe dfr_dist object satisfies all of the requirements of an algebraic distribution (see algebraic.dist) and a likelihoood model (see likelihood.model).\nThe package is designed to be used with the algebraic.mle package, which provides a framework for performing maximum likelihood estimation (MLE).\nA vignette showing how to use it is here.\n",
        "summary": "\u003ch1 id=\"dfr_dist\"\u003edfr_dist\u003c/h1\u003e\n\u003cp\u003eDynamic failure rate distributions (DFR)\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/dfr_dist\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: R\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://queelius.github.io/dfr_dist/\"\u003eGitHub Pages\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#r-package-dfrdist-dynamic-failure-rate-dfr-distributions\"\u003eR package \u003ccode\u003edfr.dist\u003c/code\u003e: dynamic failure rate (DFR)\ndistributions\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#installation\"\u003eInstallation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#usage\"\u003eUsage\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- README.md is generated from README.Rmd. Please edit that file --\u003e\n\u003ch2 id=\"r-package-dfrdist-dynamic-failure-rate-dfr-distributions\"\u003eR package \u003ccode\u003edfr.dist\u003c/code\u003e: dynamic failure rate (DFR) distributions\u003c/h2\u003e\n\u003c!-- badges: start --\u003e\n\u003c!-- badges: end --\u003e\n\u003cp\u003eAn R package for working with models in survival analysis in which the\ndistribution is parameterized by a very flexible failure rate function\n(any function that satisfies properties like being non-negative,\nintegrating to infinity over the domain, and having a support of \u003ccode\u003e(0, Inf)\u003c/code\u003e.\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "likelihood.model.series.md",
        "link": "http://localhost:1313/ghprojects/likelihood.model.series.md/",
        "date": "2023-06-12 19:18:49 +0000 UTC",
        "content": "likelihood.model.series.md Likelihood model for series systems with masked component cause of failure and other censoring mechanisms\nGitHub Link\nStars: 1 | Forks: 0 | Open Issues: 0\nLanguages Used: R\nREADME R Package: likelihood.model.series.md This is an R package for estimating the parameters of a series system model from masked data. It provides a flexible and intuitive interface for specifying the model and performing maximum likelihood estimation.\nThis R package provides a set of functions for generating MLEs for the lifetime parameters of the components in a series systems and other related characteristics from data that masks the component cause of failure, and also the system lifetime.\nMasked data comes in a variety of forms:\nThe system lifetime can be masked in three related ways. Right censoring occurs when the system under observation is only known to have survived for some minimum length of time. Left censoring occurs when the system under observation is only know to have survived for some maximum length of time. Finally, interval censoring occurs when the system under observation is only known to have survived between some minimum and maximum length of time.\nIn the unmasked situation, we know precisely how long the system under observation survived.\nRegardless of how the series system lifetime is masked, the lifetime of the components may be masked in any of the ways described in item (1). There is, additionally, another kind of masking we would like to consider. What if we do not observe any of the component lifetimes, and instead are only given a (potentially masked) series system lifetime, and a candidate set of component indexes which plausibly contains the failed component index.\nFor a series system of components, the candidate sets are subsets of .\nInstallation You can install the development version from GitHub with:\ndevtools::install_github(\u0026#34;queelius/likelihood.model.series.md\u0026#34;) Usage This package provides a comprehensive framework for maximum likelihood estimation (MLE) of series system parameters from masked data.\nIt is based on a likelihood contribution model, where each kind of masking of component failures in a series system of some kind and number of components is handled by a set of likelihood contributions. The likelihood contributions are then combined to form the likelihood model for the kind of data and series system under consideration.\nIn general, masking models may characaterized by satisfy any (or none) of the following conditions:\nCondition 1: The probability that the failed component is in the candidate set is 1.\nCondition 2: Given a candidate set of potential causes of failure, when we condition on the component cause being any one of the components in the candidate set at the given system failure time, the probability of the candidate set is uniform.\nCondition 3: The distribution of candidate sets conditioned on a system failure time and a component cause of failure is independent of the system parameter vector.\nWe provide several kinds of masking models, including:\nUninformed candidate sets that satisfy conditions 1, 2, and 3.\nCandidate sets with relaxed conditions, e.g., informed candidate sets.\nTogether, these masking models provide a flexible framework for handling a wide variety of masking situations.\nWe also provide a method for analyzing the sensitivity of a likelihood model to violations of the masking assumptions. This is done by providing a set of likelihood models that are constructed by relaxing the masking assumptions in various ways. The likelihood models are then compared using the likelihood ratio test.\nOther kinds of data and censoring are handled separately by the general likelihood model as detailed in likelihood.model. This is the general framework for adding various kinds of contributions to the likelihood model. This package is focused on providing contributions for masking. The likelihood.model package provides a robust API to work with likelihood models, e.g., for finding MLEs, bootstrapping confidence intervals, and so on.\nWe also provide for data imputation, synthetic (implicit prior) data, and so on. These are often based on the conditions the model assumes, and so are provided in this package.\nAPI When we construct a likelihood contribution model, we so so by specifying the contributions of each observation type. For example, if we have a series system with three components, and we observe the system lifetime and the lifetimes of the first two components, we would specify the likelihood contributions as follows:\nmy_model \u0026lt;- likelihood_contr_model$new( obs_type = function(df) { ifelse(df$right_censoring, \u0026#34;exact_fail_time_with_cand_set_c1_c2_c3\u0026#34;, \u0026#34;right_censored\u0026#34;) }, logliks = list( ... ) ) Now, we may call, for instance, fit(my_model, data) to fit the model. We provide a default method for fit based on MLE, but you can also provide your own method, e.g., based on a customized algorithm for efficiently finding estimates for a particular type of series system for particular types of data.\nRegardless of the outcome, ideally it will return an mle-like object (from the algebraic.mle package), in which case a host of additional methods are available to you, such as predict, confint, sample, etc. This object makes it easy to perform various analyses on your fitted model.\naic(fit) bias(fit) vcov(fit) predict(fit, new_data) confint(fit) sample(fit, method = \u0026#34;asymptotic\u0026#34;, n = 1000) Note that the likelihood.model.series.md package provides a number of likelihood contributions for common observation types. These are described in the package documentation. You can also provide your own likelihood contributions, and we provide a number of functions to make this easier.\nAssumptions Some of the models in this package make explicit assumptions about the data. We provide various functions to help you check these assumptions, to impute data that satisfies these assumptions, and to generate fake data that satisfies these assumptions.\nSometimes, we generate fake data to create an implicit prior distribution for the parameters.\nModel Selection We provide some wrappers for model selection, such as AIC, BIC, and so on. We also provide specializations and constraint functions for the parameters.\nFor example, we may have a strong belief that the components are Weibull distributed, and furthermore, that they are more or less on the same scale with slight differences in shape. In this case, we can simplify the model by assuming and then only fitting and , reducing a parameter model to a simpler parameter model. This is not an unrealistic assumption, since if a series system is well-designed, then the components should be more or less on the same scale (i.e., have approximately the same MTTF).\nBootstrapping Statistics of the MLE and Likleihood Mode To estimate various characteiristcs, such as the bias, BCa confidence intervals, etc, then bootstraping may be used. The likelihood.md.series.systems package relies upon the bootstrapping functionality in boot and likelihood.model, but provide special functions and methods that are particular to the masked data series system context.\nParametric Models A general series system model, and other kinds of series systems, are also handled by external libraries, such as the Dynamic Failure Rate library, which can be used to construct hazard functions for components that may depend on predictors, including time, any other covariates.\nDocumentation For more detailed information on how to use this package and what each function does, please refer to the package documentation. The series_system function and its parameters are described in detail there.\nContributing Contributions are welcome! Please open an issue or submit a pull request on GitHub if you find any bugs or if youd like to suggest improvements.\n",
        "summary": "\u003ch1 id=\"likelihoodmodelseriesmd\"\u003elikelihood.model.series.md\u003c/h1\u003e\n\u003cp\u003eLikelihood model for series systems with masked component cause of failure and other censoring mechanisms\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/likelihood.model.series.md\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 1 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: R\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003c!-- README.md is generated from README.Rmd. Please edit that file --\u003e\n\u003ch1 id=\"r-package-likelihoodmodelseriesmd\"\u003eR Package: \u003ccode\u003elikelihood.model.series.md\u003c/code\u003e\u003c/h1\u003e\n\u003cp\u003eThis is an R package for estimating the parameters of a series system\nmodel from masked data. It provides a flexible and intuitive interface\nfor specifying the model and performing maximum likelihood estimation.\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "chatgpt-pysearch",
        "link": "http://localhost:1313/ghprojects/chatgpt-pysearch/",
        "date": "2023-06-11 08:03:50 +0000 UTC",
        "content": "chatgpt-pysearch No description available.\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nLanguages Used: HTML, Python, CSS, Procfile\nGitHub Pages\nREADME ChatGPT chat search This was the first python app I developed in quite some time. I wanted to host ChatGPT logs, experiment with heroku, and see how easy it would be to develop the search app using nothing but ChatGPT. I\u0026rsquo;ve hosted the entire chat log that directly generated this app in this repo. It\u0026rsquo;s nothing special, but it\u0026rsquo;s interesting to see my early efforts at using ChatGPT.\nYou can see the chat log here: https://queelius.github.io/chatgpt-pysearch/index.html\nThe herok app is hosted here: https://chatgpt.metafunctor.com/\n",
        "summary": "\u003ch1 id=\"chatgpt-pysearch\"\u003echatgpt-pysearch\u003c/h1\u003e\n\u003cp\u003eNo description available.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/chatgpt-pysearch\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: HTML, Python, CSS, Procfile\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://queelius.github.io/chatgpt-pysearch/\"\u003eGitHub Pages\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003ch1 id=\"chatgpt-chat-search\"\u003eChatGPT chat search\u003c/h1\u003e\n\u003cp\u003eThis was the first python app I developed in quite some time. I wanted to host ChatGPT logs, experiment with heroku, and see how easy it would be to develop the search app using nothing but ChatGPT. I\u0026rsquo;ve hosted the entire chat log that directly generated this app in this repo. It\u0026rsquo;s nothing special, but it\u0026rsquo;s interesting to see my early efforts at using ChatGPT.\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "bernoulli-model",
        "link": "http://localhost:1313/projects/bernoulli-model/",
        "date": "2023-06-10 00:00:00 +0000 UTC",
        "content": "",
        "summary": "A general framework for constructing and working with Bernoulli models.",
        "tags": ["probabilistic-data-structures","bernoulli-model","bloom-filter","c++","bernoulli-data-type","bernoulli-set","bernoulli-map","bernoulli-algorithm","bernoulli-boolean","algorithms"],
        "section": "projects"
      },{
        "title": "bernoulli-algorithm",
        "link": "http://localhost:1313/tags/bernoulli-algorithm/",
        "date": "2023-06-10 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "bernoulli-boolean",
        "link": "http://localhost:1313/tags/bernoulli-boolean/",
        "date": "2023-06-10 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "bernoulli-data-type",
        "link": "http://localhost:1313/tags/bernoulli-data-type/",
        "date": "2023-06-10 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "bernoulli-map",
        "link": "http://localhost:1313/tags/bernoulli-map/",
        "date": "2023-06-10 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "bernoulli-model",
        "link": "http://localhost:1313/tags/bernoulli-model/",
        "date": "2023-06-10 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "bernoulli-set",
        "link": "http://localhost:1313/tags/bernoulli-set/",
        "date": "2023-06-10 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "bloom-filter",
        "link": "http://localhost:1313/tags/bloom-filter/",
        "date": "2023-06-10 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "c++",
        "link": "http://localhost:1313/tags/c++/",
        "date": "2023-06-10 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "probabilistic-data-structures",
        "link": "http://localhost:1313/tags/probabilistic-data-structures/",
        "date": "2023-06-10 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "likelihood.model",
        "link": "http://localhost:1313/ghprojects/likelihood.model/",
        "date": "2023-06-03 05:48:59 +0000 UTC",
        "content": "likelihood.model Likelihood model framework\nGitHub Link\nStars: 1 | Forks: 0 | Open Issues: 0\nLanguages Used: R, HTML\nGitHub Pages\nREADME Likelihood model R package: likelihood.model The R package likelihood.model is designed for specifying and using likelihood models for statistical inference.\nThe basic likelihood model is a concept that, in order for your object to satisfy, must implement a number of generic functions/methods. The package provides a class, likelihood_contr_model, which implements these functions and serves as a flexible framework for specifying likelihood models based on the idea of independent likelihood contributions for different types of observations, e.g., right-censored versus exact observations.\nThe package is designed to be used with the algebraic.mle package, which provides a framework for performing maximum likelihood estimation (MLE).\nInstallation You can install the development version of likelihood.model from GitHub with:\nif (!require(devtools)) { install.packages(\u0026#34;devtools\u0026#34;) } devtools::install_github(\u0026#34;queelius/likelihood.model\u0026#34;) See the package website for more information.\n",
        "summary": "\u003ch1 id=\"likelihoodmodel\"\u003elikelihood.model\u003c/h1\u003e\n\u003cp\u003eLikelihood model framework\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/likelihood.model\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 1 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: R, HTML\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://queelius.github.io/likelihood.model/\"\u003eGitHub Pages\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003ch1 id=\"likelihood-model\"\u003eLikelihood model\u003c/h1\u003e\n\u003ch1 id=\"r-package-likelihoodmodel\"\u003eR package: \u003ccode\u003elikelihood.model\u003c/code\u003e\u003c/h1\u003e\n\u003cp\u003eThe R package \u003ccode\u003elikelihood.model\u003c/code\u003e is designed for specifying and using\nlikelihood models for statistical inference.\u003c/p\u003e\n\u003cp\u003eThe basic likelihood model is a concept that, in order for your object\nto satisfy, must implement a number of generic functions/methods. The\npackage provides a class, \u003ccode\u003elikelihood_contr_model\u003c/code\u003e, which implements\nthese functions and serves as a flexible framework for specifying\nlikelihood models based on the idea of independent likelihood\ncontributions for different types of observations, e.g., right-censored\nversus exact observations.\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "numerical.mle",
        "link": "http://localhost:1313/ghprojects/numerical.mle/",
        "date": "2023-05-06 22:02:22 +0000 UTC",
        "content": "numerical.mle Numerical MLE solvers\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nLanguages Used: R\nGitHub Pages\nREADME R package: numerical.mle A set of numeric MLE solvers.\nThis is very early alpha. I just started this project and it is not ready for use yet. I just took a bunch of numerical code from algebraic.mle and put it in this separate package. I will be adding more numerical solvers and more examples in the future. Most of the code probably does not even work yet, since I havent tested it.\nInstallation You can install numerical.mle from GitHub with:\ninstall.packages(\u0026#34;devtools\u0026#34;) devtools::install_github(\u0026#34;queelius/numerical.mle\u0026#34;) API A set of methods for fitting log-likelihood functions to data. We provide various adapters for log-likelihood functions, including penalty adapters (for constrained MLEs) and transformation adapters (for transformed MLEs).\nThe object representing a fitted model is a type of mle object, the maximum likelihood estimator of the model with respect to observed data. We use the R package for this purpose. (See here).\nThe API mostly consists of generic methods with implementations for various mle type objects. For a full list of functions, see the function reference for numerical.mle.\nExamples Fitting a linear regression model library(numerical.mle) library(algebraic.mle) ",
        "summary": "\u003ch1 id=\"numericalmle\"\u003enumerical.mle\u003c/h1\u003e\n\u003cp\u003eNumerical MLE solvers\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/numerical.mle\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: R\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://queelius.github.io/numerical.mle/\"\u003eGitHub Pages\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003c!-- README.md is generated from README.Rmd. Please edit that file --\u003e\n\u003ch1 id=\"r-package-numericalmle\"\u003eR package: \u003ccode\u003enumerical.mle\u003c/code\u003e\u003c/h1\u003e\n\u003c!-- badges: start --\u003e\n\u003c!-- badges: end --\u003e\n\u003cp\u003eA set of numeric MLE solvers.\u003c/p\u003e\n\u003cp\u003eThis is very early alpha. I just started this project and it is not\nready for use yet. I just took a bunch of numerical code from\n\u003ccode\u003ealgebraic.mle\u003c/code\u003e and put it in this separate package. I will be adding\nmore numerical solvers and more examples in the future. Most of the code\nprobably does not even work yet, since I havent tested it.\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "locus",
        "link": "http://localhost:1313/ghprojects/locus/",
        "date": "2023-04-19 15:40:35 +0000 UTC",
        "content": "locus Seeing how easy it is to convert an old project on Google App Engine to a modern framework with the help of ChatGPT\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nREADME locus Seeing how easy it is to convert an old project on Google App Engine to a modern framework with the help of ChatGPT\n",
        "summary": "\u003ch1 id=\"locus\"\u003elocus\u003c/h1\u003e\n\u003cp\u003eSeeing how easy it is to convert an old project on Google App Engine to a modern framework with the help of ChatGPT\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/locus\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003ch1 id=\"locus-1\"\u003elocus\u003c/h1\u003e\n\u003cp\u003eSeeing how easy it is to convert an old project on Google App Engine to a modern framework with the help of ChatGPT\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "algorithms",
        "link": "http://localhost:1313/categories/algorithms/",
        "date": "2023-04-10 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "fisher-information-matrix",
        "link": "http://localhost:1313/tags/fisher-information-matrix/",
        "date": "2023-04-10 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "likelihood.model-r-package",
        "link": "http://localhost:1313/projects/likelihood-model/",
        "date": "2023-04-10 00:00:00 +0000 UTC",
        "content": "The R packge likelihood.model provides an API for specifying likelihood models for statistical inference.\nThe basic likelihood model is a concept that, in order for your object to satisfy, must implement a number of functions (generic methods). The package provides two different implementations of the concept:\nlikelihood_contr_model is a flexible framework for specifying likelihood models based on the idea of independent likelihood contributions for different types of observations, e.g., right-censored versus exact observations, or other kinds observations. This model is designed to accomodate more specialized likelihood models, such as series systems with latent commponents which includes ambiguous data about the components, such as masked failure causes.\nlikelihood_name_model provides a convenient wrapper for distribution functions that follow the naming and argument conventions in the R ecosystem, e.g., if we have some distribution norm (normal), then it has dnorm, pnorm, rnorm, and qnorm, respectively for the density function, probability function, sampler, and quantile function for the normal distribution. They also have standard paramenter arguments, like pnorm has a lower.tail Boolean parameter that computes either the CDF if TRUE and otherwise the survival function. Note that this model may be used to provide contributions to likelihood_contr_model.\nThe package is designed to be used with the algebraic.mle package, which provides a framework for performing maximum likelihood estimation (MLE).\n",
        "summary": "An API for constructing and working with likelihood models; works well with \u003ccode\u003ealgebraic.mle\u003c/code\u003e R package",
        "tags": ["maximum-likelihood-estimation","likelihood-models","likelihood-contributions-model","R-package","Fisher-information matrix","data-generating-process","R","statistics"],
        "section": "projects"
      },{
        "title": "likelihood.model.series.md-r-package",
        "link": "http://localhost:1313/projects/likelihood-model-series-md/",
        "date": "2023-04-10 00:00:00 +0000 UTC",
        "content": "R Package: likelihood.model.series.md This is an R package for estimating the parameters of a series system model from masked data. It provides a flexible and intuitive interface for specifying the model and performing maximum likelihood estimation.\nThis R package provides a set of functions for generating MLEs for the lifetime parameters of the components in a series systems and other related characteristics from data that masks the component cause of failure, and also the system lifetime.\nMasked data comes in a variety of forms:\nThe system lifetime can be masked in three related ways. Right censoring occurs when the system under observation is only known to have survived for some minimum length of time. Left censoring occurs when the system under observation is only know to have survived for some maximum length of time. Finally, interval censoring occurs when the system under observation is only known to have survived between some minimum and maximum length of time.\nIn the unmasked situation, we know precisely how long the system under observation survived.\nRegardless of how the series system lifetime is masked, the lifetime of the components may be masked in any of the ways described in item (1). There is, additionally, another kind of masking we would like to consider. What if we do not observe any of the component lifetimes, and instead are only given a (potentially masked) series system lifetime, and a candidate set of component indexes which plausibly contains the failed component index.\nFor a series system of $m$ components, the candidate sets are subsets of ${1,\\ldots,m}$.\nInstallation You can install the development version from GitHub with:\ndevtools::install_github(\u0026#34;queelius/likelihood.model.series.md\u0026#34;) Usage This package provides a comprehensive framework for maximum likelihood estimation (MLE) of series system parameters from masked data.\nIt is based on a likelihood contribution model, where each kind of masking of component failures in a series system of some kind and number of components is handled by a set of likelihood contributions. The likelihood contributions are then combined to form the likelihood model for the kind of data and series system under consideration.\nIn general, masking models may characaterized by satisfy any (or none) of the following conditions:\nCondition 1: The probability that the failed component is in the candidate set is 1.\nCondition 2: Given a candidate set of potential causes of failure, when we condition on the component cause being any one of the components in the candidate set at the given system failure time, the probability of the candidate set is uniform.\nCondition 3: The distribution of candidate sets conditioned on a system failure time and a component cause of failure is independent of the system parameter vector.\nWe provide several kinds of masking models, including:\nUninformed candidate sets that satisfy conditions 1, 2, and 3.\nCandidate sets with relaxed conditions, e.g., informed candidate sets.\nTogether, these masking models provide a flexible framework for handling a wide variety of masking situations.\nWe also provide a method for analyzing the sensitivity of a likelihood model to violations of the masking assumptions. This is done by providing a set of likelihood models that are constructed by relaxing the masking assumptions in various ways. The likelihood models are then compared using the likelihood ratio test.\nOther kinds of data and censoring are handled separately by the general likelihood model as detailed in likelihood.model. This is the general framework for adding various kinds of contributions to the likelihood model. This package is focused on providing contributions for masking. The likelihood.model package provides a robust API to work with likelihood models, e.g., for finding MLEs, bootstrapping confidence intervals, and so on.\nWe also provide for data imputation, synthetic (implicit prior) data, and so on. These are often based on the conditions the model assumes, and so are provided in this package.\nAPI When we construct a likelihood contribution model, we so so by specifying the contributions of each observation type. For example, if we have a series system with three components, and we observe the system lifetime and the lifetimes of the first two components, we would specify the likelihood contributions as follows:\nmy_model \u0026lt;- likelihood_contr_model$new( obs_type = function(df) { ifelse(df$right_censoring, \u0026#34;exact_fail_time_with_cand_set_c1_c2_c3\u0026#34;, \u0026#34;right_censored\u0026#34;) }, logliks = list( ... ) ) Now, we may call, for instance, fit(my_model, data) to fit the model. We provide a default method for fit based on MLE, but you can also provide your own method, e.g., based on a customized algorithm for efficiently finding estimates for a particular type of series system for particular types of data.\nRegardless of the outcome, ideally it will return an mle-like object (from the algebraic.mle package), in which case a host of additional methods are available to you, such as predict, confint, sample, etc. This object makes it easy to perform various analyses on your fitted model.\naic(fit) bias(fit) vcov(fit) predict(fit, new_data) confint(fit) sample(fit, method = \u0026#34;asymptotic\u0026#34;, n = 1000) Note that the likelihood.model.series.md package provides a number of likelihood contributions for common observation types. These are described in the package documentation. You can also provide your own likelihood contributions, and we provide a number of functions to make this easier.\nAssumptions Some of the models in this package make explicit assumptions about the data. We provide various functions to help you check these assumptions, to impute data that satisfies these assumptions, and to generate fake data that satisfies these assumptions.\nSometimes, we generate fake data to create an implicit prior distribution for the parameters.\nModel Selection We provide some wrappers for model selection, such as AIC, BIC, and so on. We also provide specializations and constraint functions for the parameters.\nFor example, we may have a strong belief that the components are Weibull distributed, and furthermore, that they are more or less on the same scale with slight differences in shape. In this case, we can simplify the model by assuming $\\lambda_1 = \\cdots = \\lambda_m$ and then only fitting $\\hat{\\lambda}$ and $\\hat{k}_1, \\ldots, \\hat{k}_m$, reducing a $2 m$ parameter model to a simpler $m+1$ parameter model. This is not an unrealistic assumption, since if a series system is well-designed, then the components should be more or less on the same scale (i.e., have approximately the same MTTF).\nBootstrapping Statistics of the MLE and Likleihood Mode To estimate various characteristcs, such as the bias, BCa confidence intervals, etc, then bootstraping may be used. The likelihood.mode.series.md package relies upon the bootstrapping functionality in boot and likelihood.model, but provide special functions and methods that are particular to the masked data series system context.\nParametric Models A general series system model, and other kinds of series systems, are also handled by external libraries, such as the Dynamic Failure Rate library, which can be used to construct hazard functions for components that may depend on predictors, including time, any other covariates.\nDocumentation For more detailed information on how to use this package and what each function does, please refer the dcoumentation.\nContributing Contributions are welcome! Please open an issue or submit a pull request on GitHub if you find any bugs or if youd like to suggest improvements.\n",
        "summary": "An R package for constructing likelihood models for series systems with masked component cause of failure and other censoring mechanisms.",
        "tags": ["maximum-likelihood-estimation","likelihood-models","likelihood-contributions-model","masked-failure-data","right-censoring","series-systems","bootstrap","R-package","Fisher-information matrix","data-generating-process","R","statistics"],
        "section": "projects"
      },{
        "title": "probabilistic-data-structures",
        "link": "http://localhost:1313/categories/probabilistic-data-structures/",
        "date": "2023-04-10 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "r-package",
        "link": "http://localhost:1313/tags/r-package/",
        "date": "2023-04-10 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "rate-distorted-perfect-hash-filter",
        "link": "http://localhost:1313/projects/rd-ph-filter/",
        "date": "2023-04-10 00:00:00 +0000 UTC",
        "content": "",
        "summary": "A model of a second-order Bernoulli set with false positives and false negatives",
        "tags": ["probabilistic-data-structures","bernoulli-model","algorithms","bloom-filter","c++"],
        "section": "projects"
      },{
        "title": "survival-analysis",
        "link": "http://localhost:1313/categories/survival-analysis/",
        "date": "2023-04-10 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "problem-set-solutions",
        "link": "http://localhost:1313/posts/problem-sets/",
        "date": "2023-03-31 00:00:00 +0000 UTC",
        "content": "I have a fairly broad interest in problem-solving, from problems in statistics to algorithms. Over the years, I\u0026rsquo;ve accumulated a collection of problem sets, which I will be refining and posting here every now and then.\nYou can find these problem sets on various topics here. It\u0026rsquo;s accessible through the menu bar as well. Please note that while I don\u0026rsquo;t claim expertise in all areas, these materials may still provide valuable insights.\n",
        "summary": "\u003cp\u003eI have a fairly broad interest in problem-solving, from problems in statistics\nto algorithms. Over the years, I\u0026rsquo;ve accumulated a collection of problem sets,\nwhich I will be refining and posting here every now and then.\u003c/p\u003e\n\u003cp\u003eYou can find these problem sets on various topics \u003ca href=\"https://metafunctor.com/#prob-sets\"\u003ehere\u003c/a\u003e.\nIt\u0026rsquo;s accessible through the menu bar as well. Please note that while I don\u0026rsquo;t\nclaim expertise in all areas, these materials may still provide valuable insights.\u003c/p\u003e",
        "tags": [],
        "section": "posts"
      },{
        "title": "using-gpt-4-to-build-a-simple-html-file-search-interface",
        "link": "http://localhost:1313/posts/made-chatgpt-to-my-saved-conversations/",
        "date": "2023-03-31 00:00:00 +0000 UTC",
        "content": " This blog post written by GPT-4. See conservation with GPT-4 that built it here. The interface to the browse/search is here. It\u0026rsquo;s really not fancy, but I\u0026rsquo;ve never had much of an interest in doing this kind of front-end work, but GPT-4 makes it pretty easy. Btw, I just realize that I think I forgot to reindex database before submitting, so it doesn\u0026rsquo;t seem to be able to find that conversation except by browsing to it.\nIntroduction In this blog post, I\u0026rsquo;ll walk you through how I built a simple search and browse interface for a set of HTML files using Flask, Whoosh, and the invaluable help of GPT-4, the AI assistant from OpenAI. Together, we tackled several challenges and created a functional and visually appealing solution.\nSetting up the Flask application With GPT-4\u0026rsquo;s guidance, I started by setting up a basic Flask application, which served as the foundation for our search and browse interface.\nIndexing HTML files with Whoosh GPT-4 helped me use the Whoosh library to create an index of the HTML files. I specified a base directory for the HTML files and grouped them accordingly. Whoosh took care of indexing the files and provided a powerful search capability.\nCreating search and browse routes GPT-4 and I implemented search functionality by creating a search route in the Flask app. We also developed a browse route that allowed users to navigate the file hierarchy.\nDisplaying search results and browsing files We created templates to display search results, as well as to browse and view the HTML files. We used the Jinja2 template engine and incorporated the Bootstrap framework to style our interface.\nAdding search history and popular searches To enhance the user experience, we implemented a search history feature that showed the last 10 search queries performed. We also added a popular searches section that persisted across user sessions.\nThroughout the process, GPT-4 provided me with valuable advice, helping me debug issues and implement new features. With GPT-4\u0026rsquo;s assistance, I was able to create a functional search and browse interface for HTML files with ease. Thanks to GPT-4, I now have a practical solution that I can build upon and customize further!\n",
        "summary": "\u003cblockquote\u003e\n\u003cp\u003eThis blog post written by GPT-4. See conservation with GPT-4 that built it\n\u003ca href=\"https://chatgpt.metafunctor.com/browse/gpt4/chat-gpt-python-search-html-files.html\"\u003ehere\u003c/a\u003e.\nThe interface to the browse/search is \u003ca href=\"https://chatgpt.metafunctor.com/\"\u003ehere\u003c/a\u003e.\nIt\u0026rsquo;s really not fancy, but I\u0026rsquo;ve never had much of an interest in doing this\nkind of front-end work, but GPT-4 makes it pretty easy.\nBtw, I just realize that I think I forgot to reindex database before submitting,\nso it doesn\u0026rsquo;t seem to be able to find that conversation except by browsing to it.\u003c/p\u003e",
        "tags": [],
        "section": "posts"
      },{
        "title": "problem_sets",
        "link": "http://localhost:1313/ghprojects/problem_sets/",
        "date": "2023-03-30 07:33:06 +0000 UTC",
        "content": "problem_sets No description available.\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nLanguages Used: Mathematica, HTML, TeX, R, Jupyter Notebook, CSS, C++, JavaScript, Perl\nREADME problem_sets ",
        "summary": "\u003ch1 id=\"problem_sets\"\u003eproblem_sets\u003c/h1\u003e\n\u003cp\u003eNo description available.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/problem_sets\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: Mathematica, HTML, TeX, R, Jupyter Notebook, CSS, C++, JavaScript, Perl\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003ch1 id=\"problem_sets-1\"\u003eproblem_sets\u003c/h1\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "algebraic.mle-r-package",
        "link": "http://localhost:1313/projects/algebraic.mle/",
        "date": "2023-03-29 00:00:00 +0000 UTC",
        "content": "The R package algebraic.mle provides an algebra over Maximum Likelihood Estimators (MLEs). These estimators possess many desirable, well-defined statistical properties which the package helps you manipulate and utilize.\n",
        "summary": "An API for algebraic maximum likelihood fitting",
        "tags": ["maximum-likelihood-estimation","data-generating-process","R-package","R","statistics","data-science","inference","likelihood-models"],
        "section": "projects"
      },{
        "title": "automatic-differentiation",
        "link": "http://localhost:1313/tags/automatic-differentiation/",
        "date": "2023-03-29 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "backpropagation",
        "link": "http://localhost:1313/tags/backpropagation/",
        "date": "2023-03-29 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "computational-graph",
        "link": "http://localhost:1313/tags/computational-graph/",
        "date": "2023-03-29 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "data-science",
        "link": "http://localhost:1313/tags/data-science/",
        "date": "2023-03-29 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "femtograd-r-package",
        "link": "http://localhost:1313/projects/femtograd/",
        "date": "2023-03-29 00:00:00 +0000 UTC",
        "content": "The R package femtograd provides a way of doing automatic differentation. It\u0026rsquo;s not particularly fast, as it was just an experiment, but I may end up using it in my likelihood.model or algebraic.mle packages.\nI will probably optimize it and provide a C++ implementation using Rcpp, but I don\u0026rsquo;t want to spend too much time on it since there are already nice packages that do this.\n",
        "summary": "An R package for backpropagation through a computational graph",
        "tags": ["maximum-likelihood-estimation","R","automatic-differentiation","backpropagation","computational-graph","statistics","data-science","inference","likelihood-models","machine-learning","optimization"],
        "section": "projects"
      },{
        "title": "inference",
        "link": "http://localhost:1313/tags/inference/",
        "date": "2023-03-29 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "likelihood-models",
        "link": "http://localhost:1313/categories/likelihood-models/",
        "date": "2023-03-29 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "model-selection-in-weibull-series-systems",
        "link": "http://localhost:1313/research/reliability-estimation-in-series-systems-model-sel/",
        "date": "2023-03-29 00:00:00 +0000 UTC",
        "content": "The repo on Github contains the prelimniary work. It follows from the Future Work section in the paper, which is here. In particular, it explores the homogenous shape parameter Weiibull series system, which is a simplification of the model and results in a system with a lifetime that is itself Weibull distributed.\nShoot me an email at lex@metafunctor.com if you\u0026rsquo;re interested in collaborating on any projects.\n",
        "summary": "In my paper, Reliability Estimation in Series Systems, I discarded a lot of research that may be interesting to pursue further. This one is about using homogeneous shape parameters for the Weibull series system, which can greatly simplify the analysis and reduce the number of parameters to estimate. It\u0026rsquo;s also quite reasonable for most well-designed systems.",
        "tags": ["maximum-likelihood-estimation","data-generating-process","statistics","siue"],
        "section": "research"
      },{
        "title": "optimization",
        "link": "http://localhost:1313/tags/optimization/",
        "date": "2023-03-29 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "reliability-estimation-in-series-systems",
        "link": "http://localhost:1313/projects/reliability-estimation-in-series-systems/",
        "date": "2023-03-29 00:00:00 +0000 UTC",
        "content": "The repo on Github contains the code and data for my master\u0026rsquo;s project in mathematics and statistics at SIUe. The project is titled \u0026ldquo;Reliability Estimation in Series Systems: Maximum Likelihood Techniques for Right-Censored and Masked Failure Data\u0026rdquo;.\nThe paper citation page is here.\nYou can view the PDF here. The abstract is as follows:\nThis paper investigates maximum likelihood techniques to estimate component reliability from masked failure data in series systems. A likelihood model accounts for right-censoring and candidate sets indicative of masked failure causes. Extensive simulation studies assess the accuracy and precision of maximum likelihood estimates under varying sample size, masking probability, and right-censoring time for components with Weibull lifetimes. The studies specifically examine the accuracy and precision of estimates, along with the coverage probability and width of BCa confidence intervals. Despite significant masking and censoring, the maximum likelihood estimator demonstrates good overall performance. The bootstrap yields correctly specified confidence intervals even for small sample sizes. Together, the modeling framework and simulation studies provide rigorous validation of statistical learning from masked reliability data.\nIt has a companion R package, wei.series.md.c1.c2.c3, which is a narrow library I developed in support of my master\u0026rsquo;s project at SIUe in mathematics and statistics. It provides a set of functions for fitting Weibull series systems with masked failure data. See the GitHub repo for more.\nI\u0026rsquo;m working on several spinoff papers. See the Future Work section in the paper for more details.\nShoot me an email at lex@metafunctor.com if you\u0026rsquo;re interested in collaborating on any projects.\n",
        "summary": "A simulation study is used to assess the sensitivity of the MLE to various parameters like sample size, masking probability, and other so on, using components with Weibull lifetimes arranged in series.",
        "tags": ["maximum-likelihood-estimation","data-generating-process","statistics","siue","data-science","inference","likelihood-models"],
        "section": "projects"
      },{
        "title": "wei.series.md.c1.c2.c3",
        "link": "http://localhost:1313/projects/wei-series-md-c1-c2-c3/",
        "date": "2023-03-29 00:00:00 +0000 UTC",
        "content": "The R package wei.series.md.c1.c2.c3 is a narrow library I developed in support of my master\u0026rsquo;s project at SIUe in mathematics and statistics. I made a post about the project here. It provides a set of functions for fitting Weibull series systems with masked failure data. See the GitHub repo for more details.\n",
        "summary": "R package in narrow support of my master\u0026rsquo;s project in reliability estimation for series systems from masked failure data like the component cause of failure being unknown or the failure being censored.",
        "tags": ["maximum-likelihood-estimation","data-generating-process","R-package","R","statistics"],
        "section": "projects"
      },{
        "title": "algebraic.dist-r-package",
        "link": "http://localhost:1313/projects/algebraic-dist/",
        "date": "2023-03-19 00:00:00 +0000 UTC",
        "content": "The R package algebraic.dist provides an algebra over distributions. It\u0026rsquo;s not fully-formed yet, but I plan on using it for a lot of my future work. For instance, I\u0026rsquo;ll move a lot of the code in algebraic.mle and likelihood.model to this package.\nAfter that, I want to experiment with using the algebraic.dist to do the following:\nCompose distributions such that operations over distributions generate other known distributions.\nThere are a lot of well-known compositions, such as the exponential distribution being the minimum of independent exponential distributions, or the sum of independent normal distributions being a normal distribution, but there is a very large space of possible compositions that are not as well-known or well-studied that I want to explore.\nLet people use an R expression to lazily compose functions of distributions. Simplifying a distribution expression will generate a most simple R expression that represents the same distribution.\nSometimes, this may result in a simple close-form distribution, like a multivariate normal distribution, but in other cases it may result in a (hopefully simpler) expression that composes multiple distributions and operations over them.\nWith these R expressions that represent distributions, we can define more operations, like taking the limiting distribution of a sequence of distributions, say $\\lim n \\to \\infty \\frac{1}{n} \\sum_{i=1}^n X_i$, which is of normal by the central limit theorem.\nDeduce various properties of these distributions, such as their moments, variances, etc. Sometimes, this may require numerical integration or Monte Carlo methods, but if the expression simplifies to a known distribution, then we can use the known properties of that distribution.\nI have a lot of this code in place in C++, but I want to re-implement it in R so that it\u0026rsquo;s more accessible to others. I may also implement some of the more interesting compositions in C++ and expose them to R via Rcpp, but I\u0026rsquo;m not sure yet. I use a lot of templates and metaprogramming in C++, and I\u0026rsquo;m not sure how well that will translate to Rcpp.\n",
        "summary": "An API for an algebra over distributions",
        "tags": ["multivariate distributions","multivariate normal distribution","multivariate empirical distribution","data generating process","R","data-science","statistics","inference","likelihood-models","probability-theory"],
        "section": "projects"
      },{
        "title": "multivariate-distributions",
        "link": "http://localhost:1313/tags/multivariate-distributions/",
        "date": "2023-03-19 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "multivariate-empirical-distribution",
        "link": "http://localhost:1313/tags/multivariate-empirical-distribution/",
        "date": "2023-03-19 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "multivariate-normal-distribution",
        "link": "http://localhost:1313/tags/multivariate-normal-distribution/",
        "date": "2023-03-19 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "probability-theory",
        "link": "http://localhost:1313/tags/probability-theory/",
        "date": "2023-03-19 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "femtograd",
        "link": "http://localhost:1313/ghprojects/femtograd/",
        "date": "2023-03-17 14:32:36 +0000 UTC",
        "content": "femtograd Like micrograd, but worse.\nGitHub Link\nStars: 1 | Forks: 0 | Open Issues: 0\nLanguages Used: R\nGitHub Pages\nREADME femtograd Exponential distribution Automatic differentiation (AD) Heres a quick demonstration of how to use the femtograd R package.\nLoad it like this:\nlibrary(femtograd) #\u0026gt; #\u0026gt; Attaching package: \u0026#39;femtograd\u0026#39; #\u0026gt; The following object is masked from \u0026#39;package:utils\u0026#39;: #\u0026gt; #\u0026gt; data Exponential distribution Lets create a simple loglikelihood function for the exponential distribution paramterized by $\\lambda$ (failure rate).\nWe have\n$$ f_{T_i}(t_i | \\lambda) = \\lambda \\exp(-\\lambda t_i). $$So, the loglikelihood function is just\n$$ \\ell(\\lambda) = n \\log \\lambda - \\lambda \\sum_{i=1}^n t_i. $$Lets generate $n=30$ observations.\nn \u0026lt;- 30 true_rate \u0026lt;- 7.3 data \u0026lt;- rexp(n,true_rate) head(data) #\u0026gt; [1] 0.102432677 0.009849689 0.037429092 0.093926112 0.033046038 0.181780460 (mle.rate \u0026lt;- abs(1/mean(data))) #\u0026gt; [1] 6.245535 We see that the MLE $\\hat\\theta$ is 6.2455349.\nAutomatic differentiation (AD) Finding the value (argmax) that maximizes the log-likelihood function is trivial to solve in this case, and it has a closed-form solution. However, to demonstrate the use of femtograd, we will construct a loglike_exp function generator that returns an object that can be automatically differentiated (AD) using backpropogation, which is an efficient way of applying the chain-rule to expressions (like $\\exp{y a x^2}$ using a computational graph that represents the expression.\nThese kind of computational graphs have the nice property that for any differentiable expression that we can model in software, its partial derivative with respect to some node in the graph can be efficiently and accurately computed without resorting to numerical finite difference methods or slow, potentially difficult to compose symbolic methods.\nThere are many libraries that do this. This library itself is based on the excellent work by Karpathy who developed the Python library known as micrograd, which was developed for the explicit purpose of teaching the basic concept of AD and backpropagation for minimizing loss functions for neural networks.\nLets solve for the MLE iteratively as a demonstration of how to use femtograd. First, we construct the log-likelihood generator:\nloglike_exp \u0026lt;- function(rate, data) { return(log(rate)*length(data) - rate * sum(data)) } Initially, we guess that $\\hat\\lambda$ is $1$, which is a terrible estimate.\nrate \u0026lt;- val(1) Gradient clipping is a technique to prevent taking too large of a step when gradients become too large (remember that gradients are a local feature, so we generally should not use it to take too big of a step) during optimization, which can cause instability or overshooting the optimal value. By limiting the step size, gradient clipping helps ensure that the optimization takes smaller, more stable steps.\nHere is the R code:\n# Takes a gradient `g` and an optional `max_norm` parameter, which defaults # to 1. It calculates the gradient\u0026#39;s L2 norm (Euclidean norm) and scales the # gradient down if its norm exceeds the specified max_norm. This is used during # the gradient ascent loop to help ensure stable optimization. grad_clip \u0026lt;- function(g, max_norm = 1) { norm \u0026lt;- sqrt(sum(g * g)) if (norm \u0026gt; max_norm) { g \u0026lt;- (max_norm / norm) * g } g } We find the MLE using a simple iteration (200 loops).\nloglik \u0026lt;- loglike_exp(rate, data) lr \u0026lt;- 0.2 # learning rate for (i in 1:200) { zero_grad(loglik) backward(loglik) data(rate) \u0026lt;- data(rate) + lr * grad_clip(grad(rate)) if (i %% 50 == 0) cat(\u0026#34;iteration\u0026#34;, i, \u0026#34;, rate =\u0026#34;, data(rate), \u0026#34;, drate/dl =\u0026#34;, grad(rate), \u0026#34;\\n\u0026#34;) } #\u0026gt; iteration 50 , rate = 6.238781 , drate/dl = 0.006148105 #\u0026gt; iteration 100 , rate = 6.245533 , drate/dl = 1.447689e-06 #\u0026gt; iteration 150 , rate = 6.245535 , drate/dl = 3.418377e-10 #\u0026gt; iteration 200 , rate = 6.245535 , drate/dl = 8.082424e-14 Did the gradient ascent method converge to the MLE?\n(converged \u0026lt;- (abs(mle.rate - data(rate)) \u0026lt; 1e-3)) #\u0026gt; [1] TRUE Its worth pointing out that we did not update loglik in the gradient ascent loop, since we only needed the gradient (score) in this case. If, however, we had needed to know the log-likelihood for some reason, such as when using a line search method to avoid overshooting, we would need to update with loglik \u0026lt;- loglike_exp(rate, data) each time through the loop.\n",
        "summary": "\u003ch1 id=\"femtograd\"\u003efemtograd\u003c/h1\u003e\n\u003cp\u003eLike micrograd, but worse.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/femtograd\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 1 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: R\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://queelius.github.io/femtograd/\"\u003eGitHub Pages\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003ch1 id=\"femtograd-1\"\u003efemtograd\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#exponential-distribution\"\nid=\"toc-exponential-distribution\"\u003eExponential distribution\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#automatic-differentiation-ad\"\nid=\"toc-automatic-differentiation-ad\"\u003eAutomatic differentiation (AD)\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eHeres a quick demonstration of how to use the\n\u003ca href=\"https://github.com/queelius/femtograd\"\u003e\u003ccode\u003efemtograd\u003c/code\u003e\u003c/a\u003e R package.\u003c/p\u003e\n\u003cp\u003eLoad it like this:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-r\" data-lang=\"r\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#a6e22e\"\u003elibrary\u003c/span\u003e(femtograd)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e#\u0026gt; \u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e#\u0026gt; Attaching package: \u0026#39;femtograd\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e#\u0026gt; The following object is masked from \u0026#39;package:utils\u0026#39;:\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e#\u0026gt; \u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e#\u0026gt;     data\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"exponential-distribution\"\u003eExponential distribution\u003c/h2\u003e\n\u003cp\u003eLets create a simple loglikelihood function for the exponential\ndistribution paramterized by $\\lambda$ (failure rate).\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "failure-rate",
        "link": "http://localhost:1313/tags/failure-rate/",
        "date": "2023-01-11 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "hazard",
        "link": "http://localhost:1313/tags/hazard/",
        "date": "2023-01-11 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "r-package-dynamic-failure-rate-dfr-distributions",
        "link": "http://localhost:1313/projects/dfr-dist/",
        "date": "2023-01-11 00:00:00 +0000 UTC",
        "content": "Note: This is quite unfinished. I plan on fleshing this out when I revisit my master\u0026rsquo;s project work on estimating latent failure rate distributions. I plan on generalizing the result to allow for arbitrary failure rates and to use the MLE approach to estimate the parameters of the failure rate, since the MLE approach is more general and can be used to estimate the parameters given more complicated data generating processes.\nThe R packge dfr_dist provides an API for specifying and estimating dynamic failure rate distributions. They can depend on the data in any way, as the failure rate is any function of time and any set of predictors, as long as the failure rate satsifies two key properties:\nIt\u0026rsquo;s non-negative. It is not meaningful to have a negative failure rate; the failure rate can decrease some times, and even go to $0$, though. It\u0026rsquo;s cumulative hazard has a limit of infinity, $\\lim_{t \\to \\infty} H(t, x_1, \\ldots, x_p) = \\infty$. If this isn\u0026rsquo;t satisfied, then the survival function is not well-defined. This object satisfies all of the requirements of an algebraic.dist and a likelihoood model. It is also designed to work well with the algebraic.mle package, which provides a framework for performing maximum likelihood estimation (MLE) and retrieving various statistical properties of the MLEs.\n",
        "summary": "An API for constructing and working with dynamic failure rates.",
        "tags": ["maximum-likelihood-estimation","failure-rate","hazard","R-package","R","statistics"],
        "section": "projects"
      },{
        "title": "queelius.github.io",
        "link": "http://localhost:1313/ghprojects/queelius.github.io/",
        "date": "2022-08-28 11:12:14 +0000 UTC",
        "content": "queelius.github.io queelius.github.io\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nGitHub Pages\nNo README available for this project.\n",
        "summary": "\u003ch1 id=\"queeliusgithubio\"\u003equeelius.github.io\u003c/h1\u003e\n\u003cp\u003equeelius.github.io\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/queelius.github.io\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://queelius.github.io/queelius.github.io/\"\u003eGitHub Pages\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eNo README available for this project.\u003c/em\u003e\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "algebraic.dist",
        "link": "http://localhost:1313/ghprojects/algebraic.dist/",
        "date": "2022-05-26 19:17:07 +0000 UTC",
        "content": "algebraic.dist Algebraic distributions\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nLanguages Used: R\nGitHub Pages\nREADME R package: algebraic.dist Installation TODO R package: algebraic.dist An algebra over distributions (random elements).\nInstallation You can install the development version of algebraic.dist from GitHub with:\n# install.packages(\u0026#34;devtools\u0026#34;) devtools::install_github(\u0026#34;queelius/algebraic.dist\u0026#34;) See the vignette algebraic.dist: Example for a quick introduction to the package.\nTODO Flesh out the algebra logic for things like simplification. ",
        "summary": "\u003ch1 id=\"algebraicdist\"\u003ealgebraic.dist\u003c/h1\u003e\n\u003cp\u003eAlgebraic distributions\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/algebraic.dist\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: R\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://queelius.github.io/algebraic.dist/\"\u003eGitHub Pages\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#r-package-algebraicdist\"\u003eR package: \u003ccode\u003ealgebraic.dist\u003c/code\u003e\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"#installation\"\u003eInstallation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"#todo\"\u003eTODO\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!-- README.md is generated from README.Rmd. Please edit that file --\u003e\n\u003ch1 id=\"r-package-algebraicdist\"\u003eR package: \u003ccode\u003ealgebraic.dist\u003c/code\u003e\u003c/h1\u003e\n\u003c!-- badges: start --\u003e\n\u003cp\u003e\u003ca href=\"https://www.gnu.org/licenses/gpl-3.0\"\u003e\u003cimg src=\"https://img.shields.io/badge/license-GPL--3-blue.svg\" alt=\"GPL-3\nLicense\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c!-- badges: end --\u003e\n\u003cp\u003eAn algebra over distributions (random elements).\u003c/p\u003e\n\u003ch2 id=\"installation\"\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eYou can install the development version of \u003ccode\u003ealgebraic.dist\u003c/code\u003e from\n\u003ca href=\"https://github.com/\"\u003eGitHub\u003c/a\u003e with:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-r\" data-lang=\"r\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e# install.packages(\u0026#34;devtools\u0026#34;)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003edevtools\u003cspan style=\"color:#f92672\"\u003e::\u003c/span\u003e\u003cspan style=\"color:#a6e22e\"\u003einstall_github\u003c/span\u003e(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;queelius/algebraic.dist\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eSee the vignette \u003ca href=\"http://queelius.github.io/algebraic.dist/articles/example.html\"\u003ealgebraic.dist:\nExample\u003c/a\u003e\nfor a quick introduction to the package.\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "latent-data",
        "link": "http://localhost:1313/tags/latent-data/",
        "date": "2022-05-13 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "masked-data",
        "link": "http://localhost:1313/tags/masked-data/",
        "date": "2022-05-13 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "r-package-md.tools",
        "link": "http://localhost:1313/projects/md.tools/",
        "date": "2022-05-13 00:00:00 +0000 UTC",
        "content": "The R package md.tools is a miscellaneous set of tools for working with masked data and common features of masked data. If doing simulation studies, it also supports latent data, i.e., data that is not observed but is generated, and various other features that may be useful for simulation studies.\nThe tool set takes inspiration from functional programming, with inputs and outputs defined over masked data frames of type tbl_md (or just data frames), making it consistent with the tidyverse way of doing things.\n",
        "summary": "An API for constructing and working with likelihood models; works well with \u003ccode\u003ealgebraic.mle\u003c/code\u003e R package",
        "tags": ["masked-data","latent-data","R-package","R","statistics"],
        "section": "projects"
      },{
        "title": "amdhals-law",
        "link": "http://localhost:1313/tags/amdhals-law/",
        "date": "2022-03-31 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "computer-science",
        "link": "http://localhost:1313/categories/computer-science/",
        "date": "2022-03-31 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "parallel-processing",
        "link": "http://localhost:1313/categories/parallel-processing/",
        "date": "2022-03-31 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "parallel-programming",
        "link": "http://localhost:1313/tags/parallel-programming/",
        "date": "2022-03-31 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "survey-accelerating-critical-section-execution-with-asymmetric-multi-core-architectures-2009",
        "link": "http://localhost:1313/posts/2022-05-13-acs/",
        "date": "2022-03-31 00:00:00 +0000 UTC",
        "content": "Introduction $$ \\operatorname{speedup}(N) = \\frac{1}{1 - P + \\frac{P}{N}}, $$ where $\\operatorname{speedup}$ is the total execution time of a single-threaded version of a program divided by the total execution time an $N$-threaded implementation of the same program.a\nAccordingly, the asymptotic speedup of a program as a function of $N$ is determined by the $1-P$ term, i.e., $\\operatorname{speedup}(N)$ goes to $1/(1-P)$ as $N$ goes to infinity. Thus, even if 99% of the time the program can be ran in parallel, the maximum possible $\\operatorname{speedup}$ is only $1/(1-0.99) = 100$. Thus, to achieve scalable performance with increasing thread counts, the sequential portion of code must be aggressively reduced no matter how small it is.\nAccelerated Critical Sections (ACS) The authors point out that a common occurrence of thread serialization is caused by the presence of critical sections, defined as code blocks guarded by locks to enforce mutual exclusion.\nTo mitigate the effect of critical section serialization (see Figure @ref(fig:cs-fig)), they propose Accelerated Critical Sections (ACS). Specifically, using an asymmetric multi-core processor in which one of the cores is four times the size of the other cores, use the large core to quickly execute critical sections on behalf of the smaller cores.\nCritical section\nTrade-offs There are several key performance trade-offs with respect to ACS.\nTrade-off #1 Faster critical section execution versus fewer threads. That is, the large core takes up an area equivalent to 4 small cores; therefore, fewer cores are available for thread execution. However, there are two forces which conspire to mitigate this disadvantage.\nFirst, as the transistor budget increases, the marginal cost of replacing multiple small cores with a single large core decreases. For example, suppose we have an area budget of 32 small cores. We can use that budget to either make a system with 32 small cores, or alternatively a system with 1 large core and 28 small cores. The system with the large core case has (not counting the large core in this fraction since it can only be used to dispatch critical sections) the number of cores compared to the system with 32 small cores. This is much more favorable than if we only had an area budget of 8 small cores.\nSecond, as critical section contention grows, increasing thread counts provide diminishing (or even negative) returns. Contention tends to grow in line with increasing core counts therefore trading multiple small cores for a single large core becomes a better deal as the transistor budget increases. In general, ACS may only improve performance if the gain in executing critical sections faster on the large core overcomes the advantage of having more threads which becomes ever more likely with increasing transistor budgets.\nTrade-off #2 Cache misses caused by private data as opposed to cache misses caused by shared data. In particular, if private data on a small core is referenced inside the critical section, then that data needs to be transferred from the small core to the large core3. However, critical sections frequently access shared memory, thus if we usually only execute code that accesses shared memory with the large core, that will lead to improved cache utilization (reduced cache misses) when accessing shared memory.In general, if accessing shared data is more common than accessing private data in a critical section\u0026ndash;which is not unlikely\u0026ndash;then the trade-off tips in favor of ACS.\nTrade-off #3 The communications overhead incurred by having the large core execute a critical section on behalf of a small core. In particular, when a thread on a small core encounters a critical section, it issues a request to the large core to execute the specified critical section. When the large core receives this request, it is placed on a queue (Critical Section Request Buffer\u0026ndash;CSRB) and executed by the large core when it reaches the top. This communication overhead is avoided if the critical section is simply executed on the local small core. However, this overhead may mitigated by the fact that if multiple cores are trying to read or write a shared lock, then the overhead of having to synchronize on this lock (e.g., propagating the lock\u0026rsquo;s state to remote caches when it changes) can be significant. If the lock is usually only accessed by the large core then the need to synchronize the state of the lock is reduced (fewer cache misses).\nTrade-off #4 If a program has many disjoint critical sections, where each critical section can be accessed by multiple threads simultaneously without contention, then executing them exclusively on the large core will cause them to unnecessarily execute sequentially; this is what the authors call \u0026ldquo;false serialization.\u0026rdquo; To mitigate this issue, they propose adding additional circuitry to heuristically estimate whether a critical section is being falsely serialized.\nThe estimation uses the following quantification: count the number of requests in the CSRB for which the lock address for the enqueued request\u0026rsquo;s critical section is different from the lock address for the incoming request\u0026rsquo;s critical section. If the count is greater than one, there are at least two independent critical sections already waiting to be executed in the CSRB. Add this count to a counter for the incoming lock address.\nAlternatively, if the count is only one, then decrement the lock address\u0026rsquo; counter. If a counter reaches a maximum threshold, the ACS is disabled for that lock address. Thus when a thread happens upon that lock, it will try to acquire it and execute the critical section locally. The hope is the false serialization rate is not so high that it overcomes the benefit of faster critical section execution.\nComparison: ACS vs SCMP With the above trade-offs in mind, the authors set out to see how their proposed ACS system compares to two other kinds of systems: a symmetric CMP (SCMP), a multi-core processor in which each core is uniform, and an asymmetric CMP (ACMP), a multi-core processor in which one of the cores is larger like in the ACS system except that the ACMP system\u0026rsquo;s large core is not used for accelerating critical sections.\nTo compare these systems, they compare their respective execution times on a carefully chosen benchmark suite. To make the comparison fair, they must control for any hardware differences that may lead to one system having an advantage for reasons unrelated to their ACS framework, e.g., use identical cores (with a few exceptions since the ACS requires hardware support), memory configurations, transistor budgets, and so forth.\nTo control for this, they simulate each system in software rather than real silicon and provide them approximately identical designs and constraints. On each system (ACS, SCMP, and ACMP), they run the same benchmark 4 suite on different area budgets (in units of \u0026ldquo;small-cores\u0026rdquo;), e.g., in benchmarks ran on systems with a budget of 8 small cores, the SCMP system consists of 8 small cores and the ACMP and ACS systems consist of 4 small cores and one large core.\nThey expect that, for reasons related to the previously mentioned trade-offs (e.g., decreasing marginal costs), as the area budget increases they will see a gradual improvement in the ACS systems compared to the SCMP and ACMP systems.\nAdditionally, the benchmark suite can be divided into two broad categories: programs that use coarse-grained locking, 10 critical sections or less, and programs that use fine-grained locking. The two categories stress different aspects of the previously mentioned trade-offs, and they expect that their ACS system will compare more favorably in coarse-grained locking benchmarks (fine-grained locking reduces critical section contention, so benefits from ACS are reduced).\nOn the course-grained benchmarks, the ACS system generally compares better than the other two even when the area budget is only 8 small cores; it wins five out seven of the benchmarks.\nOne of the benchmarks it compares less favorably in is a parallelized implementation of quicksort. Quicksort experiences very little contention on critical sections (and thus benefits from higher thread counts) and also frequently accesses private data (which must be transferred to the ACS\u0026rsquo;s large core).\nHowever, as the area budget increases ACS compares more favorably. Indeed, on systems with an area budget of 32 small cores, the ACS system significantly improves performance by 42% compared to SCMP and by 31% compared to ACMP. On the fine-grained benchmarks, as the authors expected the ACS system compares less favorably.\nOn systems with an area budget only 8 small cores, ACS reduces execution time on average by 20% compared to ACMP but increases execution time by a significant 37% compared to SCMP. Critical section contention was so low that SCMP was able to take effective advantage of its larger core count. However, as the area budget scales up, critical section contention should increase and the ACS system gains some lost ground.\nIndeed, when the area budget reaches 32, ACS outperforms SCMP by 17% and ACMP by 13%. In addition, on many of the benchmarks performance on ACS scaled more consistently with core quantity than on SCMP and ACMP. For instance, on the SCMP system it was usually necessary to reduce the optimal thread count to something well below the total number of cores to prevent critical section contention from degrading performance, but with the ACS system improvement would often be seen up to the maximum of 32 cores with room for growth.\nConclusion ACS outperforms both SCMP and ACMP on all representative (coarse-grained and fine-grained) critical-section benchmarks on processors with 16 or more cores, and it even performs well on more modest processors (especially in the coarse-grained benchmarks). In light of this and the reasonable argument that ACS will continue to extend its lead as core counts and critical-section contention rise hand in hand, ACS is a promising area of future development.\n",
        "summary": "\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n$$\n  \\operatorname{speedup}(N) = \\frac{1}{1 - P + \\frac{P}{N}},\n$$\u003cp\u003e\nwhere $\\operatorname{speedup}$ is the total execution time of a\nsingle-threaded version of a program divided by the total execution time\nan $N$-threaded implementation of the same program.a\u003c/p\u003e\n\u003cp\u003eAccordingly, the asymptotic speedup of a program as a function of $N$ is\ndetermined by the $1-P$ term, i.e., $\\operatorname{speedup}(N)$ goes to\n$1/(1-P)$ as $N$ goes to infinity. Thus, even if 99% of the time the\nprogram can be ran in parallel, the maximum possible\n$\\operatorname{speedup}$ is only $1/(1-0.99) = 100$. Thus, to achieve\nscalable performance with increasing thread counts, the sequential\nportion of code must be aggressively reduced no matter how \u003cem\u003esmall\u003c/em\u003e it\nis.\u003c/p\u003e",
        "tags": ["parallel programming","Amdhal's law"],
        "section": "posts"
      },{
        "title": "md.tools",
        "link": "http://localhost:1313/ghprojects/md.tools/",
        "date": "2022-01-29 20:41:28 +0000 UTC",
        "content": "md.tools Masked data tools\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nLanguages Used: R\nGitHub Pages\nREADME R package: md.tools A miscellaneous set of tools for working with masked data and common features of masked data. The tool set takes inspiration from functional programming, with inputs and outputs defined over masked data frames of type tbl_md (or just data frames), making it consistent with the tidyverse way of doing things.\nWe provide a set of simple functions on masked data frames, which may be used to compose more complicated functions, particularly when using the pipe operator %\u0026gt;%.\nInstallation You can install the development version of md.tools from GitHub with:\n# install.packages(\u0026#34;devtools\u0026#34;) #devtools::install_github(\u0026#34;queelius/md.tools\u0026#34;) We load the libraries md.tools and tidyverse with:\nlibrary(tidyverse) library(md.tools) Matrices A lot of space in md.tools is devoted to working with matrices encoded in the columns of data frames. We could directly store matrices in a column, but we prefer to work with columns defined over primitive types like boolean.\nConsider the boolean matrix C of size 10-by-3:\nn \u0026lt;- 5 m \u0026lt;- 3 C \u0026lt;- matrix(sample(c(T,F), size=m*n, replace=TRUE), nrow=n) We may represent this in a data frame of 5 rows with the columns c1, c2, and c3 with:\nmd \u0026lt;- md_encode_matrix(C,\u0026#34;c\u0026#34;) print(md) #\u0026gt; # A tibble: 5  3 #\u0026gt; c1 c2 c3 #\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;lgl\u0026gt; #\u0026gt; 1 FALSE TRUE TRUE #\u0026gt; 2 TRUE TRUE TRUE #\u0026gt; 3 TRUE TRUE TRUE #\u0026gt; 4 FALSE FALSE FALSE #\u0026gt; 5 FALSE FALSE FALSE We may also decode a matrix stored in a data frame with:\nprint(all(C == md_decode_matrix(md,\u0026#34;c\u0026#34;))) #\u0026gt; [1] TRUE We may want to work with a Boolean matrix as a list. The function md_boolean_matrix_to_list uses the following transformation:\nIf we have a $n$-by-$m$ Boolean matrix, then if the $(j,k)$-element is TRUE, the $j$-th vector in the list contains the integer $k$.\nWe can show the md with the candidate set as a set of integers with:\nmd %\u0026gt;% md_boolean_matrix_to_charsets(\u0026#34;c\u0026#34;, \u0026#34;candidate set\u0026#34;) #\u0026gt; # A tibble: 5  4 #\u0026gt; c1 c2 c3 `candidate set` #\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;chr\u0026gt; #\u0026gt; 1 FALSE TRUE TRUE {2, 3} #\u0026gt; 2 TRUE TRUE TRUE {1, 2, 3} #\u0026gt; 3 TRUE TRUE TRUE {1, 2, 3} #\u0026gt; 4 FALSE FALSE FALSE {} #\u0026gt; 5 FALSE FALSE FALSE {} We allow converting between three representations: lists of integer vectors, Boolean vectors, and lists of charsets (sets represented with strings, e.g., { 1, 2 }. Thus, the inverse of md_boolean_matrix_to_list is just md_list_to_boolean_matrix and so on.\nDecorators We now consider some data frame transformations that adds additional columns with information that may be inferred from what is already in the data frame. For this reason, we have chosen to call them decorators.\nIn a masked data frame, we may have a column k that stores the failed component. We simulate failed components and mark them as latent with:\nmd \u0026lt;- md %\u0026gt;% mutate(k=sample(1:m,n,replace=TRUE)) %\u0026gt;% md_mark_latent(\u0026#34;k\u0026#34;) print(md) #\u0026gt; Latent variables: k #\u0026gt; # A tibble: 5  4 #\u0026gt; c1 c2 c3 k #\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 FALSE TRUE TRUE 1 #\u0026gt; 2 TRUE TRUE TRUE 1 #\u0026gt; 3 TRUE TRUE TRUE 2 #\u0026gt; 4 FALSE FALSE FALSE 3 #\u0026gt; 5 FALSE FALSE FALSE 3 We may additionally have a candidate set encoded by the Boolean columns c1,,cm, in which case we may infer whether the candidate set contains the failed component k with:\nmd \u0026lt;- md %\u0026gt;% md_set_contains(\u0026#34;c\u0026#34;, \u0026#34;k\u0026#34;, \u0026#34;contains\u0026#34;) print(md) #\u0026gt; Latent variables: k #\u0026gt; # A tibble: 5  5 #\u0026gt; c1 c2 c3 k contains #\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;lgl\u0026gt; #\u0026gt; 1 FALSE TRUE TRUE 1 FALSE #\u0026gt; 2 TRUE TRUE TRUE 1 TRUE #\u0026gt; 3 TRUE TRUE TRUE 2 TRUE #\u0026gt; 4 FALSE FALSE FALSE 3 FALSE #\u0026gt; 5 FALSE FALSE FALSE 3 FALSE We see that there is a new column, contains, that tells us whether the candidate set actually contains the failed component. No new information is given by this column, it only presents what information that is already there in a potentially more conventient format.\nGiven the same data frame and candidate set, we may determine the cardinality of the candidate sets with:\nmd \u0026lt;- md %\u0026gt;% md_set_size(\u0026#34;c\u0026#34;) print(md) #\u0026gt; Latent variables: k #\u0026gt; # A tibble: 5  6 #\u0026gt; c1 c2 c3 k contains size_c #\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 FALSE TRUE TRUE 1 FALSE 2 #\u0026gt; 2 TRUE TRUE TRUE 1 TRUE 3 #\u0026gt; 3 TRUE TRUE TRUE 2 TRUE 3 #\u0026gt; 4 FALSE FALSE FALSE 3 FALSE 0 #\u0026gt; 5 FALSE FALSE FALSE 3 FALSE 0 We may unmark a column variable as latent with:\nmd \u0026lt;- md %\u0026gt;% md_unmark_latent(\u0026#34;k\u0026#34;) print(md) #\u0026gt; # A tibble: 5  6 #\u0026gt; c1 c2 c3 k contains size_c #\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;int\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;int\u0026gt; #\u0026gt; 1 FALSE TRUE TRUE 1 FALSE 2 #\u0026gt; 2 TRUE TRUE TRUE 1 TRUE 3 #\u0026gt; 3 TRUE TRUE TRUE 2 TRUE 3 #\u0026gt; 4 FALSE FALSE FALSE 3 FALSE 0 #\u0026gt; 5 FALSE FALSE FALSE 3 FALSE 0 The latent variable specification is metadata about the masked data frame, but it does not necessarily impose any requirements on algorithms applied to it.\nMore generally, a masked data frame may have a lot more metadata about it, and we provide some tools for working with them. However, for the most part, you are expected to handle the metadata yourself. The metadata is stored in the attributes, and so underneath the hood, a masked data frame is just a data frame and may be treated as one.\nMetadata To read and write data frames for sharing with others, including yourself, we prefer to work with plaintext files like CSV files, where each row corresponds to some set of measurements of some experimental unit.\nHowever, we may also want to store metadata about the experiment that generated the data, or we may wish to store more information about the experimental units that does not naturally fit into the data frame model.\nTo store metadata, we take the general approach of storing JSON (Javscript Object Notation) in the comments of the tabular data file (like CSV), where a comment by default is anything after the # character on a line.\ndata \u0026lt;- md_read_csv_with_meta(\u0026#34;./data-raw/exp_series_md_1.csv\u0026#34;) #\u0026gt; Rows: 1000 Columns: 8 #\u0026gt;  Column specification  #\u0026gt; Delimiter: \u0026#34;,\u0026#34; #\u0026gt; dbl (5): t, k, t1, t2, t3 #\u0026gt; lgl (3): x1, x2, x3 #\u0026gt; #\u0026gt;  Use `spec()` to retrieve the full column specification for this data. #\u0026gt;  Specify the column types or set `show_col_types = FALSE` to quiet this message. print(data) #\u0026gt; Latent variables: k t1 t2 t3 #\u0026gt; # A tibble: 1,000  8 #\u0026gt; t k t1 t2 t3 x1 x2 x3 #\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;lgl\u0026gt; \u0026lt;lgl\u0026gt; #\u0026gt; 1 0.144 2 0.281 0.144 0.266 TRUE TRUE FALSE #\u0026gt; 2 0.0105 1 0.0105 0.0141 0.0633 TRUE FALSE TRUE #\u0026gt; 3 0.0363 2 0.105 0.0363 0.545 TRUE TRUE FALSE #\u0026gt; 4 0.00972 1 0.00972 0.251 0.0960 TRUE FALSE TRUE #\u0026gt; 5 0.0377 3 0.0937 0.0943 0.0377 TRUE FALSE TRUE #\u0026gt; 6 0.0958 3 0.283 0.391 0.0958 FALSE TRUE TRUE #\u0026gt; 7 0.169 3 0.197 1.01 0.169 FALSE TRUE TRUE #\u0026gt; 8 0.270 3 0.322 0.371 0.270 FALSE TRUE TRUE #\u0026gt; 9 0.299 3 0.390 0.401 0.299 TRUE FALSE TRUE #\u0026gt; 10 0.00794 2 0.524 0.00794 0.120 FALSE TRUE TRUE #\u0026gt; #  990 more rows We may view all of the metadata stored in data with:\nmeta \u0026lt;- attributes(data) meta[\u0026#34;row.names\u0026#34;] \u0026lt;- NULL print(meta) #\u0026gt; $class #\u0026gt; [1] \u0026#34;tbl_md\u0026#34; \u0026#34;tbl_df\u0026#34; \u0026#34;tbl\u0026#34; \u0026#34;data.frame\u0026#34; #\u0026gt; #\u0026gt; $names #\u0026gt; [1] \u0026#34;t\u0026#34; \u0026#34;k\u0026#34; \u0026#34;t1\u0026#34; \u0026#34;t2\u0026#34; \u0026#34;t3\u0026#34; \u0026#34;x1\u0026#34; \u0026#34;x2\u0026#34; \u0026#34;x3\u0026#34; #\u0026gt; #\u0026gt; $comment #\u0026gt; [1] \u0026#34;this is a simulation test.\u0026#34; #\u0026gt; #\u0026gt; $param #\u0026gt; [1] 3 4 5 #\u0026gt; #\u0026gt; $components #\u0026gt; family param #\u0026gt; 1 exponential 3 #\u0026gt; 2 exponential 4 #\u0026gt; 3 exponential 5 #\u0026gt; #\u0026gt; $candidate_conditions #\u0026gt; [1] \u0026#34;C1\u0026#34; \u0026#34;C2\u0026#34; \u0026#34;C3\u0026#34; #\u0026gt; #\u0026gt; $latent #\u0026gt; [1] \u0026#34;k\u0026#34; \u0026#34;t1\u0026#34; \u0026#34;t2\u0026#34; \u0026#34;t3\u0026#34; #\u0026gt; #\u0026gt; $observable #\u0026gt; [1] \u0026#34;t\u0026#34; \u0026#34;x1\u0026#34; \u0026#34;x2\u0026#34; \u0026#34;x3\u0026#34; #\u0026gt; #\u0026gt; $num_comp #\u0026gt; [1] 3 #\u0026gt; #\u0026gt; $sample_size #\u0026gt; [1] 1000 Note that we removed the row.names attribute, since its quite long and uninformative.\nA lot of the metadata for data has to do with how the data was generated. In particular, we see this data is the result of a simulation for a series system with $3$ exponentially distributed component lifetimes parameterized by $\\lambda = (3,4,5)\u0026rsquo;$ and a candidate model consistent with conditions $C_1$, $C_2$, and $C_3$ for series systems with a masked component cause of failure in the form of candidate sets.\n",
        "summary": "\u003ch1 id=\"mdtools\"\u003emd.tools\u003c/h1\u003e\n\u003cp\u003eMasked data tools\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/md.tools\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: R\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://queelius.github.io/md.tools/\"\u003eGitHub Pages\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003c!-- README.md is generated from README.Rmd. Please edit that file --\u003e\n\u003ch1 id=\"r-package-mdtools\"\u003eR package: \u003ccode\u003emd.tools\u003c/code\u003e\u003c/h1\u003e\n\u003c!-- badges: start --\u003e\n\u003c!-- badges: end --\u003e\n\u003cp\u003eA miscellaneous set of tools for working with \u003cem\u003emasked data\u003c/em\u003e and common\nfeatures of masked data. The tool set takes inspiration from functional\nprogramming, with inputs and outputs defined over masked data frames of\ntype \u003ccode\u003etbl_md\u003c/code\u003e (or just data frames), making it consistent with the\n\u003cem\u003etidyverse\u003c/em\u003e way of doing things.\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "algebraic.mle",
        "link": "http://localhost:1313/ghprojects/algebraic.mle/",
        "date": "2022-01-27 09:12:55 +0000 UTC",
        "content": "algebraic.mle Algebraic maximum likelihood estimators\nGitHub Link\nStars: 1 | Forks: 0 | Open Issues: 0\nLanguages Used: R\nGitHub Pages\nREADME R package: algebraic.mle algebraic.mle is an R package that provides an algebra over Maximum Likelihood Estimators (MLEs). These estimators possess many desirable, well-defined statistical properties which the package helps you manipulate and utilize.\nInstallation algebraic.mle can be installed from GitHub by using the devtools package in R:\n#devtools::install_github(\u0026#34;queelius/algebraic.mle\u0026#34;) #devtools::install_github(\u0026#34;queelius/algebraic.dist\u0026#34;) library(algebraic.dist) #\u0026gt; Registered S3 method overwritten by \u0026#39;algebraic.dist\u0026#39;: #\u0026gt; method from #\u0026gt; print.dist stats library(algebraic.mle) Purpose The likelihood function is a fundamental concept in statistics and parametric models. The algebraic.mle package enables you to manipulate and utilize MLEs in a way that is consistent with the underlying statistical theory and according to a powerful, well-defined interface.\nAPI Overview The main object in the algebraic.mle package is the mle object, which represents a fitted model. The package provides a number of generic methods designed for mle objects. A comprehensive list of functions is available in the function reference for algebraic.mle.\nFitting exponential models Here is an example of fitting a conditional exponential model to some data using algebraic.mle. The true DGP is given by Y | x ~ X(x) + W where X(x) ~ EXP(rate(x)), W ~ N(0, 1e-3), and rate(x) = exp(b0 + b1 * x).\nIn this analysis, we do not care how x is distributed, and we take it to be an observable exogenous variable. We are interested in the conditional distribution of Y | x.\nLets fit a conditional exponential model to some data from this DGP. While the true DGP is a bit more complicated, the most salient part is the exponential component, and the gaussian term may be thought of as added noise, say, from imprecise measurement. Of course, the true DGP is unknown in practice, so arriving at an conditional exponential model is a matter of judgement and domain knowledge.\nIn this model, Y | x ~ EXP(rate(x)) where rate(x) = exp(b0 + b1*x). First, lets define the DGP (data generating process):\nb0 \u0026lt;- -.1 b1 \u0026lt;- 0.5 dgp \u0026lt;- function(n, x) { # rate is the expected value of X rate \u0026lt;- exp(b0 + b1 * x) X \u0026lt;- rexp(n, rate) # W is the random error W \u0026lt;- rnorm(n, 0, 1e-3) # Y | x is the observed value Y \u0026lt;- X + W return(Y) } Lets generate some date:\nn \u0026lt;- 75 # number of observations set.seed(1231) # for reproducibility df \u0026lt;- data.frame(x = rep(NA, n), y = rep(NA, n)) for (i in 1:n) { # We do not care how x is distributed, so we take it to be an observable # exogenous variable that impacts the conditional mean of Y. x \u0026lt;- runif(1, -10, 10) y \u0026lt;- dgp(n = 1, x = x) df[i, ] \u0026lt;- c(x, y) } Now, we define three functions, resp, rate, and loglik, which will be used to define the model.\nresp \u0026lt;- function(df) df$y rate \u0026lt;- function(df, beta) exp(beta[1] + beta[2] * df$x) loglik \u0026lt;- function(df, resp, rate) { function(beta) sum(dexp(x = resp(df), rate = rate(df, beta), log = TRUE)) } Lets fit the model. Well use the optim function in stats to fit the model and then wrap it into an mle object using mle_numerical.\n# initial guess for the parameters par0 \u0026lt;- c(0, 0) names(par0) \u0026lt;- c(\u0026#34;b0\u0026#34;, \u0026#34;b1\u0026#34;) sol \u0026lt;- algebraic.mle::mle_numerical(optim(par = par0, fn = loglik(df, resp, rate), control = list(fnscale = -1), hessian = TRUE)) summary(sol) #\u0026gt; Maximum likelihood estimator of type mle_numerical is normally distributed. #\u0026gt; The estimates of the parameters are given by: #\u0026gt; b0 b1 #\u0026gt; -0.2253626 0.4560893 #\u0026gt; The standard error is 0.1167634 0.02145606 . #\u0026gt; The asymptotic 95% confidence interval of the parameters are given by: #\u0026gt; 2.5% 97.5% #\u0026gt; b0 -0.4542147 0.003489406 #\u0026gt; b1 0.4140362 0.498142415 #\u0026gt; The MSE of the individual components in a multivariate estimator is: #\u0026gt; [,1] [,2] #\u0026gt; [1,] 0.0136336902 0.0003746527 #\u0026gt; [2,] 0.0003746527 0.0004603623 #\u0026gt; The log-likelihood is -119.6977 . #\u0026gt; The AIC is 243.3954 . Lets plot it:\n# plot the x-y points from the data frame plot(df$x,df$y) # now overlay a plot of the conditional mean x \u0026lt;- seq(-10, 10, .1) b0.hat \u0026lt;- params(sol)[1] b1.hat \u0026lt;- params(sol)[2] y.hat \u0026lt;- 1/exp(b0.hat + b1.hat*x) y \u0026lt;- 1/exp(b0 + b1*x) lines(x, y, col = \u0026#34;green\u0026#34;, lwd = 10) lines(x, y.hat, col = \u0026#34;blue\u0026#34;, lwd = 10) Hypothesis test and model selection Lets test the hypothesis that b0 = 0 using a likelihood ratio test. We can use the LRT because this null model is a special case (nested) of the full model. The null model is Y | x ~ EXP(rate(x)) where rate(x) = exp(b1*x), while the full model is Y | x ~ EXP(rate(x)) where rate(x) = exp(b0 + b1*x).\n# construct null model where b1 = 0 rate_b0_zero \u0026lt;- function(df, b1) exp(b1 * df$x) # initial guess for the parameters # fit the model under the null hypothesis sol2 \u0026lt;- mle_numerical(optim(par = 0, fn = loglik(df, resp, rate_b0_zero), control = list(fnscale = -1), hessian = TRUE, method = \u0026#34;BFGS\u0026#34;)) summary(sol2) #\u0026gt; Maximum likelihood estimator of type mle_numerical is normally distributed. #\u0026gt; The estimates of the parameters are given by: #\u0026gt; [1] 0.4617093 #\u0026gt; The standard error is 0.01899941 . #\u0026gt; The asymptotic 95% confidence interval of the parameters are given by: #\u0026gt; 2.5% 97.5% #\u0026gt; param1 0.4244712 0.4989475 #\u0026gt; The MSE of the estimator is 0.0003609774 . #\u0026gt; The log-likelihood is -121.7164 . #\u0026gt; The AIC is 245.4328 . Lets compute the likelihood ratio test statistic and p-value:\n(lrt.sol2 \u0026lt;- -2 * (loglik_val(sol2) - loglik_val(sol))) #\u0026gt; [1] 4.037435 pchisq(lrt.sol2, df = 1, lower.tail = FALSE) # compute the p-value #\u0026gt; [1] 0.04450142 We see that the p \u0026lt; 0.05, but just barely, so we say the data is not compatible with the null hypothesis b0 = 0.\nIf we wanted to do model selection, we could use the AIC:\naic(sol) #\u0026gt; [1] 243.3954 aic(sol2) #\u0026gt; [1] 245.4328 By the AIC measure, since the full model has an AIC less than the null model, we would choose the full model. We actually know the DGP and both models are reasonable approximations, but the full model is a closer approximation.\nAll models are wrong, but some are useful. - George Box\nEventually, if we have a sufficiently large sample, any model that is not the DGP can be discarded, but reality is so complex that we will never have a large enough sample and we will never be able to come up with a model that is exactly the DGP.\nLets do another test, b1 = 0, i.e., its an unconditional exponential model, or just a standard exponential distribution.\nrate_b1_zero \u0026lt;- function(df, b0) exp(b0) # fit the model under the null hypothesis sol3 \u0026lt;- algebraic.mle::mle_numerical(optim(par = 0, fn = loglik(df, resp, rate_b1_zero), control = list(fnscale = -1), hessian = TRUE, method = \u0026#34;BFGS\u0026#34;)) (lrt.sol3 \u0026lt;- -2 * (loglik_val(sol3) - loglik_val(sol))) #\u0026gt; [1] 285.0265 pchisq(lrt.sol3, df = 1, lower.tail = FALSE) # compute the p-value #\u0026gt; [1] 6.029289e-64 This has a p-value of essentially zero, so we reject the null hypothesis that b1 = 0.\nLets compare the confidence intervals for each of these models.\nprint(confint(sol)) #\u0026gt; 2.5% 97.5% #\u0026gt; b0 -0.4542147 0.003489406 #\u0026gt; b1 0.4140362 0.498142415 print(confint(sol2)) #\u0026gt; 2.5% 97.5% #\u0026gt; param1 0.4244712 0.4989475 print(confint(sol3)) #\u0026gt; 2.5% 97.5% #\u0026gt; param1 -2.722463 -2.269829 We see that the 95% confidence interval for b0 does not include zero, so we reject the null hypothesis that b0 = 0. The 95% confidence interval for b1 does not include zero, so we reject the null hypothesis that b1 = 0.\nYou can see tutorials for more examples of using the package in the vignettes.\n",
        "summary": "\u003ch1 id=\"algebraicmle\"\u003ealgebraic.mle\u003c/h1\u003e\n\u003cp\u003eAlgebraic maximum likelihood estimators\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/algebraic.mle\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 1 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: R\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://queelius.github.io/algebraic.mle/\"\u003eGitHub Pages\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003ch1 id=\"r-package-algebraicmle\"\u003eR package: \u003ccode\u003ealgebraic.mle\u003c/code\u003e\u003c/h1\u003e\n\u003c!-- badges: start --\u003e\n\u003cp\u003e\u003ca href=\"https://www.gnu.org/licenses/gpl-3.0\"\u003e\u003cimg src=\"https://img.shields.io/badge/license-GPL--3-blue.svg\" alt=\"GPL-3\nLicense\"\u003e\u003c/a\u003e\u003c/p\u003e\n\u003c!-- badges: end --\u003e\n\u003cp\u003e\u003ccode\u003ealgebraic.mle\u003c/code\u003e is an R package that provides an algebra over Maximum\nLikelihood Estimators (MLEs). These estimators possess many desirable,\nwell-defined statistical properties which the package helps you\nmanipulate and utilize.\u003c/p\u003e\n\u003ch2 id=\"installation\"\u003eInstallation\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003ealgebraic.mle\u003c/code\u003e can be installed from GitHub by using the devtools\npackage in R:\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "abstract-data-type",
        "link": "http://localhost:1313/categories/abstract-data-type/",
        "date": "2021-11-02 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "bifunctor",
        "link": "http://localhost:1313/tags/bifunctor/",
        "date": "2021-11-02 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "computation",
        "link": "http://localhost:1313/tags/computation/",
        "date": "2021-11-02 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "homomorphic-computational-extensions",
        "link": "http://localhost:1313/projects/homomorphic_computational_extensions/",
        "date": "2021-11-02 00:00:00 +0000 UTC",
        "content": "Introduction We consider homomorphisms which are based on computational concerns which are used to transform inefficient or lossy computations over some original domain $T$ into a conceptually equivalent group $T^*$ over a restricted set of operations.\nIf the original problem can be solved using these restricted operations, then we may transform $T$ into $T^*$ and efficiently perform the computations. Sometimes, the entire solution cannot be transformed back to $T$, but the restricted set of functions or operations may still be sufficient, e.g., evaluating $a + c \u0026lt; b + c$ even though $a+c$ or $b+c$ may not be in the domain of $T$.\nMotivation Suppose you have a value type $T$ (e.g., $\\color{tan}\\texttt{double}$ or something more fancy), but when you apply some operations to it, undesirable behavior is produced, e.g., $\\color{tan}\\texttt{double}$ overflows due to multiplications or loses too much precision due to round-off error.\nIn the case of a numeric type like $\\color{tan}\\texttt{double}$, one option is to use a big number library. However, this approach has some disadvantages:\nYou may not want to have a dependency on some external library The big number implementation may be too inefficient. Assume the computational basis of $T$ is $F(T) = \\{*,/,+,-,\u0026lt;,==\\}$, which can be used to relatively efficiently implement other operations like $\\sin$.\nSuppose we map $T$ to a modified type $\\hat{T}$ such that the computational basis $F(\\hat{T})$ is a proper subset of $F(T)$, say $F(\\hat{T}) = \\{*,/,\u0026lt;,==\\}$. In exchange for this restriction, the undesired behavior may be avoidable, say multiplications and divisions almost never overflow or underflow. If we do not require the operations in basis $F(T)$, this is a good exchange.\nAlternatively, if the computational basis $F(T)$ is needed, it may or may not be possible to map $\\hat{T}$ back to $T$ without any loss of information.\nExample Suppose we try to compute $a!/b!$ (ratio of factorials). The end result may be a value in the domain of $T$, but intermediate values (e.g., $a!$) may only be in the domain of $\\hat{T}$. In this case, we can map the final result back to $T$ without any loss.\nThe logarithm of the data is a natural candidate for this is mapping $\\color{tan}\\texttt{double}$ to $\\color{tan}\\widehat{\\texttt{double}}$ with the restricted basis\n$$ \\\\{*,/,\u003c,==,=\\\\} $$such that any of these operations almost never fail and can be performed very efficiently, both in terms of time and space complexity.\nCode template \u0026lt;typename T = double\u0026gt; struct lg { T k; lg(lg const \u0026amp;) = default; // default constructs the multiplicative identity lg() : k(T(0)) {} lg(T x) : k(log(x)) { assert(0 \u0026lt; x); }; // operator to convert (back) to type T. operator T() const { return exp(k); } }; template \u0026lt;typename T\u0026gt; auto operator*(lg\u0026lt;T\u0026gt; x, lg\u0026lt;T\u0026gt; y) { return lg\u0026lt;T\u0026gt;{x.k + y.k}; } template \u0026lt;typename T\u0026gt; auto operator/(lg\u0026lt;T\u0026gt; x, lg\u0026lt;T\u0026gt; y) { return lg\u0026lt;T\u0026gt;{x.k - y.k}; } template \u0026lt;typename T\u0026gt; auto operator\u0026lt;(lg\u0026lt;T\u0026gt; x, lg\u0026lt;T\u0026gt; y) { return x.k \u0026lt; y.k; } template \u0026lt;typename T\u0026gt; auto operator==(lg\u0026lt;T\u0026gt; x, lg\u0026lt;T\u0026gt; y) { return x.k == y.k; } ",
        "summary": "Class of homomorphic monads that \u003cem\u003eextend\u003c/em\u003e algebraic data types in some well-defined way for faciliating faster or more accurate calculations, such as the logarithm trick.",
        "tags": ["homomorphism","computation","computer science","bifunctor"],
        "section": "projects"
      },{
        "title": "homomorphism",
        "link": "http://localhost:1313/tags/homomorphism/",
        "date": "2021-11-02 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "monad",
        "link": "http://localhost:1313/categories/monad/",
        "date": "2021-11-02 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "computational-statistics-siue-stat-575-problem-set-2",
        "link": "http://localhost:1313/probsets/stat575/stat575-problem-set-2/",
        "date": "2021-10-30 00:00:00 +0000 UTC",
        "content": "Problem 1 Derive the E-M algorithm for right-censored normal data with known variance, say $2 = 1$. Consider $Y_i$s that are i.i.d. from a $N(\\theta, 1)$, $i=1,2\\ldots, n$. We observe $(x_1, \\ldots, x_n)$ and $(\\delta_1, \\ldots, \\delta_n)$, where $x_i = \\min(y_i,c)$, and $\\delta_i = I(y_i \u0026lt; c)$. Let $C$ be the total number of censored (incomplete) observations. We denote the missing data as ${Z_i : \\delta_i = 0}$.\nPart (a) Derive the complete log-likelihood, $\\ell(\\theta | Y)$.\nSolution $$ Y_i \\sim f_{Y_i}(y | \\theta) $$$$ f_{Y_i}(y | \\theta) = (2 \\pi)^{-\\frac{1}{2}} \\exp\\left(-\\frac{1}{2}(y - \\theta)^2\\right). $$$$ \\begin{align*} L(\\theta | \\{y_i\\}) \u0026= \\prod_{i=1}^{n} (2 \\pi)^{-\\frac{1}{2}} \\exp\\left(-\\frac{1}{2}(y_i - \\theta)^2\\right)\\\\ \u0026= (2 \\pi)^{-\\frac{n}{2}} \\exp\\left(-\\sum_{i=1}^{n} \\frac{1}{2}(y_i - \\theta)^2\\right). \\end{align*} $$$$ \\begin{align*} \\ell(\\theta | \\{y_i\\}) \u0026= \\log L(\\theta | \\{y_i\\})\\\\ \u0026= -\\frac{n}{2} \\log (2 \\pi) - \\frac{1}{2} \\sum_{i=1}^{n} (y_i - \\theta)^2\\\\ \u0026= -\\frac{n}{2} \\log (2 \\pi) - \\frac{1}{2} \\sum_{i=1}^{n} y_i^2 + \\theta \\sum_{i=1}^{n} y_i - \\frac{n}{2} \\theta^2. \\end{align*} $$$$ \\ell(\\theta | \\{y_i\\}) = k + \\theta \\sum_{i=1}^{n} y_i - \\frac{n}{2} \\theta^2. $$Part (b) $$ E(Y | x, \\delta=1, \\theta^{(t)}) = x $$$$ E(Y | x, \\delta=0, \\theta^{(t)}) = E(Y | Y \u003e x) = \\theta^{(t)} + \\frac{\\phi(x-\\mu)}{1 - \\Phi(x-\\mu)} $$ where $\\phi$ and $\\Phi$ are pdf and cdf of standard normal.\nSolution The distribution of $Y$ given $\\delta = 1$, is uncensored and therefore it is given that $Y$ realized the value $x$. Since the expectation of a constant $x$ is $x$, that means $E(Y | Y = x) = x$.\nIf $\\delta = 0$, $Y$ is censored, i.e., $Y \u0026gt; x$. To take its expectation, we first need to derive the conditional conditional distribution of $Y$ given $Y \u0026gt; x$ and $\\theta^{(t)}$.\n$$ \\Pr(Y \\leq y | Y \u003e x) = \\Pr(x \u003c Y \\leq y) / \\Pr(Y \u003e x) $$$$ \\Pr(Y \\leq y | Y \u003e x) = \\frac{F_Y(y | \\theta^{(t)}) - F_Y(x | \\theta^{(t)})}{1 - F_Y(y | \\theta^{(t)})}. $$ where $F_{Y|\\theta^{(t)}}$ is the cdf of the normal distribution with $\\sigma=1$ and $\\mu=\\theta^{(t)}$.\n$$ F_{Y}(y|\\theta^{(t)}) = \\Phi(y - \\theta^{(t)}), $$$$ \\Pr(Y \\leq y | Y \u003e x) = \\frac{\\Phi(y - \\theta^{(t)}) - \\Phi(x - \\theta^{(t)})}{1 - \\Phi(x - \\theta^{(t)})} $$$$ F_{Y|x}(y|\\theta^{(t)}) = 1 - \\frac{1- \\Phi(y - \\theta^{(t)})}{1 - \\Phi(x - \\theta^{(t)})} $$$$ f_{Y}(y|x,\\theta^{(t)}) = \\frac{\\phi(y - \\theta^{(t)})}{1 - \\Phi(x - \\theta^{(t)})} I(y \u003e x). $$$$ \\begin{align*} E(Y|x,\\theta^{(t)}) \u0026= \\int_{x}^{\\infty} y f_{Y}(y|x,\\theta^{(t)}) dy\\\\ \u0026= \\int_{x}^{\\infty} y \\left(\\frac{\\phi(y - \\theta^{(t)})}{1 - \\Phi(x - \\theta^{(t)})}\\right) dy\\\\ \u0026= \\frac{1}{{1 - \\Phi(x - \\theta^{(t)})}}\\int_{x}^{\\infty} y \\phi(y - \\theta^{(t)}) dy. \\end{align*} $$Analytically, this is a tricky integration problem. Certainly, it would be trivial to numerically integrate this to obtain a solution, but we seek a closed-form solution.\nI searched online, and discovered an interesting way to tackle this integration problem.\n$$ \\frac{df}{dy} = -(y - \\theta) f(y) $$$$ \\int_{a}^{b} \\frac{df}{dy} dy = f(b) - f(a). $$$$ \\begin{align*} E(Y|x,\\theta^{(t)}) \u0026= \\frac{1}{1 - F(x)}\\int_{x}^{\\infty} y f(y) dy\\\\ \u0026= -\\frac{1}{1 - F(x)}\\int_{x}^{\\infty} - (y -\\theta^{(t)}) f(y) dy + \\frac{\\theta^{(t)}}{1-F(x)}\\int_{x}^{\\infty} f(y) dy\\\\ \u0026= -\\frac{1}{1 - F(x)}\\int_{x}^{\\infty} \\frac{df}{dy} dy + \\frac{\\theta^{(t)}}{1-F(x)} (1-F(x))\\\\ \u0026= -\\frac{1}{1 - F(x)}\\left(f(\\infty) - f(x)\\right) + \\theta^{(t)}\\\\ \u0026= \\frac{f(x)}{1 - F(x)} + \\theta^{(t)}. \\end{align*} $$$$ E(Y|x,\\theta^{(t)}) = \\theta^{(t)} + \\frac{\\phi(x-\\theta^{(t)})}{1 - \\Phi(x-\\theta^{(t)})}. $$Part (c) Derive the $E$-step and $M$-step using parts (a) and (b). Give the updating equation.\nSolution E-step The $E$-step entails taking the conditional expectation of the complete log-likelihood function $\\ell(\\theta | {Y_i})$ given the observed data ${x_i}$ and ${\\delta_i}$.\n$$ \\begin{align*} Q(\\theta | \\theta^{(t)}) \u0026= E_{Y_i | x_i,\\delta_i}(\\ell(\\theta | \\{Y_i\\})\\\\ \u0026= E_{Y_i | x_i,\\delta_i}\\left(k + \\theta \\sum_{i=1}^{n} Y_i - \\frac{n}{2} \\theta^2\\right)\\\\ \u0026= k - \\frac{n}{2}\\theta^2 + \\theta \\sum_{i=1}^{n} E_{Y_i | x_i,\\delta_i}(Y_i). \\end{align*} $$$$ Q(\\theta | \\theta^{(t)}) = k - \\frac{n}{2}\\theta^2 + \\theta \\sum_{i=1}^{n} \\delta_i x_i + (1-\\delta_i) \\left(\\theta^{(t)} + \\frac{\\phi(x_i-\\theta^{(t)})}{1 - \\Phi(x_i-\\theta^{(t)})}\\right). $$$$ Q(\\theta | \\theta^{(t)}) = k - \\frac{n}{2}\\theta^2 + C \\theta \\theta^{(t)} + R \\theta + \\theta \\sum_{i=1}^{n} \\frac{(1-\\delta_i)\\phi(x_i-\\theta^{(t)})}{1 - \\Phi(x_i-\\theta^{(t)})}. $$M-step $$ \\theta^{(t+1)} = \\arg\\max_{\\theta} Q(\\theta | \\theta^{(t)}). $$$$ \\frac{d Q(\\theta | \\theta^{(t)})}{d \\theta}\\Biggr|_{\\theta=\\theta^{(t+1)}} = 0, $$$$ -n\\theta^{(t+1)} + C \\theta^{(t)} + R + \\sum_{i=1}^{n} \\frac{(1-\\delta_i)\\phi(x_i-\\theta^{(t)})}{1 - \\Phi(x_i-\\theta^{(t)})} = 0. $$$$ \\theta^{(t+1)} = \\frac{R}{n} + \\frac{C}{n} \\theta^{(t)} + \\frac{1}{n}\\sum_{i=1}^{n}\\frac{(1-\\delta_i)\\phi(x_i-\\theta^{(t)})}{1 - \\Phi(x_i-\\theta^{(t)})}. $$$$ R = \\sum_{i=1}^{n} \\delta_i x_i $$$$ C = \\sum_{i=1}^{n} (1-\\delta_i). $$Part (d) Use your algorithm on the V.A. data to find the MLE of $\\mu$. Take the log of the event times first and standardize by sample standard deviation. You may simply use the censored data sample mean as your starting value.\nSolution In the following R code, we implement the updating equation derived in the previous step. We encapulsate the procedure into a function that takes its arguments in the form of a censored set, uncensorted set, starting value ($\\theta^{(1)}$), and an $\\epsilon$ value to control stopping condition.\n# assuming the uncensored and censored data are distributed normally, # we use the EM algorithm to derive an estimator given censored and uncensored # data. mean_normal_censored_estimator_em \u0026lt;- function(uncensored,censored,theta,eps=1e-6,debug=T) { dev \u0026lt;- sd(log(c(uncensored,censored))) censored \u0026lt;- log(censored) / dev uncensored \u0026lt;- log(uncensored) / dev theta \u0026lt;- log(theta) / dev n \u0026lt;- length(censored) + length(uncensored) C \u0026lt;- length(censored) R \u0026lt;- sum(uncensored) s \u0026lt;- function(theta) { sum \u0026lt;- 0 for (i in 1:C) { num \u0026lt;- dnorm(censored[i],mean=theta,sd=1) denom \u0026lt;- 1-pnorm(censored[i],mean=theta,sd=1) sum \u0026lt;- sum + (num / denom) } sum } i \u0026lt;- 1 repeat { theta.new \u0026lt;- R/n + C/n * theta + (1/n)*s(theta) if (debug==T) { cat(\u0026#34;theta[\u0026#34;, i, \u0026#34;] =\u0026#34;,theta,\u0026#34;, theta[\u0026#34;, i+1, \u0026#34;] =\u0026#34;,theta.new,\u0026#34;\\n\u0026#34;) } if (abs(theta.new - theta) \u0026lt; eps) { theta \u0026lt;- theta.new * dev theta \u0026lt;- exp(theta) return(theta) } i \u0026lt;- i + 1 theta \u0026lt;- theta.new } } We apply this procedure to the indicated data set.\nlibrary(MASS) # has VA data VAs \u0026lt;- subset(VA,prior==0) censored \u0026lt;- VAs$status == 0 censored_xs \u0026lt;- VAs[censored,c(\u0026#34;stime\u0026#34;)] uncensored_xs \u0026lt;- VAs[!censored,c(\u0026#34;stime\u0026#34;)] mu \u0026lt;- mean(uncensored_xs) cat(\u0026#34;mean of the uncensored sample is \u0026#34;, mu, \u0026#34;.\u0026#34;) ## mean of the uncensored sample is 112.1648 . sol \u0026lt;- mean_normal_censored_estimator_em(uncensored_xs,censored_xs,mu) ## theta[ 1 ] = 3.857928 , theta[ 2 ] = 3.424258 ## theta[ 2 ] = 3.424258 , theta[ 3 ] = 3.415443 ## theta[ 3 ] = 3.415443 , theta[ 4 ] = 3.415286 ## theta[ 4 ] = 3.415286 , theta[ 5 ] = 3.415283 ## theta[ 5 ] = 3.415283 , theta[ 6 ] = 3.415283 sol ## [1] 65.2625 We see that our estimate of $\\theta$ is $\\hat{\\theta} = 65.2624985$. (The $\\theta$ before transforming it to the appropriate scale was $3.415283$.)\nThis mean is somewhat lower than anticipated, which makes me suspect something is wrong with my updating equation. If I have the time, I will revisit it.\nProblem 2 Solution Part (a) There are $N=1500$ gay men in the survey sample where $X_i$ denotes the $i$-th persons response to the number of risky sexual encounters he had in the previous $30$ days. Thus, we observe a sample $\\vec{X} = (X_1,X_2,\\ldots, X_N)$.\nWe assume there are $3$ groups in the population, denoted by $z=1$, $t=2$, and $p=3$. Group $1$ members report $0$ risky sexual encounters regardless of the truth where the probability of being a member of group $1$ is denoted by $\\alpha$,\nGroup $2$ members accurately report risky sexual encounters and represent typical behavior where the probability of being a member of group $2$ is denoted by $\\beta$. We assume this group\u0026rsquo;s number of sexual encounters follows a poisson with mean $\\mu$.\nGroup $3$ members accurately report risky sexual encounters and represent high-risk behavior where the probability of being a member of group $3$ is $\\gamma = 1-\\alpha-\\beta$. We assume this group\u0026rsquo;s number of sexual encounters follows a poisson with mean $\\lambda$.\n$$ X_i \\sim f(x | \\vec{\\theta}) = \\alpha I(x=0) + \\beta \\mathrm{Poi}(x | \\mu) + (1-\\alpha-\\beta)\\mathrm{Poi}(x | \\lambda) $$$$ \\vec{\\theta} = (\\alpha,\\beta,\\mu,\\lambda)'. $$$$ \\begin{align*} X_i | Z_i \u0026= 1 \\sim I(x=0),\\\\ X_i | Z_i \u0026= 2 \\sim \\mathrm{Poi}(\\mu),\\\\ X_i | Z_i \u0026= 3 \\sim \\mathrm{Poi}(\\lambda), \\end{align*} $$$$ Z_i \\sim f_{Z_i}(z_i | \\vec{\\theta}) = \\Pr(Z_i=z_i) = \\begin{cases} \\alpha \u0026 z_i = 1,\\\\ \\beta \u0026 z_i = 2,\\\\ \\gamma=1-\\alpha-\\beta \u0026 z_i = 3, \\end{cases} $$$$ f_{X_i,Z_i}(x_i,z_i | \\vec{\\theta}) = \\alpha I(z_i = 1) + \\beta \\mathrm{Poi}(\\mu) I(z_i = 2) + (1-\\alpha-\\beta) \\mathrm{Poi}(\\lambda) I(z_i=3). $$$$ \\mathcal{L}(\\vec{\\theta} | \\vec{X}, \\vec{Z}) = \\prod_{i=1}^{N} f_{X_i,Z_i}(x_i,z_i | \\vec{\\theta}), $$$$ \\mathcal{L}(\\vec{\\theta} | \\vec{X}, \\vec{Z}) = \\left(\\prod_{\\{i | z_i = 1\\}} \\alpha I(x_i=0)\\right) \\left(\\prod_{\\{i | z_i = 2\\}} \\beta \\frac{\\mu^{x_i} e^{-\\mu}}{x_i!}\\right) \\left(\\prod_{\\{i | z_i = 3\\}} \\gamma \\frac{\\lambda^{x_i} e^{-\\lambda}}{x_i!}\\right). $$$$ \\mathcal{L}(\\vec{\\theta} | \\vec{X}, \\vec{Z}) = \\left(\\prod_{\\{i | z_i = 1, x_i = 0 \\}} \\alpha\\right) \\prod_{k=0}^{16} \\left(\\prod_{\\{i | z_i = 2, x_i = k\\}} \\beta \\frac{\\mu^{k} e^{-\\mu}}{k!}\\right) \\prod_{k=0}^{16} \\left(\\prod_{\\{i | z_i = 3, x_i = k\\}} \\gamma \\frac{\\lambda^{k} e^{-\\lambda}}{k!}\\right). $$$$ \\mathcal{L}(\\vec{\\theta} | \\{n_{j,k}\\}) = \\alpha^{n_{1,0}} \\prod_{k=0}^{16} \\beta^{n_{2,k}} \\frac{\\mu^{k n_{2,k}} e^{-\\mu n_{2,k}}}{(k!)^{n_{2,k}}} \\prod_{k=0}^{16} \\gamma^{n_{3,k}} \\frac{\\lambda^{k n_{3,k}} e^{-\\lambda n_{3,k}}}{(k!)^{n_{3,k}}} $$$$ \\ell(\\vec{\\theta} | \\{n_{j,k}\\}) = n_{1,0} \\log \\alpha + \\sum_{k=0}^{16} \\log \\left(\\beta^{n_{2,k}} \\frac{\\mu^{k n_{2,k}} e^{-\\mu n_{2,k}}}{(k!)^{n_{2,k}}}\\right) + \\sum_{k=0}^{16} \\log \\left(\\gamma^{n_{3,k}} \\frac{\\lambda^{k n_{3,k}} e^{-\\lambda n_{3,k}}}{(k!)^{n_{3,k}}}\\right) $$$$ \\begin{split} \\ell(\\vec{\\theta} | \\{n_{j,k}\\}) = n_{1,0} \\log \\alpha + \\sum_{k=0}^{16} \u0026n_{2,k}(\\log \\beta + k \\log \\mu - \\mu - \\log k!) + \\\\ \u0026n_{3,k}(\\log \\gamma + k \\log \\lambda - \\lambda - \\log k!). \\end{split} $$$$ \\ell(\\vec{\\theta} | \\{n_{j,k}\\}) = n_{1,0} \\log \\alpha + \\sum_{k=0}^{16} \\left\\{ n_{2,k}(\\log \\beta + k \\log \\mu - \\mu) + n_{3,k}(\\log \\gamma + k \\log \\lambda - \\lambda) \\right\\}. $$E-step $$ Q(\\vec{\\theta} | \\vec{\\theta}^{(t)}) = E(\\ell(\\vec{\\theta})) $$$$ Q(\\vec{\\theta} | \\vec{\\theta}^{(t)}) = E \\left( n_{1,0} \\log \\alpha + \\sum_{k=0}^{16} \\left\\{ n_{2,k}(\\log \\beta + k \\log \\mu - \\mu) + n_{3,k}(\\log \\gamma + k \\log \\lambda - \\lambda) \\right\\} \\right). $$$$ Q(\\vec{\\theta} | \\vec{\\theta}^{(t)}) = E(n_{1,0}) \\log \\alpha + \\sum_{k=0}^{16} \\left\\{ E(n_{2,k})(\\log \\beta + k \\log \\mu - \\mu) + E(n_{3,k})(\\log \\gamma + k \\log \\lambda - \\lambda) \\right\\} $$ given ${n_j}$ and $\\theta^{(t)}$.\nConsider $E!\\left(n_{2,k} | {n_j}, \\theta^{(t)}\\right)$. To solve this expectation, we must first derive the distribution of $n_{2,k}$.\n$$ \\Pr(Z_j = 2 | x_j = k) = \\Pr(Z_j = 2) \\Pr(x_j = k | Z_j = 2) / \\Pr(x_j = k). $$ We note that $\\Pr(x_j = k)$ is equivalent to $\\pi_k(\\vec{\\theta})$, $\\Pr(Z_j = 2)$ is the definition of $\\beta$, and $\\Pr(x_j = k | Z_j = 2)$ is $f_{X_j|Z_j}(k | Z_j=2) = \\mathrm{Poi}(k | \\mu)$.\n$$ t_k(\\vec{\\theta}) = \\Pr(Z_j = 2 | x_j = k) = \\beta \\mathrm{Poi}(k | \\mu) / \\pi_k(\\vec{\\theta}). $$$$ E(n_{2,k}) = n_k t_k(\\vec{\\theta}^{(t)}). $$$$ E(n_{3,k}) = n_k p_k(\\vec{\\theta}^{(t)}) $$$$ E(n_{1,0}) = n_0 z_0(\\vec{\\theta}^{(t)}), $$$$ Q(\\vec{\\theta} | \\vec{\\theta}^{(t)}) = n_0 z_0(\\vec{\\theta}^{(t)}) \\log \\alpha + \\sum_{k=0}^{16} \\left\\{ n_k t_k(\\vec{\\theta}^{(t)})(\\log \\beta + k \\log \\mu - \\mu) + n_k p_k(\\vec{\\theta}^{(t)})(\\log \\gamma + k \\log \\lambda - \\lambda) \\right\\} $$M-step $$ \\vec{\\theta}^{(t+1)} = \\argmax_{\\vec{\\theta}} Q(\\vec{\\theta} | \\vec{\\theta}^{(t)}). $$$$ \\nabla Q(\\vec{\\theta} | \\vec{\\theta}^{(t)})\\Bigr|_{\\vec{\\theta}=\\vec{\\theta}^{(t+1)}} = \\vec{0}. $$$$ Q_l(\\vec{\\theta},c | \\vec{\\theta}^{(t)}) = Q(\\vec{\\theta} | \\vec{\\theta}^{(t)}) + c(1-\\alpha-\\beta-\\gamma). $$$$ \\frac{\\partial Q_l}{\\partial \\alpha} = \\frac{n_0 z_0(\\theta^{(t)})}{\\alpha} - c = 0, $$$$ \\alpha^{(t+1)} = \\frac{1}{c} n_0 z_0(\\theta^{(t)}). $$$$ \\beta^{(t+1)} = \\frac{1}{c} \\sum_{k=0}^{16} n_k t_k(\\theta^{(t)}). $$$$ \\gamma^{(t+1)} = \\frac{1}{c} \\sum_{k=0}^{16} n_k p_k(\\theta^{(t)}). $$$$ n_0 z_0(\\theta^{(t)}) + \\sum_{k=0}^{16} n_k t_k(\\theta^{(t)}) + \\sum_{k=0}^{16} n_k p_k(\\theta^{(t)}) = N. $$$$ \\begin{align*} \\alpha^{(t+1)} \u0026= \\frac{1}{N} n_0 z_0(\\theta^{(t)})\\\\ \\beta^{(t+1)} \u0026= \\frac{1}{N} \\sum_{k=0}^{16} n_k t_k(\\theta^{(t)})\\\\ \\gamma^{(t+1)} \u0026= \\frac{1}{N} \\sum_{k=0}^{16} n_k p_k(\\theta^{(t)}). \\end{align*} $$$$ \\begin{align*} \\frac{\\partial Q_l}{\\partial \\mu}\\biggr|_{\\mu=\\mu^{(t+1}} \u0026= 0\\\\ \\sum_{k=0}^{16} n_k t_k(\\theta^{(t)})(k/\\mu^{(t+1)}-1) \u0026= 0\\\\ \\frac{1}{\\mu^{(t+1)}} \\sum_{k=0}^{16} n_k t_k(\\theta^{(t)}) k \u0026= \\sum_{k=0}^{16} n_k t_k(\\theta^{(t)})\\\\ \\mu^{(t+1)} \u0026= \\frac{\\sum_{k=0}^{16} k n_k t_k(\\theta^{(t)})}{\\sum_{k=0}^{16} n_k t_k(\\theta^{(t)})}. \\end{align*} $$$$ \\lambda^{(t+1)} = \\frac{\\sum_{k=0}^{16} k n_k p_k(\\theta^{(t)})}{\\sum_{k=0}^{16} n_k p_k(\\theta^{(t)})}. $$Part (b) Estimate the parameters of the model, using the observed data.\nSolution # we observe n = (n0,n1,...,n16) ns \u0026lt;- c(379,299,222,145,109,95,73,59,45,30,24,12,4,2,0,1,1) N \u0026lt;- sum(ns) # theta := (alpha, beta, mu, lambda)\u0026#39; # note that there is an implicit parameter gamma s.t. # alpha + beta + gamma = 1 # the initial value assumes each category z, t, or p # is equally probable, and so we let # (alpha^(0),beta^(0)) = (1/3,1/3) # and mu^(0) and lambda^(0) are just arbitrarily chosen to be 2 and 3, # with the insight that group 3 is more risky than group 2. theta \u0026lt;- c(1/3,1/3,2,3) # theta := (alpha, beta, mu, lambda) Pi \u0026lt;- function(i,theta) { res \u0026lt;- 0 if (i == 0) res \u0026lt;- theta[1] res \u0026lt;- res + theta[2] * theta[3]^i * exp(-theta[3]) res \u0026lt;- res + (1 - theta[1] - theta[2]) * theta[4]^i * exp(-theta[4]) res } z0 \u0026lt;- function(theta) { theta[1] / Pi(0,theta) } t \u0026lt;- function(i,theta) { theta[2] * theta[3]^i * exp(-theta[3]) / Pi(i,theta) } p \u0026lt;- function(i,theta) { (1-theta[1] - theta[2]) * theta[4]^i * exp(-theta[4]) / Pi(i,theta) } # update algorithm, based on EM algorithm update \u0026lt;- function(theta,ns) { # note: n0 := ns[1] instead of ns[0] since R does not use zero-based indexes alpha \u0026lt;- ns[1] * z0(theta) / N beta \u0026lt;- 0 mu_num \u0026lt;- 0 mu_denom \u0026lt;- 0 lam_num \u0026lt;- 0 lam_denom \u0026lt;- 0 for (i in 0:16) { ti \u0026lt;- t(i,theta) pi \u0026lt;- p(i,theta) beta \u0026lt;- beta + ns[i+1] * ti mu_num \u0026lt;- mu_num + i * ns[i+1] * ti mu_denom \u0026lt;- mu_denom + ns[i+1] * ti lam_num \u0026lt;- lam_num + i * ns[i+1] * pi lam_denom \u0026lt;- lam_denom + ns[i+1] * pi } beta \u0026lt;- beta / N mu \u0026lt;- mu_num / mu_denom lam \u0026lt;- lam_num / lam_denom c(alpha,beta,mu,lam) } em \u0026lt;- function(theta,ns,steps=10000,debug=T) { for(i in 1:steps) { theta = update(theta,ns) if (debug==T) { if (i %% 1000 == 0) { cat(\u0026#34;iteration =\u0026#34;,i,\u0026#34; theta = (\u0026#34;,theta,\u0026#34;)\u0026#39;\\n\u0026#34;) } } } theta } # solution theta = (alpha, beta, mu, lambda) sol \u0026lt;- em(theta,ns,10000,T) ## iteration = 1000 theta = ( 0.1221661 0.5625419 1.467475 5.938889 )\u0026#39; ## iteration = 2000 theta = ( 0.1221661 0.5625419 1.467475 5.938889 )\u0026#39; ## iteration = 3000 theta = ( 0.1221661 0.5625419 1.467475 5.938889 )\u0026#39; ## iteration = 4000 theta = ( 0.1221661 0.5625419 1.467475 5.938889 )\u0026#39; ## iteration = 5000 theta = ( 0.1221661 0.5625419 1.467475 5.938889 )\u0026#39; ## iteration = 6000 theta = ( 0.1221661 0.5625419 1.467475 5.938889 )\u0026#39; ## iteration = 7000 theta = ( 0.1221661 0.5625419 1.467475 5.938889 )\u0026#39; ## iteration = 8000 theta = ( 0.1221661 0.5625419 1.467475 5.938889 )\u0026#39; ## iteration = 9000 theta = ( 0.1221661 0.5625419 1.467475 5.938889 )\u0026#39; ## iteration = 10000 theta = ( 0.1221661 0.5625419 1.467475 5.938889 )\u0026#39; We see that the solution is $0.1221661, 0.5625419, 1.4674746, 5.9388889$.\nPart (c) Estimate the standard errors and pairwise correlations of your parameters, using any available method.\nSolution We have chosen to use the Bootstrap method.\n# ns = (379,299,222,145,109,95,73,59,45,30,24,12,4,2,0,1,1) # 379 responded 0 encounters # 299 responded 1 encounters # 222 responded 2 encounters # ... # 1 responded 16 encounters # # to resample, we resample from the data set that includes each # persons response, as determined by ns. data \u0026lt;- NULL for (i in 1:length(ns)) { data \u0026lt;- append(data,rep((i-1),ns[i])) } make_into_counts \u0026lt;- function(data) { ns \u0026lt;- NULL for (i in 0:16) { ni \u0026lt;- data[data == i] l \u0026lt;-length(ni) ns \u0026lt;- append(ns,l) } ns } m \u0026lt;- 1000 # bootstrap replicates em_steps \u0026lt;- 100 theta.bs \u0026lt;- em(theta,ns,em_steps,F) thetas \u0026lt;- rbind(theta.bs) for (i in 2:m) { indices \u0026lt;- sample(N,N,replace=T) resampled \u0026lt;- make_into_counts(data[indices]) theta.bs \u0026lt;- em(theta,resampled,em_steps,F) thetas \u0026lt;- rbind(thetas,theta.bs) if (i %% 100 == 0) { cat(\u0026#34;iteration \u0026#34;, i, \u0026#34;\\n\u0026#34;) print(cov(thetas)) } } ## iteration 100 ## [,1] [,2] [,3] [,4] ## [1,] 0.0004197254 -0.0001718468 0.0017266699 0.001591205 ## [2,] -0.0001718468 0.0005295261 0.0002895402 0.001980314 ## [3,] 0.0017266699 0.0002895402 0.0131179548 0.015108087 ## [4,] 0.0015912053 0.0019803141 0.0151080872 0.047009875 ## iteration 200 ## [,1] [,2] [,3] [,4] ## [1,] 0.0003864557 -1.678292e-04 1.590662e-03 0.00154358 ## [2,] -0.0001678292 4.671077e-04 9.764038e-05 0.00133111 ## [3,] 0.0015906622 9.764038e-05 1.228480e-02 0.01297749 ## [4,] 0.0015435804 1.331110e-03 1.297749e-02 0.03894848 ## iteration 300 ## [,1] [,2] [,3] [,4] ## [1,] 0.0003735625 -1.785107e-04 1.479671e-03 0.001351610 ## [2,] -0.0001785107 4.678372e-04 6.137843e-06 0.001259075 ## [3,] 0.0014796708 6.137843e-06 1.123608e-02 0.011748534 ## [4,] 0.0013516098 1.259075e-03 1.174853e-02 0.036388361 ## iteration 400 ## [,1] [,2] [,3] [,4] ## [1,] 0.0003625489 -0.0001755464 0.0014276201 0.001221715 ## [2,] -0.0001755464 0.0004540625 0.0000184334 0.001288138 ## [3,] 0.0014276201 0.0000184334 0.0110764497 0.010780774 ## [4,] 0.0012217155 0.0012881380 0.0107807741 0.034067537 ## iteration 500 ## [,1] [,2] [,3] [,4] ## [1,] 0.0003718052 -0.0001842823 0.0014502414 0.001310802 ## [2,] -0.0001842823 0.0004847405 0.0001080019 0.001398247 ## [3,] 0.0014502414 0.0001080019 0.0114792580 0.011828494 ## [4,] 0.0013108018 0.0013982467 0.0118284941 0.036489243 ## iteration 600 ## [,1] [,2] [,3] [,4] ## [1,] 0.0003791435 -1.814512e-04 1.497719e-03 0.001364054 ## [2,] -0.0001814512 4.674232e-04 7.293112e-05 0.001410218 ## [3,] 0.0014977193 7.293112e-05 1.157800e-02 0.011903853 ## [4,] 0.0013640538 1.410218e-03 1.190385e-02 0.037292937 ## iteration 700 ## [,1] [,2] [,3] [,4] ## [1,] 0.0003819013 -1.782221e-04 1.521678e-03 0.001410964 ## [2,] -0.0001782221 4.546723e-04 8.545081e-05 0.001405131 ## [3,] 0.0015216781 8.545081e-05 1.178236e-02 0.012322621 ## [4,] 0.0014109640 1.405131e-03 1.232262e-02 0.037738946 ## iteration 800 ## [,1] [,2] [,3] [,4] ## [1,] 0.0003730646 -0.0001676221 0.0015068905 0.001443218 ## [2,] -0.0001676221 0.0004405397 0.0001354924 0.001470624 ## [3,] 0.0015068905 0.0001354924 0.0118808619 0.012889971 ## [4,] 0.0014432180 0.0014706239 0.0128899710 0.038858338 ## iteration 900 ## [,1] [,2] [,3] [,4] ## [1,] 0.0003676784 -0.0001699529 0.0014571801 0.001358486 ## [2,] -0.0001699529 0.0004554077 0.0001823193 0.001590474 ## [3,] 0.0014571801 0.0001823193 0.0117524614 0.012790632 ## [4,] 0.0013584862 0.0015904740 0.0127906324 0.039055305 ## iteration 1000 ## [,1] [,2] [,3] [,4] ## [1,] 0.0003697739 -0.0001652985 0.0014912066 0.001367237 ## [2,] -0.0001652985 0.0004523873 0.0002111503 0.001638727 ## [3,] 0.0014912066 0.0002111503 0.0120934727 0.013311533 ## [4,] 0.0013672372 0.0016387267 0.0133115328 0.039376614 cov.bs \u0026lt;- cov(thetas) cor.bs \u0026lt;- cor(thetas) The Bootstrap estimator of the covariance matrix is given by\n## [,1] [,2] [,3] [,4] ## [1,] 0.0003697739 -0.0001652985 0.0014912066 0.001367237 ## [2,] -0.0001652985 0.0004523873 0.0002111503 0.001638727 ## [3,] 0.0014912066 0.0002111503 0.0120934727 0.013311533 ## [4,] 0.0013672372 0.0016387267 0.0133115328 0.039376614 and the correlation matrix is given by\n## [,1] [,2] [,3] [,4] ## [1,] 1.0000000 -0.40415269 0.70517057 0.3583080 ## [2,] -0.4041527 1.00000000 0.09027364 0.3882685 ## [3,] 0.7051706 0.09027364 1.00000000 0.6100050 ## [4,] 0.3583080 0.38826847 0.61000496 1.0000000 Let\u0026rsquo;s try using the Hessian of the observed information matrix.\nlibrary(numDeriv) loglike \u0026lt;- function(theta) { s \u0026lt;- 0 for (x in data) { s \u0026lt;- s + log(theta[1]*as.numeric(x==0) + theta[2]*dpois(x,theta[3]) + (1-theta[1]-theta[2])*dpois(x,theta[4])) } s } mle \u0026lt;- c(0.1221661,0.5625419,1.4674746,5.9388889) solve(-hessian(loglike,mle)) ## [,1] [,2] [,3] [,4] ## [1,] 0.0003799048 -1.909698e-04 1.438556e-03 0.001184057 ## [2,] -0.0001909698 4.657702e-04 7.132638e-05 0.001417409 ## [3,] 0.0014385560 7.132638e-05 1.111722e-02 0.011376017 ## [4,] 0.0011840568 1.417409e-03 1.137602e-02 0.034664940 ",
        "summary": "This problem set covers the E-M algorithm for right-censored normal data with known variance.",
        "tags": ["statistics","R","computation","EM algorithm","statistical inference"],
        "section": "probsets"
      },{
        "title": "data-mining",
        "link": "http://localhost:1313/tags/data-mining/",
        "date": "2021-10-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "em-algorithm",
        "link": "http://localhost:1313/tags/em-algorithm/",
        "date": "2021-10-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "em-algorithm",
        "link": "http://localhost:1313/categories/em-algorithm/",
        "date": "2021-10-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "monte-carlo-simulation",
        "link": "http://localhost:1313/tags/monte-carlo-simulation/",
        "date": "2021-10-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "multiprocessor-synchronization-tournament-peterson-lock",
        "link": "http://localhost:1313/posts/2012-03-05-tournament-lock/tournament_lock/",
        "date": "2021-10-30 00:00:00 +0000 UTC",
        "content": "Multiprocessor synchronization is a notoriously tricky subject matter. Unlike with a single thread of execution, in a shared-resource system, where resources are shared among multiple independent processors, we must think very hard about how the critical sections where such shared resources are accessed.\nDefinition: Peterson\u0026rsquo;s algorithm is a concurrent programming algorithm for mutual exclusion that allows two or more processes to share a single-use resource without conflict, using only shared memory for communication.\nIn this post, we generalize the result and provide a Java-based solution.\nGeneralization to a power of 2 locks A way to generalize the two-thread Peterson lock is to arrange a number of 2-thread Peterson locks in a binary tree. Suppose $n$ is a power of two. Each thread is assigned a leaf lock which it shares with one other thread. Each lock treats one thread as thread 0 and the other as thread 1. In the tree-locks acquire method, the thread acquires every two-thread Peterson lock from that thread\u0026rsquo;s leaf to the root. The tree-locks release method for the tree-lock unlocks each of the 2-thread Peterson locks that thread has acquired, from the root back to its leaf. At any time, a thread can be delayed for a finite duration. (In other words, threads can take naps, or even vacations, but they do not drop dead.)\nTheorem: The tournament-Peterson lock guarantees mutual exclusion.\n$$ \\lceil \\log_2 n/2\\rceil = \\lceil log_2 n  1 \\rceil $$ layers, after which point only one thread can remain. Therefore, the root node represents the final lock, for which only two other threads may acquire access to at any given moment. Of these two threads, the thread that acquires this final lock will have effectively acquired the actual lock.\nSince each node is mutually exclusive for two threads, and the tree structure only allows 2 threads to reach each node, then each subtree must ensure mutual exclusion to its root node. Therefore, the root of the entire tree must also ensure mutual exclusion. \nTheorem: The tournament-Peterson lock guarantees freedom from deadlock.\nProof: When a thread A releases a lock, for each of the nodes in its path from the root to its leaf node, it sets the flag variable for each Peterson lock corresponding to it (A) to false. Thus, for each node that it visited in its path, the other node that \u0026ldquo;lost\u0026rdquo; must be able to progress since its no longer the case that\nflag[A] == true \u0026amp;\u0026amp; victim == ~A is true, therefore each one must escape the while loop and therefore be promoted to the next level. Therefore, it must be deadlock free. \nTheorem: The tournament-Peterson lock guarantees freedom from starvation.\nProof: Starvation freedom guarantees deadlock freedom, but it is not the case that deadlock freedom guarantees starvation freedom. So, in answer (4b) above, while we may have shown that deadlock is not possible, have we shown that starvation is also not possible? No. So, lets consider this case separately. For something to be starvation free, each thread trying to acquire a lock must eventually acquire the lock. We know that for starvation to happen, a thread must be bypassed forever. Each Peterson lock itself is starvation free, so it cannot happen at the level of a single node. Immediately, then, we see that it simply cannot happen: at each layer in the tree, the thread to arrive earlier (such that it is not the victim) must be promoted. Recursively, then, we see that each subtree is starvation free, therefore the entire tree is starvation free. \nTournament-Peterson Lock Here is the source code solution.\n/** * @title Tournament-Peterson lock * * @author Alex Towell (lex@metafunctor.com) * @file TournamentPeterson.java * @since 1.6 * @date 2/8/2011 * @course CS 590-002 Multiprocessor Synchronization * @desc Implementation of an n-thread lock using a binary tree of 2-thread * Peterson locks. The number of threads the lock correctly works with * must be specified upon Tournament lock instantiation. * * @require Lock.java, Peterson.java, ThreadID.java * * @precondition * each thread must have a ThreadID in the range of 0 to threads-1, * where threads is an integer passed to the constructor. * * @note I modified the Peterson lock slightly so that its constructor * accepts a single int parameter for determining the flag-thread * mapping. */ package TournamentPetersonLock; /** * Tournament tree lock. * * Tournament tree of Peterson locks to provide mutually exclusive access to * a critical section for n threads. * * Each Peterson lock is a 2-thread lock, so the Tournament tree is a binary * tree of such locks which only permits one thread from each of its left and * right subtrees to pass to it. * * @note the number of threads the lock correctly works with must be * specified upon construction of the Tournament lock * * @precondition each thread using the Tournament tree must have a unique * thread ID in the range of [0, threads-1] * * @see Lock * @see Peterson * @see ThreadID */ class Tournament implements Lock { /** * Construct a Tournament lock for the specified number of threads. * * @param threads the number of threads to configure the lock for */ public Tournament(int threads) { this.threads = threads; this.locks = new Peterson[threads]; // note: root will be at index 1, // so locks array size is locks+1 // instantiate and configure each Peterson lock createLocks(1, threads/2, threads/2); } /** * Used by current thread to request a lock on a critical section protected * by this Tournament lock. * * @precondition thread does not have the lock * @postcondition thread acquired the lock */ public void lock() { // start at the leaf node lock for current thread int index = getLeafLock(); // root is index 1, so exit the while loop when index 0 (index of // unitialized node lock) is reached. while (index != 0) { locks[index].lock(); index /= 2; } } /** * Release a lock on a critical section (releases each of the Peterson * locks a thread acquired). * * @precondition thread has the lock * @postcondition thread released the lock * * @see #unlock(int) */ public void unlock() { unlock(getLeafLock()); // call unlock(int) on leaf node for thread } /** * Private method helper for unlock(). * * @param index * unlock all nodes along the path from the root to the leaf node * corresponding to current thread */ private void unlock(int index) { if (index != 0) { unlock(index/2); locks[index].unlock(); // post-order: unlock after recursive call // to unlock from root down to leaf } } /** * Private helper function that creates Peterson locks for subtree rooted * at specified index. * * Each Peterson lock is created such that when a thread calls lock() or * unlock(), it will be assigned the correct flag index into each of the * Peterson nodal locks of the Tournament tree. * * @precondition index \u0026gt; 0 * @postcondition every lock in the subtree rooted at index will be * configured correctly * * @param index * subtree\u0026#39;s rooted index (array-based binary tree) to create locks * for * @param lessThan * if a thread arrives at this lock node, any thread ID \u0026lt; lessThan * will be assigned to index 0 in the Peterson lock flag array, * otherwise it will be assigned to index 1 * @param size * the size of left or right subtree of parent at specified index */ private void createLocks(int index, int lessThan, int size) { if (index \u0026lt; threads) { // instantiate Peterson lock at specified node locks[index] = new Peterson(lessThan); // instantiate the left and right subtrees of this node size /= 2; createLocks(getLeftChild(index), lessThan - size, size); createLocks(getRightChild(index), lessThan + size, size); } } /** * Returns the index of the leaf node for current thread. * * This private helper method will map a ThreadID to the proper leaf * node index in the Tournament tree of Peterson locks. */ private int getLeafLock() { return (threads + ThreadID.get())/2; } /** * Returns the index of the left child node of the parent node at * specified index. * * @param index index of parent node * @return int * index of left child node, note that if return value is \u0026gt;= threads * then node at index is a leaf */ private static int getLeftChild(int index) { return 2*index; } /** * Returns the index of the right child node of the parent node at * specified index. * * @param index index of parent node. * @return int * index of right child node, note that if return value is \u0026gt;= threads * then node at index is a leaf */ private static int getRightChild(int index) { return 2*index+1; } /** * Array of 2-thread Peterson locks. * * @see Peterson */ private Peterson[] locks; /** * The number of threads constructed to work with. * * @see #Tournament(int) */ private int threads; } ",
        "summary": "\u003cp\u003eMultiprocessor synchronization is a notoriously tricky subject matter.\nUnlike with a single thread of execution, in a shared-resource system, where\nresources are shared among multiple independent processors, we must think very\nhard about how the critical sections where such shared resources are accessed.\u003c/p\u003e\n\u003cp\u003eDefinition: Peterson\u0026rsquo;s algorithm is a concurrent programming algorithm for mutual\nexclusion that allows two or more processes to share a single-use resource without\nconflict, using only shared memory for communication.\u003c/p\u003e",
        "tags": ["computer science","multiprocessor synchronization","mutex"],
        "section": "posts"
      },{
        "title": "mutex",
        "link": "http://localhost:1313/tags/mutex/",
        "date": "2021-10-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "r",
        "link": "http://localhost:1313/categories/r/",
        "date": "2021-10-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "categories"
      },{
        "title": "review-a-symbolic-representation-of-time-series-with-implications-for-streaming-algorithms",
        "link": "http://localhost:1313/posts/2012-02-04-sax/cs584_sax_review/",
        "date": "2021-10-30 00:00:00 +0000 UTC",
        "content": "In [1], the authors present a method for constructing a symbolic (nominal) representation for real-valued time series data. A symbolic representation is desirable because then it becomes possible to use many of the effective algorithms that require symbolic representation, like hashing and Markov models.\nThe authors claim that one of the most useful time series operations is measuring the similarity between two time series data sets. To do this on the original time series, the Euclidean distance formula can be used. Therefore, for a time series transformation to be useful, distance measures applied to the corresponding transformations should provide some guaranteed lower bound on the true distance. This is a basic requirement for almost all time series algorithms in data mining. Non-symbolic transformations like Discrete Fourier Transform (DFT) and Piecewise Aggregate Approximation (PAA) models have this lower-bounding property. However, the authors claim no previously proposed symbolic representations do, which limits their usefulness.\nAdditionally, the authors observe that most raw time series data sets have very high dimensionality. This is problematic because time series mining algorithms are $\\mathcal{O}(cn)$, where n is the number of dimensions. Therefore, preferably any transformations on the original time series will reduce the dimensionality to a more manageable size. Unfortunately, the authors observe, previously proposed symbolic representations preserve the original time series dimensionality.\nNext, the authors present their symbolic representation, SAX (Symbolic Aggregate approXimation), which addresses each of the previously mentioned shortcomings of symbolic representations.\nSAX is unique in that it uses an intermediate transformation, PAA, and then nominalizes the PAA representation into a sequence of characters\u0026rsquo;a string. By using the intermediate PAA representation, SAX enjoys two benefits:\nIt is able to exploit the dimensionality reducing properties of PAA, and\nIt provably lower bounds PAA, and PAA provably lower bounds the original time series. Therefore, through the transitivity relationship, SAX provably lower bounds the original time series.\nHaving the SAX representation offers many benefits in addition to those mentioned previously. For instance, when extracting subsequences of size $n$ from the original time series $T$, a sliding window approach can be used. However, this means $|T| - n + 1$ subsequences must be stored. When working with the SAX representation, however, the symbolic representation generalizes many subsequences such that many subsequences that were distinct in the original time series are identical in SAX. This allows one to compress the subsequence data using techniques like run-length encoding. This compressed form may be quite advantageous, especially if memory constraints are a factor.\nTo transform a time series into SAX, first the time series must be transformed into PAA. Next, an additional discretizing transformation is applied on the PAA. This is done in such a way as to make each discrete symbol appear with an equal probability in the string. This can be easily done if we observe that the original normalized time series has a normal distribution, therefore we simply need to partition the possible values in a time series into $a$ intervals ($a$ represents the number of discrete symbols in our alphabet\u0026ndash;larger values of a correspond to more granular approximations), where the range of values in each interval has an equal probability of occurring (thus, for example, the interval containing the mean will likely be relatively small). Determining where the intervals begin and end can be easily done, since the time series has a normal distribution. Once the intervals are calculated, the PAA can be discretized into a string of symbols, ${a, b, c, \\ldots}$, by assigning symbol $a$ to PAA coefficients that fall within the first interval, symbol $b$ to PAA coefficients that fall within the second interval, and so on until every PAA coefficient has been discretized. At this point, the original time series has been transformed into SAX.\nTo show that the SAX distance measures can be made to lower bound the original time series, the authors first demonstrate distance measure for the PAA, which is similar to the Euclidean distance formula:\n$$ \\operatorname{DR}(\\bar{Q},\\bar{C}) = \\sqrt{\\frac{n}{w} \\sum_{i=1}^w (\\bar{q}_i-\\bar{c}_i )^2}. $$$\\operatorname{DR}$ lower bounds the Euclidean distance formula for the original time series, where $\\bar{Q}$ and $\\bar{C}$ represent the PAA transformation of time series $Q$ and $C$. With this formula in mind, next they present the distance formula for SAX:\n$$ \\operatorname{MIN\\_DIST}(\\bar{Q},\\bar{C})=\\sqrt{\\frac{n}{w} \\sum_{i=1}^w (\\operatorname{dist}(\\hat{q}_i-\\hat{c}_i))^2} $$The authors observe that the above two formulas are identical, except for the presence of the inner dist function. Since $\\operatorname{dist}(\\hat{q} - \\hat{c})$ lower-bounds $\\bar{q}_i-\\bar{c}_i$, $\\operatorname{MIN_DIST}$ must lower bound $\\operatorname{DR}$. And, by transitivity relation, $\\operatorname{MIN_DIST}$ therefore lower-bounds the distance measure for the original time series.\nThe authors then go on to show how the dist function can be a fast table lookup, where the table is the cross product of the symbols ${a, b, \\ldots}$. Each cell in the table represents the distance between the row symbol and the column symbol, and its value can be calculated with a straightforward formula.\nNext, the authors conduct a number of experiments to empirically test the validity and performance of SAX when compared to the traditional Euclidean distance formula (on the original time series data) and other representations.\nFor instance, they show the experimental results generated with hierarchical clustering. The results reveal that the clusters generated from the SAX representation (using MINDIST as the distance measure) are the same as the clusters generated from the original time series (using the classical Euclidean distance formula). Other symbolic representations performed poor by comparison, and the authors stipulate that the superior performance of SAX can be attributed to the smoothing effect caused by dimensionality reduction.\nThey discuss the results of other experiments as well. In each case, SAX performs comparatively well, and in some cases it does better than the Euclidian distance measure on the original time series.\nNext, the authors demonstrate the advantages of having a symbolic representation of a time series. For instance, motif discoverylooking for subsequences with the same general patterncan be accomplished by hashing (which requires discrete data) subsequences into buckets using a random subset of the subsequence as the key, then searching through the buckets. Note that since SAX provides a symbolic representation, it tends to be resilient to noise (it is not over-fitted to the noise) because the discrete values smooth out most of the variations caused by noise.\nFinally, the authors present their conclusion. They emphasize that their experimental results demonstrate that SAX is competitive or superior to other approaches on a variety of classification and clustering problems. Furthermore, they point out that the symbolic nature of SAX opens it up to other domains, like motif discovery which cannot be done on real-valued data. They close with a few remarks on future directions to pursue with SAX; notably, they are curious to see how well other data mining algorithms (that require discrete representations) do when paired with SAX.\nAnalysis and Critique The symbolic nature of SAX opens up the possibility of using many fast and efficient algorithms and data structures (that require discrete representations) developed in other disciplines which are unavailable to real-valued representations, like PAA or FFT. However, SAX does so while still providing a lower bound on the distance measures of the original time series, unlike other symbolic representations discussed in the paper. This suggests that SAX is offering a reasonable approximation (to whatever degree is required) of the original time series, which gives us confidence in its results. SAX allows us to use its simplified, dimensionally reduced transformation in memory constrained environments, reasonably confident that the results acquired on its reduced data set will be applicable to the larger, original data set. Since time series data sets tend to be quite large, this advantage should not be overlooked.\nHowever, I would argue the more important properties of SAX have more to do with its symbolic nature and less to do with its dimensionally reduced form. Since it offers an accurate (according to the MINDIST lower bounding property) symbolic representation, it is able to effectively generalize the time series data points, permitting more sophisticated analysis of time series that is resilient to noise. For instance, the motif discovery algorithm, PROJECTION [2], is quite promising, and has applicability to a wide range of domains. This algorithm is only possible if the time series has been discretized as required by the hashing function.\nUnfortunately, in parts the paper was more difficult to read than it needed to be. This is, of course, not uncommon. While I feel I was able to understand their work, at times I had to take a second, third, or even fourth look at the text to adequately grasp the material presented. In some cases, simple fixes like providing better examples would have sufficed. For instance, in their paper, much of the discussion in Section 3 was about how to construct a symbolic representation of a time series. For much of the discussion, they used an alpha size of three (such that there were only three possible values that a data point could have, a, b, or c). However, the first time they illustrate the dist table (Table 4) for facilitating distance measures between symbolic pairs, they use an alphabet of size four. In particular, Figure 5 used an alphabet of size three, and it would have been convenient to be able to compare it to Table 4.\nAlso, they do not adequately address many of the topics mentioned in their abstract and introduction. For instance, they mention streaming in the title of their paper, and throughout the abstract, but then barely mention it again throughout the remainder of the paper. I strongly believe that SAX is amenable to streaming algorithms, but the authors could have did a better job at demonstrating this.\nConclusion Overall, despite my criticisms, the paper effectively conveys the main thrust of their accomplishment, SAX, and how it can be put to use. Furthermore, the authors seem to be addressing a rather urgent need (in 2003 and even today), especially in light of the exponentially growing volume of time series data being generated. As the saying goes, we are increasingly data rich but information poor. Thus, we need more effective ways to analyze and find patterns in these huge data sets. The authors of [1] make a convincing case that SAX will help us towards this end.\nReferences [1] Ramakrishnan Srikant and Rakesh Agrawal. A Symbolic Representation of Time Series, with Implications for Streaming Algorithms. In Proceedings of the 8th ACM SIGMOD workshop on Research issues in data mining and knowledge discovery (2003), pp. 2-11.\n[2] Tompa, M. \u0026amp; Buhler, J. (2001). Finding Motifs Using Random Projections. In proceedings of the 5th Intel Conference on Computational Molecular Biology. Montreal, Canada, Apr 22-25. pp. 67-74.\n",
        "summary": "\u003cp\u003eIn [1], the authors present a method for constructing a symbolic (nominal) representation for real-valued time series data. A symbolic representation is desirable because then it becomes possible to use many of the effective algorithms that require symbolic representation, like hashing and Markov models.\u003c/p\u003e\n\u003cp\u003eThe authors claim that one of the most useful time series operations is measuring the similarity between two time series data sets. To do this on the original time series, the Euclidean distance formula can be used. Therefore, for a time series transformation to be useful, distance measures applied to the corresponding transformations should provide some guaranteed lower bound on the \u003ccode\u003etrue\u003c/code\u003e distance. This is a basic requirement for almost all time series algorithms in data mining. Non-symbolic transformations like Discrete Fourier Transform (DFT) and Piecewise Aggregate Approximation (PAA) models have this lower-bounding property. However, the authors claim no previously proposed symbolic representations do, which limits their usefulness.\u003c/p\u003e",
        "tags": ["statistics","time series","computation","symbolic","data mining"],
        "section": "posts"
      },{
        "title": "siue-computational-statistics-stat-575-problem-set-4",
        "link": "http://localhost:1313/probsets/stat575/problem_set_4/",
        "date": "2021-10-30 00:00:00 +0000 UTC",
        "content": "Problem 1 Use Metropolis Hasting algorithm to generate $Y \\sim \\mathrm{Gamma}(\\alpha, 1)$, where $\\alpha \u0026gt; 1$. Note $\\alpha$ need not to be an integer. Consider the proposal distribution $g$, which is the density of $\\mathrm{GAM}(a,b)$, where $a=\\lfloor \\alpha \\rfloor$ and $b = a/\\alpha$.\nPart (a) Implement your accept-reject algorithm and Metropolis-hastings algorithms to get a sample of $10000$ from $Y \\sim \\mathrm{Gamma}(\\alpha=2.5,1)$.\nAcceptance-rejection sampler We implement the density and sampler functions, respectively $\\mathrm{dgamma1}$ and $\\mathrm{rgamma1}$.\n$$ f_X(x) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha-1} e^{-\\beta x}. $$$$ Z = \\sum_{i=1}^{a} X_i \\sim \\mathrm{Gamma}(a,b) $$ where $X_i \\sim \\mathrm{Exponential}(b)$.\n$$ c = \\max_y \\left\\{\\frac{f_Y(y)}{f_Z(y)}\\right\\}, $$ but in general $c$ must only satisfy $f_Y(y) / c f_Z(y) \\leq 1$.\n$$ \\frac{d}{dy}\\log h(y)\\Bigr|_{y = y^*} = 0, $$$$ c = h(y^*) = (\\alpha/e)^{\\alpha-\\lfloor \\alpha \\rfloor}. $$ Observe that if $\\alpha$ is an integer, then $c = 1$ and $h(y) = 1$, in which case the target distribution and the candidate distribution are identical.\nWe implement the acceptance-rejection algorithm with the following code:\n# The density function for random variates in the family # GAM(shape=alpha,rate=1) dgamma1 \u0026lt;- function(x, alpha) { dgamma(x, shape = alpha, rate = 1) } # An acceptance-rejection sampling procedure for random variates in the family # GAM(shape=alpha,rate=1) accept.reject.rgamma1 \u0026lt;- function(n, alpha) { a \u0026lt;- floor(alpha) rate \u0026lt;- a/alpha q \u0026lt;- (alpha/exp(1))^(a - alpha) ys \u0026lt;- vector(length = n) for (i in 1:n) { repeat { y \u0026lt;- sum(rexp(a, rate)) # draw candidate if (runif(1) \u0026lt;= q * y^(alpha - a) * exp(y * a/alpha - y)) { ys[i] \u0026lt;- y break } } } ys } We sample from $\\mathrm{Gamma}(2.5,1)$ with the the acceptance-rejection method with:\nalpha \u0026lt;- 2.5 m \u0026lt;- 10000 accept.reject.samp \u0026lt;- accept.reject.rgamma1(m, alpha) Metropolis-Hastings algorithm Here is our implementation of the Metropolis-Hastings algorithm:\n# A sampling procedure for random variates in the family # GAM(shape=alpha,rate=1) using Metropolis-Hastings algorithm metro.hast.rgamma1 \u0026lt;- function(n, alpha, burn = 0) { a \u0026lt;- floor(alpha) rate \u0026lt;- a/alpha # density for random variates in the family GAM(shape=alpha,rate=1) f \u0026lt;- function(x) { dgamma(x, shape = alpha, rate = 1) } g \u0026lt;- function(x) { dgamma(x, shape = a, rate = rate) } m \u0026lt;- n + burn ys \u0026lt;- vector(length = m) ys[1] \u0026lt;- sum(rexp(a, rate)) for (i in 2:m) { v \u0026lt;- sum(rexp(a, rate)) # draw from g u \u0026lt;- ys[i - 1] R \u0026lt;- f(v) * g(u)/(f(u) * g(v)) if (runif(1) \u0026lt;= R) { ys[i] \u0026lt;- v } else { ys[i] \u0026lt;- u } } ys[(burn + 1):m] } We sample from the Metro-Hastings algorithm with the following code:\nmetro.hast.samp \u0026lt;- metro.hast.rgamma1(m, alpha) Part (b) Check on mixing and convergence using plots. Run multiple chain and compute the Gelman-Rubin statistics. You may pick any reasonable burn-in.\nWe plot the histograms with:\npar(mfrow = c(1, 2)) hist(accept.reject.samp, freq = F, breaks = 50, main = \u0026#34;acceptance-rejection\u0026#34;) lines(seq(0.01, 15, by = 0.01), dgamma1(seq(0.01, 15, by = 0.01), alpha), col = \u0026#34;blue\u0026#34;, lwd = 2) hist(metro.hast.samp, freq = F, breaks = 50, main = \u0026#34;metropolis-hastings\u0026#34;) lines(seq(0.01, 15, by = 0.01), dgamma1(seq(0.01, 15, by = 0.01), alpha), col = \u0026#34;blue\u0026#34;, lwd = 2) Both samplers seem to be compatible with the density.\nWe plot the \\emph{sample path} of the Metropolis-Hastings and acceptance-rejection samplers with:\npar(mfrow = c(1, 2)) plot(metro.hast.samp, pch = \u0026#34;\u0026#34;, xlab = \u0026#34;t\u0026#34;, ylab = \u0026#34;Y\u0026#34;, main = \u0026#34;metropolis-hastings\u0026#34;) plot(accept.reject.samp, pch = \u0026#34;\u0026#34;, xlab = \u0026#34;t\u0026#34;, ylab = \u0026#34;Y\u0026#34;, main = \u0026#34;acceptance-rejection\u0026#34;) Both of these look good, as neither remain at or near the same value for many iterations. They also both quickly move away from their initial values.\nWe plot the ACFs with:\npar(mfrow = c(1, 2)) acf(metro.hast.samp) acf(accept.reject.samp) Both samplers seem to have very little autocorrelation. If an uncorrelated sample is extremely important, to be safe, taking every other sample point would probably be sufficient.\nWe implement the Gelman-Rubin statistic with:\n# samps: should be an L x J matrix, where L is the length of the samples and J # is the number of samples (independent chains). gelman.rubin \u0026lt;- function(samps) { L \u0026lt;- nrow(samps) J \u0026lt;- ncol(samps) x.bar \u0026lt;- apply(samps, 2, mean) B \u0026lt;- var(x.bar) * L W \u0026lt;- mean(apply(samps, 2, var)) ((L - 1)/L * W + B/L)/W } Next, we compute Gelman-Rubin statistics on the computed independence chains.\nchains \u0026lt;- 1000 samps \u0026lt;- matrix(nrow = m, ncol = chains) for (i in 1:chains) { samps[, i] \u0026lt;- metro.hast.rgamma1(m, alpha, burn = 1000) } gelman.rubin.stat \u0026lt;- gelman.rubin(samps) print(gelman.rubin.stat) ## [1] 1.000007 $$ R = 1.0000065. $$$$ \\sqrt{R} = 1.0000033, $$ and thus are satisfied with our burn-in choice and chain length.\nPart (c) Estimate $E(Y^2)$ using the generated chain. Compare with the estimate you get with acceptance-rejection sampling (Exam 1).\n$$ E(Y^2) = \\frac{\\Gamma(2+\\alpha)}{\\Gamma(\\alpha)} = \\frac{\\Gamma(4.5)}{\\Gamma(2.5)} = 8.75. $$We estimate $E(Y^2)$ using the acceptance-rejection and Metropolis-Hastings by taking the square of each element in the samples they generated and then taking the mean:\ntab \u0026lt;- matrix(nrow = 2, ncol = 1) rownames(tab) \u0026lt;- c(\u0026#34;acceptance-rejection\u0026#34;, \u0026#34;metropolis-hastings\u0026#34;) colnames(tab) \u0026lt;- c(\u0026#34;mean\u0026#34;) tab[1] \u0026lt;- c(mean(accept.reject.samp^2)) tab[2] \u0026lt;- c(mean(metro.hast.samp^2)) knitr::kable(data.frame(tab)) mean acceptance-rejection 8.879713 metropolis-hastings 8.747732 Both are quite close to the true value of $8.75$. Problem 2 (Problem 7.1) Rework the textbook example. Consider the mixture normal $\\delta N(7,0.5^2) + (1-\\delta) N(10,0.5^2)$.\nPart (a) Simulate $200$ realizations from the mixture distribution with $\\delta = 0.7$. Draw a histogram of these data.\nWe implement the density and sampler for the mixture distribution with:\ndmix \u0026lt;- function(x, delta) { delta * dnorm(x, 7, 0.5) + (1 - delta) * dnorm(x, 10, 0.5) } rmix \u0026lt;- function(n, delta) { xs \u0026lt;- vector(length = n) for (i in 1:n) { xs[i] \u0026lt;- ifelse(runif(1) \u0026lt; delta, rnorm(1, 7, 0.5), rnorm(1, 10, 0.5)) } xs } We generate a sample and plot its histogram with:\nn \u0026lt;- 200 delta \u0026lt;- 0.7 data \u0026lt;- rmix(n, delta) hist(data, freq = F) Part (b) Now assume $\\delta$ is unknown. Implement independence chain MCMC procedure to simulate from the posterior distribution of $\\delta$, using your data from part (a).\nlmix \u0026lt;- Vectorize(function(delta, xs) { if (delta \u0026lt; 0 || delta \u0026gt; 1) { return(0) } p \u0026lt;- 1 for (x in xs) { p \u0026lt;- p * dmix(x, delta) } p }, \u0026#34;delta\u0026#34;) logmix \u0026lt;- Vectorize(function(delta, xs) { if (delta \u0026lt; 0 || delta \u0026gt; 1) { return(-Inf) } logp \u0026lt;- 0 for (x in xs) { logp \u0026lt;- logp + log(dmix(x, delta)) } logp }, \u0026#34;delta\u0026#34;) $$ p(\\delta|\\vec{x}) \\propto p(\\delta) \\mathrm{lmix}(\\delta|\\vec{x}). $$$$ R = \\frac{f(\\delta^{*}) g(\\delta^{(t)})}{f(\\delta^{(t)})g(\\delta^{*})} = \\frac{p(\\delta^{*}|\\vec{x}) p(\\delta^{(t)})}{p(\\delta^{(t)}|\\vec{x}) p(\\delta^{*})} $$$$ R = \\frac{p(\\delta^{*}) \\mathrm{lmix}(\\delta^{*}|\\vec{x}) p(\\delta^{(t)})}{p(\\delta^{(t)}) \\mathrm{lmix}(\\delta^{(t)}|\\vec{x}) p(\\delta^{*})} = \\frac{\\mathrm{lmix}(\\delta^{*}|\\vec{x})}{\\mathrm{lmix}(\\delta^{(t)}|\\vec{x})}. $$Numerical imprecision Suppose we have a data type $T$ that models real numbers. Since computers are physical, $T$ can only represent a finite set of numbers.\n$$ \\mathrm{lmix} \\colon \\mathbb{R} \\times 2^{\\mathbb{R}} \\mapsto \\mathbb{R}, $$$$ \\mathrm{lmix} \\colon T \\times 2^T \\mapsto T, $$ then if the true value of the likelihood function applied to a sufficiently large sample is some value $p \\in (0,\\epsilon)$ where $\\epsilon$ is the smallest representable positive number of type $T$, the best we can do is round $p$ to $0$ or $\\epsilon$. As a consequence, the likelihood function evaluates to $0$ on any sufficiently large sample size.\n$$ \\mathrm{logmix} \\colon T \\times 2^T \\mapsto T $$ then, for instance, $\\log_2 \\epsilon = -K$ where $-K$ is very likely to be at least approximately representatable by $T$, and much smaller values as well. We cannot map many of these log-likelihoods back to a likelihood, but as long as we only need to work with log-likelihoods, this is not a problem.\nWith the above in mind, we replace the likelihood function with the log-likelihood function to significantly increase the space of samples we can work with.\ndelta.estimator.ic \u0026lt;- function(n, data, delta0 = runif(1), burn = 0) { m \u0026lt;- n + burn deltas \u0026lt;- vector(length = m) deltas[1] \u0026lt;- delta0 for (i in 2:m) { delta \u0026lt;- runif(1) # draw candidate from prior delta.old \u0026lt;- deltas[i - 1] log.R \u0026lt;- logmix(delta, data) - logmix(delta.old, data) if (log(runif(1)) \u0026lt;= log.R) { deltas[i] \u0026lt;- delta } else { deltas[i] \u0026lt;- delta.old } } deltas[(burn + 1):m] } Part (c) Implement a random walk chain with $\\delta^* = \\delta^{(t)} + \\epsilon_t$ with $\\epsilon \\sim \\mathrm{Uniform}(-1,1)$.\n$$ \\epsilon_{t+1} \\sim f(\\delta^* - \\delta^{(t)}) $$ where $f$ is the density of $\\mathrm{Uniform}(-1,1)$.\ndelta.estimator.rw \u0026lt;- function(n, data, delta0 = runif(1), burn = 0) { m \u0026lt;- n + burn deltas \u0026lt;- vector(length = m) deltas[1] \u0026lt;- delta0 for (i in 2:m) { delta.old \u0026lt;- deltas[i - 1] delta \u0026lt;- delta.old + runif(1, -1, 1) log.R \u0026lt;- logmix(delta, data) - logmix(delta.old, data) if (log(runif(1)) \u0026lt;= log.R) { deltas[i] \u0026lt;- delta } else { deltas[i] \u0026lt;- delta.old } } deltas[(burn + 1):m] } Part (d) Reparameterize the problem letting $U = \\log\\left(\\delta/(1-\\delta)\\right)$ and $U^* = u(t) + \\epsilon_t$. Implement a random walk chain with $U$ as in Equation (7.8) page 208.\nlogit \u0026lt;- function(delta) { log(delta/(1 - delta)) } logit.inv \u0026lt;- function(u) { exp(u)/(1 + exp(u)) } logit.inv.J \u0026lt;- function(u) { exp(u)/(1 + exp(u))^2 } delta.estimator.u.rw \u0026lt;- function(n, data, delta0 = runif(1), burn = 0) { m \u0026lt;- n + burn u \u0026lt;- vector(length = m) u[1] \u0026lt;- logit(delta0) for (i in 2:m) { u.old \u0026lt;- u[i - 1] u.star \u0026lt;- u.old + runif(1, -1, 1) R \u0026lt;- lmix(logit.inv(u.star), data) * logit.inv.J(u.star)/(lmix(logit.inv(u.old), data) * logit.inv.J(u.old)) if (runif(1) \u0026lt;= R) { u[i] \u0026lt;- u.star } else { u[i] \u0026lt;- u.old } } logit.inv(u[(burn + 1):m]) } Part (e) Compare the estimates and convergence behavior of three algorithms.\nWe do not do a burn-in, since we are interested in seeing how quickly the three methods converge. We only plot chains of length $1000$.\nWe generate the data sets with:\nchain \u0026lt;- 1000 burn \u0026lt;- 0 deltas.ic \u0026lt;- delta.estimator.ic(chain, data, burn = burn) deltas.rw \u0026lt;- delta.estimator.rw(chain, data, burn = burn) deltas.u.rw \u0026lt;- delta.estimator.u.rw(chain, data, burn = burn) tab \u0026lt;- matrix(nrow = 3, ncol = 1) rownames(tab) \u0026lt;- c(\u0026#34;independence chain\u0026#34;, \u0026#34;random walk\u0026#34;, \u0026#34;reparameterized random walk\u0026#34;) colnames(tab) \u0026lt;- c(\u0026#34;mu\u0026#34;) tab[1, ] \u0026lt;- mean(deltas.ic) tab[2, ] \u0026lt;- mean(deltas.rw) tab[3, ] \u0026lt;- mean(deltas.u.rw) knitr::kable(data.frame(tab)) $\\mu$ independence chain 0.6886690 random walk 0.6935625 reparameterized random walk 0.6854366 As the table of estimations shows, all three methods provide a good estimate of $\\delta$. Next, we consider their convergence and mixing behavior.\nWe plot the histograms with:\npar(mfrow = c(1, 3)) hist(deltas.ic, freq = F, breaks = 50, main = \u0026#34;independence chain\u0026#34;) hist(deltas.rw, freq = F, breaks = 50, main = \u0026#34;random walk\u0026#34;) hist(deltas.u.rw, freq = F, breaks = 50, main = \u0026#34;reparameterized random walk\u0026#34;) The reparameterized random walk metropolis has a histogram that is most compatible with normality, i.e., characteristic bell curve with a mode at $\\delta = 0.7$. That said, all three histograms arguably satisfy normality with approximately the same mean at $\\delta = 0.7$.\nWe plot the sample paths with:\npar(mfrow = c(1, 3)) plot(deltas.ic, pch = \u0026#34;\u0026#34;, type = \u0026#34;l\u0026#34;, xlab = \u0026#34;t\u0026#34;, ylab = \u0026#34;delta\u0026#34;, main = \u0026#34;independence chain\u0026#34;) plot(deltas.rw, pch = \u0026#34;\u0026#34;, type = \u0026#34;l\u0026#34;, xlab = \u0026#34;t\u0026#34;, ylab = \u0026#34;delta\u0026#34;, main = \u0026#34;random walk\u0026#34;) plot(deltas.u.rw, pch = \u0026#34;\u0026#34;, type = \u0026#34;l\u0026#34;, xlab = \u0026#34;t\u0026#34;, ylab = \u0026#34;delta\u0026#34;, main = \u0026#34;reparameterized random walk\u0026#34;) We see that the random walk demonstrates relatively poor mixing. It has a high rejection rate (stays at the same level for long periods of time), causing it to explore the support of the likelihood slowly.\nThe sample path of the indepedence chain also can be said to demonstrate poor mixing.\nThe reparameterized random walk exihibits good mixing, vigorously jiggling around the true value.\nWe plot the ACFs with:\npar(mfrow = c(1, 3)) acf(deltas.ic, main = \u0026#34;independence chain\u0026#34;) acf(deltas.rw, main = \u0026#34;random walk\u0026#34;) acf(deltas.u.rw, main = \u0026#34;reparameterized random walk\u0026#34;) They all decay quickly, but in order of increasing autocorrelation: the reparameterized random walk, the independence chain, and the random walk.\nIn particular, the reparameterized random walk shows autocorrelation that decays quite rapidly with respect to lag time.\nProblem 3 Consider an i.i.d. sample $X_1,\\ldots,X_n$ from $N(\\mu,\\sigma^2)$. Consider the Bayesian analysis to estimate $\\mu$ and $\\tau = (\\sigma^2)^{-1}$. We put prior $\\mu \\sim N(m,p^{-1})$ and $\\tau \\sim \\mathrm{Gamma}(a,b)$.\nPart (a) Write out the posterior distribution of $(\\mu,\\tau)|\\vec{x}$. You may ignore the normalizing constant.\n$$ \\pi(\\mu,\\tau|\\vec{x}) = f(\\vec{x}|\\tau,\\mu)f(\\tau)f(\\mu) / Z $$$$ \\pi(\\mu,\\tau|\\vec{x}) \\propto L(\\tau,\\mu|\\vec{x})f(\\tau)f(\\mu). $$$$ L(\\mu,\\tau|\\vec{x}) = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left\\{-\\frac{1}{2 \\sigma^2}(x_i-\\mu)^2\\right\\} $$$$ L(\\mu,\\tau|\\vec{x}) = \\left(2 \\pi \\sigma^2\\right)^{-n/2} \\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(x_i-\\mu)^2\\right\\}. $$$$ L(\\mu,\\tau|\\vec{x}) \\propto \\tau^{n/2} \\exp\\left\\{-\\frac{\\tau}{2}\\sum_{i=1}^{n}(x_i-\\mu)^2\\right\\}. $$$$ \\pi(\\mu,\\tau|\\vec{x}) \\propto \\tau^{n/2+a-1} \\exp\\left\\{-\\frac{\\tau}{2}\\sum_{i=1}^{n}(x_i-\\mu)^2-\\frac{p}{2}(\\mu - m)^2 - b \\tau\\right\\}. $$ Part (b) Show the posterior conditional distribution of $\\mu|(\\tau,\\vec{x})$ is $$ N\\left(\\frac{n \\tau \\bar{x} + p m}{ n \\tau + p}, \\frac{1}{n \\tau + p}\\right) $$ and the posterior conditional distribution of $\\tau|(\\mu,\\vec{x})$ is $$ \\mathrm{GAM}\\!\\left(a+n/2,b+n/2[s^2+(u -\\bar{x})^2]\\right). $$ Distribution of $\\mu|(\\tau,\\vec{x})$ $$ \\pi(\\mu | \\tau,\\vec{x}) = \\frac{\\pi(\\mu,\\tau|\\vec{x})}{\\pi(\\tau|\\vec{x})} $$$$ \\pi(\\tau|\\vec{x}) = \\int_{-\\infty}^{\\infty} \\pi(\\mu,\\tau|\\vec{x}) d\\mu. $$$$ \\pi(\\mu | \\tau,\\vec{x}) \\propto \\pi(\\mu,\\tau|\\vec{x}). $$$$ \\pi(\\mu | \\tau,\\vec{x}) \\propto \\exp\\left\\{-\\frac{\\tau}{2}\\sum_{i=1}^{n}(x_i-\\mu)^2\\right\\} \\exp\\left(-\\frac{p}{2}(\\mu - m)^2\\right). $$$$ \\pi(\\mu | \\tau,\\vec{x}) = \\exp\\left\\{-\\frac{1}{2 k_1}\\left(\\mu - k_2\\right)^2\\right\\} $$ with a mean $k_2$ and variance $k_1$.\n$$ \\begin{align*} \\pi(\\mu | \\tau,\\vec{x}) \u0026\\propto \\exp\\left\\{-\\frac{\\tau}{2}\\left[\\sum x_i^2 - 2 \\mu \\sum x_i + n \\mu^2\\right] - \\frac{p}{2}\\left[\\mu^2 - 2\\mu m + m^2\\right]\\right\\}\\\\ \u0026\\propto \\exp\\left\\{-\\frac{1}{2}\\left[- 2 n \\tau \\bar{x}\\mu + n \\tau \\mu^2 + p \\mu^2 - 2 p m \\mu\\right]\\right\\}\\\\ \u0026\\propto \\exp\\left\\{-\\frac{1}{2}\\left[(n \\tau + p)\\mu^2 - (2 p m + 2 n \\tau \\bar{x})\\mu\\right]\\right\\}\\\\ \u0026\\propto \\exp\\left\\{-\\frac{n \\tau + p}{2}\\left[\\mu^2 - \\frac{2(p m + n \\tau \\bar{x})}{n \\tau + p}\\mu\\right]\\right\\}. \\end{align*} $$$$ \\begin{align*} \\pi(\\mu | \\tau,\\vec{x}) \u0026\\propto \\exp\\left\\{-\\frac{n \\tau + p}{2}\\left[\\mu - \\frac{p m + n \\tau \\bar{x}}{n \\tau + p}\\right]^2 - \\left[\\frac{p m + n \\tau \\bar{x}}{n \\tau + p}\\right]^2\\right\\}\\\\ \u0026\\propto \\exp\\left\\{-\\frac{n \\tau + p}{2}\\left[\\mu - \\frac{p m + n \\tau \\bar{x}}{n \\tau + p}\\right]^2\\right\\}. \\end{align*} $$$$ \\frac{p m + n \\tau \\bar{x}}{n \\tau + p} $$$$ \\frac{1}{n\\tau + p}. $$Distribution of $\\tau|(\\mu,\\vec{x})$ $$ \\pi(\\tau | \\mu,\\vec{x}) = \\frac{\\pi(\\mu,\\tau|\\vec{x})}{\\pi(\\mu|\\vec{x})} $$$$ \\pi(\\mu|\\vec{x}) = \\int_{-\\infty}^{\\infty} \\pi(\\mu,\\tau|\\vec{x}) d\\tau. $$$$ \\pi(\\tau | \\mu,\\vec{x}) \\propto \\pi(\\mu,\\tau|\\vec{x}). $$$$ \\pi(\\tau | \\mu,\\vec{x}) \\propto \\tau^{n/2+a-1} \\exp\\left\\{-\\frac{\\tau}{2}\\sum_{i=1}^{n}(x_i-\\mu)^2 - b \\tau \\right\\}. $$$$ \\tau^{\\alpha-1}\\exp(-\\beta \\tau). $$ So, we rewrite the above as \\begin{align} \\pi(\\tau | \\mu,\\vec{x}) \u0026amp;\\propto \\tau^{n/2+a-1} \\exp\\left{-\\frac{\\tau}{2}\\sum(x_i-\\mu)^2 - b \\tau \\right}\\ \u0026amp;\\propto \\tau^{n/2+a-1} \\exp\\left{-\\left(\\frac{1}{2}\\sum(x_i-\\mu)^2 + b\\right) \\tau \\right}. \\end{align} Thus, we see that $\\alpha = n/2+a$ and $\\beta = b + \\frac{1}{2}\\sum(x_i-\\mu)^2$. The $\\beta$ is not in the form requested, so we continue, focusing strictly on $\\beta$.\nWe may rewrite $\\sum(x_i-\\mu)^2$ as\n$$ \\begin{align*} \\sum(x_i-\\mu)^2 \u0026= \\sum(x_i- \\bar{x} + \\bar{x} - \\mu)^2\\\\ \u0026= \\sum(x_i- \\bar{x})^2 + \\sum(\\bar{x} - \\mu)^2 - 2 \\sum(x_i - \\bar{x})(\\bar{x} - \\mu)\\\\ \u0026= \\sum(x_i- \\bar{x})^2 + n(\\bar{x} - \\mu)^2 - 2 \\left(\\sum x_i - n \\bar{x}\\right)(\\bar{x} - \\mu). \\end{align*} $$$$ \\sum(x_i-\\mu)^2 = \\sum(x_i- \\bar{x})^2 + n(\\bar{x} - \\mu)^2. $$$$ \\sum(x_i-\\mu)^2 = n(s^2 + (\\mu-\\bar{x})^2), $$$$ \\mathrm{Gamma}\\!\\left(n/2+a,b + n(s^2 + (\\mu-\\bar{x})^2)/2\\right). $$ Part (c) First, generate some ``observed\u0026rsquo;\u0026rsquo; sample data using $x = rnorm(200,mu=5,sigma=2)$. Hand-code Gibbs Sampler algorithm to sample $(\\mu,\\tau)$ from the posterior using $x$. You make take prior parameters $a = 0.0001; b = 0.0001; p = 0.0001; m = 0$. Use the estimated posterior mean and compare your estimates with the true parameters $\\mu = 5$ and $\\tau = 0.25$.\nWe generate the sample with:\nx \u0026lt;- rnorm(200, mean = 5, sd = 2) We implement the Gibbs sampling with the function:\nmu.tau.gibbs \u0026lt;- function(n, x, burn = 1000, theta0 = NULL, p = 1e-04, m = 0, a = 1e-04, b = 1e-04) { x.mu \u0026lt;- mean(x) x.s2 \u0026lt;- var(x) x.n \u0026lt;- length(x) rmu \u0026lt;- function(tau) { mean \u0026lt;- (x.n * tau * x.mu + p * m)/(x.n * tau + p) var \u0026lt;- 1/(x.n * tau + p) rnorm(1, mean = mean, sd = sqrt(var)) } rtau \u0026lt;- function(mu) { rgamma(1, shape = a + x.n/2, rate = b + x.n * (x.s2 + (mu - x.mu)^2)/2) } prior \u0026lt;- function() { c(rnorm(1, m, 1/p), rgamma(1, a, b)) } N \u0026lt;- n + burn thetas \u0026lt;- matrix(nrow = N, ncol = 2) if (is.null(theta0)) { thetas[1, ] \u0026lt;- prior() } else { thetas[1, ] \u0026lt;- theta0 } for (i in 1:(N - 1)) { tau.new \u0026lt;- rtau(thetas[i, 1]) mu.new \u0026lt;- rmu(tau.new) thetas[i + 1, ] \u0026lt;- c(mu.new, tau.new) } thetas \u0026lt;- thetas[(burn + 1):N, ] mu.est \u0026lt;- mean(thetas[, 1]) tau.est \u0026lt;- mean(thetas[, 2]) sigma.est \u0026lt;- sqrt(1/tau.est) list(theta.dist = thetas, mu.est = mu.est, tau.est = tau.est, sigma.est = sigma.est) } We use the Gibbs sampler to estimate $(\\mu,\\tau)$ with:\n# set up hyper-parameters a \u0026lt;- 1e-04 b \u0026lt;- 1e-04 m \u0026lt;- 0 p \u0026lt;- 1e-04 res \u0026lt;- mu.tau.gibbs(1e+05, x, burn = 10000, p = p, a = a, m = m, b = b) mu.est \u0026lt;- round(as.numeric(res$mu.est), digits = 4) tau.est \u0026lt;- round(as.numeric(res$tau.est), digits = 4) var.est \u0026lt;- round(1/tau.est, digits = 4) c(mu.est, tau.est) ## [1] 5.0791 0.2236 We estimate $(\\mu,\\tau)$ to be $(5.0791, 0.2236)\u0026rsquo;$. Therefore, we estimate that the data is being sampled from the normal distribution \\begin{equation} X_i \\sim N(\\mu=5.0791,\\sigma^2=4.4723). \\end{equation}\nAdditional analysis Out of curiosity, we decided to plot the marginals of the sample superimposed with their respective conditional densities with:\nx.mu \u0026lt;- mean(x) x.n \u0026lt;- length(x) x.s2 \u0026lt;- var(x) mu.dist \u0026lt;- res$theta.dist[, 1] tau.dist \u0026lt;- res$theta.dist[, 2] hist(mu.dist, freq = F, breaks = 50, main = \u0026#34;marginal of mu\u0026#34;, xlab = \u0026#34;mu\u0026#34;) lines(seq(4, 6, by = 0.01), dnorm(seq(4, 6, by = 0.01), mean = (x.n * tau.est * x.mu)/(x.n * tau.est + p), sd = sqrt(1/(x.n * tau.est + p)))) hist(tau.dist, freq = F, breaks = 50, main = \u0026#34;marginal of tau\u0026#34;, xlab = \u0026#34;tau\u0026#34;) lines(seq(0.15, 0.4, by = 0.01), dgamma(seq(0.15, 0.4, by = 0.01), shape = a + x.n/2, rate = b + x.n * (x.s2 + (mu.est - x.mu)^2)/2)) ",
        "summary": "This problem set covers sampling from a Gamma distribution using Metropolis-Hastings and acceptance-rejection methods.",
        "tags": ["statistics","R","computation","statistical inference","monte carlo simulation"],
        "section": "probsets"
      },{
        "title": "statistical-inference",
        "link": "http://localhost:1313/tags/statistical-inference/",
        "date": "2021-10-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "symbolic",
        "link": "http://localhost:1313/tags/symbolic/",
        "date": "2021-10-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "time-series",
        "link": "http://localhost:1313/tags/time-series/",
        "date": "2021-10-30 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "rstatlab",
        "link": "http://localhost:1313/ghprojects/rstatlab/",
        "date": "2021-08-30 23:25:35 +0000 UTC",
        "content": "rstatlab No description available.\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nNo README available for this project.\n",
        "summary": "\u003ch1 id=\"rstatlab\"\u003erstatlab\u003c/h1\u003e\n\u003cp\u003eNo description available.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/rstatlab\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eNo README available for this project.\u003c/em\u003e\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "computational-statistics",
        "link": "http://localhost:1313/tags/computational-statistics/",
        "date": "2021-08-01 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "course",
        "link": "http://localhost:1313/tags/course/",
        "date": "2021-08-01 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "coursework",
        "link": "http://localhost:1313/tags/coursework/",
        "date": "2021-08-01 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "numerical-methods",
        "link": "http://localhost:1313/tags/numerical-methods/",
        "date": "2021-08-01 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "problem-sets",
        "link": "http://localhost:1313/probsets/",
        "date": "2021-08-01 00:00:00 +0000 UTC",
        "content": "",
        "summary": "Problem sets and solutions for various courses.",
        "tags": ["SIUe","coursework","university"],
        "section": "probsets"
      },{
        "title": "projects",
        "link": "http://localhost:1313/projects/",
        "date": "2021-08-01 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": ["SIUe","coursework","university"],
        "section": "projects"
      },{
        "title": "regression-analysis-siue-stat-482-probem-set-8",
        "link": "http://localhost:1313/probsets/stat482/problem_set_8/",
        "date": "2021-08-01 00:00:00 +0000 UTC",
        "content": "Problem 1 We are interested in modeling the relationship among the predictor variables for the body fat example. Specifically, we wish to model midarm circumference ($w$) as a function of triceps skinfold thickness ($x_1$) and thigh circumference ($x_2$). Refer to the data from Table 7.1. The data for $x_1$ is listed in the first column, $x_2$ is listed in the second column, and $w$ is listed in the third column. We are not interested in the body fat measurements, listed in the fourth column, for this problem.\nPart (a) Compute the correlation matrix for $w$, $x_1$, $x_2$.\n# drop the last column of data (original response variable in the experiment) exp8_1.data = read.csv(\u0026#39;TABLE0701.csv\u0026#39;)[,1:3] exp8_1.data.cor = cor(exp8_1.data) print(exp8_1.data.cor) ## triceps thigh midarm ## triceps 1.0000000 0.9238425 0.4577772 ## thigh 0.9238425 1.0000000 0.0846675 ## midarm 0.4577772 0.0846675 1.0000000 Part (b) Test for a marginal effect of $x_2$ on $w$ against a model which includes no other input variables. (Compute the test statistic and $p$-value.) Provide an interpretation of the result, stated in the context of the problem.\n$$ m_0 : w_i = \\beta_0 + \\epsilon_i $$$$ m_2 : w_i = \\beta_0 + \\beta_1 x_{2 i} + \\epsilon_i. $$names(exp8_1.data) = c(\u0026#34;x1\u0026#34;,\u0026#34;x2\u0026#34;,\u0026#34;w\u0026#34;) m0 = lm(w~1, data=exp8_1.data) m2 = lm(w~x2, data=exp8_1.data) print(anova(m0,m2)) ## Analysis of Variance Table ## ## Model 1: w ~ 1 ## Model 2: w ~ x2 ## Res.Df RSS Df Sum of Sq F Pr(\u0026gt;F) ## 1 19 252.73 ## 2 18 250.92 1 1.8117 0.13 0.7227 We see that $F_2 = .130$ with $p$-value $.723$.\nThis is a very large $p$-value, and so $x_2$ (thigh) is not adding much explanatary power compared to the model $m_0$ with no explanatary inputs. In other words, $x_2$ provides very little predictive power of $w$ (midarm).\nInterpretation The observed data is compatible with the reduced (no effects) model $m_0$. It is not necessary to add thigh measurement to the no effects model for predicting midarm measurment.\nPart (c) Test for a partial effect of $x_2$ on $w$ against a model which includes $x_1$. (Compute the test statistic and $p$-value.) Provide an interpretation of the result, stated in the context of the problem.\n$$ m_1 : w_i = \\beta_0 + \\beta_1 x_{i 1} + \\epsilon_i $$$$ m_{1 2} : w_i = \\beta_0 + \\beta_1 x_{i 1} + \\beta_1 x_{2 i} + \\epsilon_i. $$m1 = lm(w~x1, data=exp8_1.data) m12 = lm(w~x1+x2, data=exp8_1.data) print(anova(m1,m12)) ## Analysis of Variance Table ## ## Model 1: w ~ x1 ## Model 2: w ~ x1 + x2 ## Res.Df RSS Df Sum of Sq F Pr(\u0026gt;F) ## 1 18 199.769 ## 2 17 2.416 1 197.35 1388.6 \u0026lt; 2.2e-16 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 Part (d) Fit the regression model for $w$ which includes both $x_1$ and $x_2$.\nsummary(m12) ## ## Call: ## lm(formula = w ~ x1 + x2, data = exp8_1.data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.58200 -0.30625 0.02592 0.29526 0.56102 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 62.33083 1.23934 50.29 \u0026lt;2e-16 *** ## x1 1.88089 0.04498 41.82 \u0026lt;2e-16 *** ## x2 -1.60850 0.04316 -37.26 \u0026lt;2e-16 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 0.377 on 17 degrees of freedom ## Multiple R-squared: 0.9904,\tAdjusted R-squared: 0.9893 ## F-statistic: 880.7 on 2 and 17 DF, p-value: \u0026lt; 2.2e-16 $$ \\hat{w} = 62.331 + 1.881 x_1 - 1.608 x_2. $$plot(exp8_1.data$x1,exp8_1.data$x2) Part (e) What feature of multidimensional modeling is illustrated in this problem?\nAnswer: Multicollinearity.\nSpecifically, observe that $x_1$ and $x_2$ are strongly positively correlated, $r_{1 2} = 0.924$, but $x_1$ and $x_2$ have, respectively, a positive and negative partial effect on $w$. The combination of these partial effects and the correlation of $x_1$ and $x_2$ cancels out their partial effects on $w$.\nIf we look at the scatterplots of $x_1$ versus $w$ and $x_2$ vs $w$, they seem uncorrelated. However, the joint distribution of $x_1$ and $x_2$ are highly explanatory of $w$. Investigating relationships in higher dimensions requires higher level statistical methods, such as regression analysis, rather than two-dimensional methods and graphs.\n",
        "summary": "This problem set covers multicollinearity in regression analysis and the marginal and partial effects of predictor variables, among other topics.",
        "tags": ["statistics"],
        "section": "probsets"
      },{
        "title": "regression-analysis",
        "link": "http://localhost:1313/tags/regression-analysis/",
        "date": "2021-08-01 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "simulation",
        "link": "http://localhost:1313/tags/simulation/",
        "date": "2021-08-01 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "stat-482-regression-analysis-siue-fall-2022",
        "link": "http://localhost:1313/probsets/stat482/",
        "date": "2021-08-01 00:00:00 +0000 UTC",
        "content": "This is a problem set for STAT 482 - Regression Analysis at SIUe. These problem sets were given by Dr. Andrew Neath, a professor in the Department of Mathematics and Statistics at Southern Illinois University Edwardsville (SIUe) during the Fall 2022 semester. It covers topics in regression analysis.\n",
        "summary": "Problem sets and solutions for STAT 482 - Regression Analysis at SIUe.",
        "tags": ["statistics","regression-analysis","course","SIUe","statistics","data-science","inference"],
        "section": "probsets"
      },{
        "title": "stat-575-computational-statistics-siue-summer-2021",
        "link": "http://localhost:1313/probsets/stat575/",
        "date": "2021-08-01 00:00:00 +0000 UTC",
        "content": "These problem sets were given by Dr. Qiang Beidi, a professor in the Department of Mathematics and Statistics at Southern Illinois University Edwardsville (SIUe) during the Summer 2021 semester. She covered a range of topics in numerical methods, simulation, and statistical computing.\n",
        "summary": "Problem sets and solutions for STAT 575 - Computational Statistics at SIUe.",
        "tags": ["statistics","computational-statistics","numerical-methods","simulation","statistical-computing","SIUe","statistics","data-science","inference"],
        "section": "probsets"
      },{
        "title": "statistical-computing",
        "link": "http://localhost:1313/tags/statistical-computing/",
        "date": "2021-08-01 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "prob.4.2.comp.stats",
        "link": "http://localhost:1313/ghprojects/prob.4.2.comp.stats/",
        "date": "2021-07-25 08:49:08 +0000 UTC",
        "content": "prob.4.2.comp.stats No description available.\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nLanguages Used: R\nREADME Problem 4.2 - Computational Statistics ",
        "summary": "\u003ch1 id=\"prob42compstats\"\u003eprob.4.2.comp.stats\u003c/h1\u003e\n\u003cp\u003eNo description available.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/prob.4.2.comp.stats\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: R\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003ch1 id=\"problem-42---computational-statistics\"\u003eProblem 4.2 - Computational Statistics\u003c/h1\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "computational-statistics-siue-stat-575-exam-1",
        "link": "http://localhost:1313/probsets/stat575/stat575-exam1/",
        "date": "2021-07-10 00:00:00 +0000 UTC",
        "content": "Problem 1 Part (1) (10 points) $$ f(x)  e^{-x^2/2}I(x \u003e 2). $$ Consider the proposed distribution $g(x) = 2 e^{2(x2)}I(x \u0026gt; 2)$.\nPart (a) Sample from $g$ using inverse-transform method.\nSolution $$ \\begin{align*} G(x) \u0026= P(X \\leq x)\\\\ \u0026= P(2+S \\leq x)\\\\ \u0026= P(S \\leq x-2)\\\\ \u0026= F_S(x-2)\\\\ \u0026= \u0026= I(x \u003e 2)(1 - \\exp(-2(x-2))). \\end{align*} $$ As a quick proof that $G$ is the cdf of $g$, note that $dG/dx = g$.\n$$ \\begin{align*} G(x) \u0026= \\int_{-\\infty}^{x} g(s) ds\\\\ \u0026= I(x \u003e 2) \\int_{2}^{x} 2 e^{2(s2)} ds\\\\ \u0026= I(x \u003e 2) e^4 \\int_{2}^{x} 2 e^{2 s} ds\\\\ \u0026= -I(x \u003e 2) e^4 \\int_{2}^{x} (-2) e^{2 s} ds\\\\ \u0026= -I(x \u003e 2) e^4 \\left(e^{-2 s}|_2^x\\right)\\\\ \u0026= -I(x \u003e 2) e^4 \\left(e^{-2 x}-e^{-4}\\right)\\\\ \u0026= I(x \u003e 2) (1 - e^4 e^{-2 x})\\\\ \u0026= I(x \u003e 2) (1 - e^{-2(x-2)}), \\end{align*} $$$$ \\begin{align*} u \u0026= G(x)\\\\ u \u0026= 1 - e^{-2(x-2)}\\\\ 1-u \u0026= e^{-2(x-2)}\\\\ \\log(1-u) \u0026= -2(x-2)\\\\ -\\frac{1}{2}\\log(1-u) \u0026= x-2, \\end{align*} $$$$ x = -\\frac{1}{2}\\log(1-u) + 2 $$$$ X = -\\frac{1}{2}\\log(1-U) + 2 $$ is a random variable whose density is $g$.\nPart (b) Use accept-reject algorithm to generate a sample of $10000$ from f. Choose a $c$ so that $f(y)/[c g(y)]  1$. Verify the generated sample via a plot of the true normalized density, and a histogram of the generated values.\nSolution $$ \\frac{k(y)}{g(y)} \\leq 1 $$$$ y^* = \\argmax_y k(y)/g(y) $$ and then let $c = k(y^)/g(y^)$.\n$$ h(y) = k(y)/g(y) = \\frac{e^{-y^2/2}}{2e^{-2(y-2)}}. $$$$ \\log h(y) = \\log \\frac{e^{-y^2/2}}{2e^{-2(y-2)}} = -\\frac{1}{2}y^2 + 2(y-2). $$$$ \\begin{align*} c = h(2) \u0026= \\frac{k(2)}{g(2)}\\\\ \u0026= \\frac{1}{2e^2}. \\end{align*} $$$$ u \\leq \\frac{k(y)}{g(y)} = e^{-(y-2)^2/2}. $$Here is the code that implements our sampling method for $f$ using acceptance-rejection sampling:\n# the proposed density we can easily sample from g \u0026lt;- function(y) { 2*exp(-2*(y-2)) } # inverse transform method for sampling from g rg \u0026lt;- function(n) { -0.5*log(1-runif(n))+2 } rf \u0026lt;- function(n) { data \u0026lt;- vector(length=n) for (i in 1:n) { repeat { y \u0026lt;- rg(1) u \u0026lt;- runif(1) if (runif(1) \u0026lt;= exp(-(y-2)^2/2)) { data[i] \u0026lt;- y break } } } data } k \u0026lt;- function(y) { exp(-y^2/2) } f \u0026lt;- function(y) { # normalizing constant Z \u0026lt;- 17.5358 Z*k(y) } To verify the sampling method, we drawn $n=10000$ samples from $f$ and plot its histogram along with a plot of its density function $f$.\ndata \u0026lt;- rf(10000) ys \u0026lt;- seq(2,10,by=.1) hist(data,freq=F,breaks=50,main=\u0026#34;f\u0026#34;) lines(x=ys,f(ys),col=\u0026#34;red\u0026#34;) The histogram seems compatible with the pdf $f$.\nProblem 2 (5 points) Implement your accept-reject algorithm to get a sample of 10000 from $\\mathrm{Gamma}(2.5, 1)$. Verify that your method works via a plot of the true normalized density, and a histogram of the generated values.\nSolution This is not the approach you were looking for, but on the test I did poorly on this section.\nBe that as it may, here is essentially my answer on the test, except that the solution is so slow that I decreased $c$ so that, at the extreme tail of the distribution, $f(y) / c g(y) \u0026gt; 1$.\nalpha \u0026lt;- 2.5 n \u0026lt;- 10000 c \u0026lt;- 10 a \u0026lt;- floor(alpha) b \u0026lt;- a / alpha ys \u0026lt;- vector(length=n) for (i in 1:n) { repeat { y \u0026lt;- rgamma(n=1,shape=a,scale=b) u \u0026lt;- runif(1) P \u0026lt;- dgamma(y,shape=alpha,scale=1) / (c*dgamma(y,shape=a,scale=b)) if (u \u0026lt; P) { ys[i] \u0026lt;- y break } } } hist(ys,freq=F,breaks=50) lines(x=seq(.01,10,by=.05),y=dgamma(seq(.01,10,by=.05),shape=alpha,scale=1),col=\u0026#34;red\u0026#34;) Problem 3 (30 points) Considers $197$ animals randomly divided into four categories (four phenotypes) as follows: $X = (x1, x2, x3, x4)^T$ with cell probabilities $(1/2 + /4,(1  )/4,(1  )/4, /4)^T$. We observe $X = (125, 18, 20, 34)^T$.\nPart (a) Hand code your algorithm using Newton-Ralphson to find the maximum likelihood estimator of $$ directly from the observed likelihood. Compare your result with what you get using the built-in $\\mathrm{optim}()$ function in R.\nSolution $$ \\ell(\\theta | \\vec{x}) = x_1 \\log\\left(\\frac{1}{2}+\\frac{\\theta}{4}\\right) + x_2 \\log\\left(\\frac{1-\\theta}{4}\\right) + x_3 \\log\\left(\\frac{1-\\theta}{4}\\right) + x_4 \\log\\left(\\frac{\\theta}{4}\\right). $$$$ \\theta^{(t+1)} = \\theta^{(t)} - \\frac{d \\ell / d \\theta}{d^2 \\ell / d \\theta^2} $$$$ \\frac{d \\ell}{d \\theta} = \\frac{x_1}{\\theta+2} + \\frac{x_2}{\\theta-1} + \\frac{x_3}{\\theta-1} + \\frac{x_4}{\\theta} $$$$ \\frac{d^2 \\ell}{d \\theta^2} = -\\frac{x_1}{(\\theta+2)^2} - \\frac{x_2}{(\\theta-1)^2} - \\frac{x_3}{(\\theta-1)^2} - \\frac{x_4}{\\theta^2}. $$Instead of taking the time to simplify this expression, we will just substitute these derivations into the updating equation in the following R code:\nl1 \u0026lt;- function(theta,x) { x[1]/(theta+2) + (x[2]+x[3])/(theta-1) + x[4]/theta } l2 \u0026lt;- function(theta,x) { -x[1]/(theta+2)^2 - (x[2]+x[3])/(theta-1)^2 - x[4]/theta^2 } theta_mle \u0026lt;- function(x, start = 0.5, eps = 1e-6) { i \u0026lt;- 0 theta0 \u0026lt;- start theta1 \u0026lt;- NULL repeat { theta1 \u0026lt;- theta0 - l1(theta0,x) / l2(theta0,x) if (abs(theta1-theta0) \u0026lt; eps) { break } theta0 \u0026lt;- theta1 i \u0026lt;- i + 1 } list(mle=theta1,iterations=i) } We invoke the updating equations on the given data to estimate $\\theta$ with the following R code:\n# observed data x \u0026lt;-c(125, 18, 20, 34) sol \u0026lt;- theta_mle(x=x, start=0.5, eps=1e-6) mle \u0026lt;- sol$mle mle_iterations \u0026lt;- sol$iterations We see that the MLE converges to a solution around $0.6268215$ after $3$. We compare this result with the built-in procedure, $\\rm{optim}$:\n# the function to maximize, the log-likelihood function loglike \u0026lt;- function(theta) { x[1]*log(0.5+theta/4) + x[2]*log(0.25*(1-theta)) + x[3]*log(0.25*(1-theta)) + x[4]*log(0.25*theta) } # since optim finds the value that minimizes the function, we provide it with # the negative of the log-likelihood. optim(0.5,function(theta) { -loglike(theta) },lower=0.1,upper=0.9,method=\u0026#34;L-BFGS-B\u0026#34;)$par ## [1] 0.626821 The value $\\mathrm{optim}$ found is approximately the same. It was fussy with explicitly providing upper and lower bounds. This warrants further investigation, but for another time.\nPart (b) Implement the E-M algorithm to find the the maximum likelihood estimator of $$ with the ``augmented\u0026rsquo;\u0026rsquo; data with missing information $Z = y_2$. Compare your result with part (a).\nSolution $$ \\vec{y} = (y_1, y_2, y_3, y_4, y_5)^T $$ with cell probabilities $(1/2, /4,(1  )/4,(1  )/4, /4)^T$.\n$$ f(\\vec{y}|\\theta) \\propto \\prod_{i=1}^{5} \\pi_i(\\theta)^{y_i} $$$$ \\vec{\\pi}(\\theta) = (1/2, /4,(1  )/4,(1  )/4, /4)^T. $$$$ \\log f(\\vec{y} | \\theta) = \\sum_{i=1}^{5} y_i \\log \\pi_i(\\theta) $$$$ \\log f(\\vec{y} | \\theta) = k(\\vec{y}) + y_2 \\log(\\theta) + y_3 \\log(1-\\theta) + y_4 \\log(1-\\theta) + y_5 \\log \\theta. $$E-step $$ Q(\\theta|\\theta^{(t)}) = E_{Z|\\vec{x},\\theta^{(t)}}(\\log f(\\vec{y}|\\theta)), $$$$ Q(\\theta|\\theta^{(t)})= E_{Z|\\vec{x},|\\theta^{(t)}}\\left(y_2 \\log(\\theta) + y_3 \\log(1-\\theta) + y_4 \\log(1-\\theta) + y_5 \\log \\theta\\right) $$$$ \\begin{split} Q(\\theta|\\theta^{(t)}) = E_{Z|\\vec{x},|\\theta^{(t)}}(y_2) \u0026 \\log(\\theta) + E_{Z|\\vec{x},|\\theta^{(t)}}(y_3) \\log(1-\\theta) +\\\\ \u0026 E_{Z|\\vec{x},|\\theta^{(t)}}(y_4) \\log(1-\\theta) + E_{Z|\\vec{x},|\\theta^{(t)}}(y_5) \\log \\theta. \\end{split} $$$$ E_{Z|\\vec{x}}(y_3) = x_2. $$$$ Z | (\\vec{x},\\theta^{(t)}) \\sim \\rm{BIN}(x_1, \\frac{\\theta^{(t)}}{2+\\theta^{(t)}}). $$$$ E_{Z|\\vec{x},|\\theta^{(t)}}(y_2) = \\frac{x_1 \\theta^{(t)}}{2+\\theta^{(t)}}. $$$$ Q(\\theta|\\theta^{(t)}) = \\frac{x_1 \\theta^{(t)}}{2+\\theta^{(t)}} \\log(\\theta) + x_2 \\log(1-\\theta) + x_3 \\log(1-\\theta) + x_4 \\log \\theta. $$M-step $$ \\theta^{(t+1)} = \\argmax_{\\theta} Q(\\theta|\\theta^{(t)}), $$$$ \\frac{d Q(\\theta|\\theta^{(t)})}{d \\theta}\\biggr|_{\\theta = \\theta^{(t+1)}} = 0. $$$$ \\frac{d Q}{d \\theta} = \\frac{125 \\theta^{(t)}}{2+\\theta^{(t)}} - \\frac{38}{1-\\theta} - \\frac{34}{\\theta} = 0 $$$$ \\theta^{(t+1)} = \\frac{159 \\theta^{(t)} + 68}{197 \\theta^{(t)} + 144}. $$$$ \\hat\\theta_{\\mathrm{EM}} = \\lim_n \\theta^{(t)}. $$We implement the EM algorithm in the following R code:\ntheta0 \u0026lt;- .5 theta1 \u0026lt;- NULL i \u0026lt;- 1 repeat { theta1 \u0026lt;- (159*theta0 + 68)/(197*theta0 + 144) cat(\u0026#34;theta[\u0026#34;,i,\u0026#34;] = \u0026#34;, theta1,\u0026#34;\\n\u0026#34;) if (abs(theta1-theta0) \u0026lt; 1e-6) { break } theta0 \u0026lt;- theta1 i \u0026lt;- i + 1 } ## theta[ 1 ] = 0.6082474 ## theta[ 2 ] = 0.6243211 ## theta[ 3 ] = 0.6264889 ## theta[ 4 ] = 0.6267773 ## theta[ 5 ] = 0.6268156 ## theta[ 6 ] = 0.6268207 ## theta[ 7 ] = 0.6268214 print(theta1) ## [1] 0.6268214 We see the standard MLE $\\hat\\theta_{\\rm{mle}}$ and $\\hat\\theta_{\\rm{EM}}$ both obtain the same solution up to $6$ decimal places when using the same starting value and stopping condition. However, $\\hat\\theta_{\\rm{EM}}$ required more iterations before convergence, which was expected given that the EM algorithm is of linear order while the MLE using Newton-raphson is of quadratic order. However, the EM algorithm does have the benefit of a less complex updating equation.\nPart (c) Find the standard error of the MLE using either a numerical calculation of the inverse of the observed fishers information, i.e $[l()]^{1}$, or using Louis Method.\nSolution We already have the second derivative of the log-likelihood, so we choose to use the observed Fisher information evaluated at $\\theta = \\theta_{\\rm{mle}}$.\nobs_fisher \u0026lt;- -l2(mle,x) var_mle \u0026lt;- 1 / obs_fisher sqrt(var_mle) ## [1] 0.05146735 We see that an estimate of standard error of the MLE is $\\mathrm{sd}(\\hat{\\theta}_{\\rm{mle}}) = 0.0514673$.\nProblem 4 (10 points ) Consider the density $f(x)  3e^{0.5(x+2)^2} + 7e^{0.5(x2)^2}$ (problems 6, Homework 1).\nPart (a) Compute the exact normalizing constant, both in closed form using $\\pi$ (pencil and paper), and also to 5 decimal places (by evaluating the exact version in R).\nSolution $$ f(x) \\propto \\ker(x) $$$$ \\rm{ker}(x) = 3 e^{-0.5(x+2)^2} + 7 e^{-0.5(x-2)^2} $$$$ \\int_{-\\infty}^{\\infty} \\frac{1}{C} \\ker(x) dx = 1. $$$$ C = \\int_{-\\infty}^{\\infty} 3 e^{-0.5(x+2)^2} dx + \\int_{-\\infty}^{\\infty} 7 e^{-0.5(x-2)^2} dx. $$$$ C = 3 \\sqrt{2 \\pi} \\int_{-\\infty}^{\\infty} \\frac{e^{-0.5(x+2)^2}}{\\sqrt{2 \\pi}} dx + 7 \\sqrt{2 \\pi} \\int_{-\\infty}^{\\infty} \\frac{e^{-0.5(x-2)^2}}{\\sqrt{2 \\pi}} dx $$$$ C = 3 \\sqrt{2 \\pi} \\int_{-\\infty}^{\\infty} \\phi(x+2) dx + 7 \\sqrt{2 \\pi} \\int_{-\\infty}^{\\infty} \\phi(x-2) dx. $$$$ C = 3 \\sqrt{2 \\pi} + 7 \\sqrt{2 \\pi} = 10 \\sqrt{2 \\pi} $$ is the normalizing constant, which is 25.06628 to $5$ decimal places.\nUsing R\u0026rsquo;s numerical integrator, we get the result:\nC \u0026lt;- 10*sqrt(2*pi) ker \u0026lt;- function(x) { 3*exp(-0.5*(x+2)^2) + 7*exp(-0.5*(x-2)^2) } res \u0026lt;- integrate(ker,lower = -Inf, upper = Inf) print(res) ## 25.06628 with absolute error \u0026lt; 4e-05 Part (b) Approximate this integral with a Simpsons rule to three decimal places. What is the effective range and number of subintervals required?\nSolution Simpson\u0026rsquo;s rule is implemented by the following R code. Note that we did not bother to optimize it.\n# simpson : numerical integrator applying simpson\u0026#39;s rule to n subintervals # over the range (a,b). # # arguments; # f : the function to integrate # a : the lower-bound # b : the upper-bound. (a,b) together discrete the range. # n : the number of subintervals to partition the range # # we evenly partition the range into n subintervals of size (b-a)/n # and apply simson\u0026#39;s rule to each subinterval. then, we accumulate these # values and return the result. simpson \u0026lt;- function(f, a, b, n) { h \u0026lt;- (b-a)/n s \u0026lt;- 0 x \u0026lt;- a for (i in 1:(n/2)) { s \u0026lt;- s + f(x) + 4 * f(x+h) + f(x+2*h) x \u0026lt;- x + 2*h } s*h/3 } To test effective range and subintervals, we decided to make a program that exhaustively searches for the minimum range and number of subintervals over a discrete set of points. In particular, we search for a range of the form $(-r,r)$ that is symmetric and an even $n$. It is not perfect, but it seems like a reasonable way to estimate these requirements.\nHere is the R code:\nR \u0026lt;- NULL N \u0026lt;- NULL found \u0026lt;- F for (r in 1:200) { for (n in 1:100) { res \u0026lt;- simpson(ker,-r/10,r/10,2*n) if (abs(res - C) \u0026lt; 0.001) { R \u0026lt;- r/10 N \u0026lt;- 2*n cat(\u0026#34;r = +-\u0026#34;, R, \u0026#34;, n = \u0026#34;, N, \u0026#34;, C = \u0026#34;, res, \u0026#34;\\n\u0026#34;) found \u0026lt;- T break } } if (found) { break } } ## r = +- 5.9 , n = 16 , C = 25.06603 The minimum range $(-r,r)$, $r \u0026gt; 0$, when divided into $n$ subintervals, that is the same as the true value $10 \\sqrt{2\\pi}$ to $3$ decimal places is given by $r = 5.9$ and $n = 16$.\n",
        "summary": "This exam covers accept-reject algorithms, the EM algorithm, and the MLE of a truncated normal distribution.",
        "tags": null,
        "section": "probsets"
      },{
        "title": "computational-statistics-siue-stat-575-exam-1",
        "link": "http://localhost:1313/probsets/stat575/stat575-exam2/",
        "date": "2021-07-10 00:00:00 +0000 UTC",
        "content": "Problem 1 $$ q(x) = \\frac{e^x}{e^{2x}+1}, x \\in (-\\infty,\\infty). $$Part (a) Find the Monte Carlo estimate of $\\sigma^2$ using acceptance-rejection sampling. Take the candidate distribution as the double exponential, i.e., $g(x) = \\exp(-|x|)$.\nSolution We are interested in sampling $X$ from a kernel $q$.\nq \u0026lt;- function(x) { exp(x)/(exp(2*x)+1) } Suppose $Y$ is the double exponential random variable with the kernel $g$.\ng \u0026lt;- function(x) { exp(-abs(x)) } Since the double exponential is symmetric about its mean $0$, we can simply sample $W \\sim \\mathrm{EXP}(\\lambda=1)$ and let $Y = -W$ with probability $0.5$ and $Y = W$ with probability $0.5$.\nry \u0026lt;- function(n) { ys \u0026lt;- numeric(n) ws \u0026lt;- rexp(n=n,rate=1) us \u0026lt;- runif(n) for (i in 1:n) { ys[i] \u0026lt;- ifelse(us[i] \u0026lt; 0.5,-ws[i],ws[i]) } ys } $$ \\begin{align*} c \u0026= \\max_x \\left\\{\\frac{q(x)}{g(x)}\\right\\}\\\\ \u0026= \\max_x \\left\\{\\frac{e^{x+|x|}}{e^{2x}+1}\\right\\}. \\end{align*} $$ We forgo a formal proof and point out that the denominator is always larger than the numerator, i.e., $q(x)/g(x) \u0026lt; 1$. However, as $x$ goes to $\\pm \\infty$, $q(x)/g(x)$ goes to $1$ and thus $c = 1$. We implement the acceptance-rejection sampler for $X$ with kernel $q$ with:\nrx \u0026lt;- function(n) { xs \u0026lt;- numeric(n) for (i in 1:n) { repeat { y \u0026lt;- ry(1) if (runif(1) \u0026lt; q(y)/g(y)) { xs[i] \u0026lt;- y break } } } xs } We estimate $E(X^2)$ by taking the square of a sample:\nx \u0026lt;- rx(10000) print(mean(x^2)) ## [1] 2.43841 Part (b) Find the normalizing constant of the pdf by integrating $q(x)$ over the support. Then derive the CDF of $X$.\nSolution $$ \\frac{1}{Z} \\int_{-\\infty}^{\\infty} q(x) dx = 1. $$$$ Z = 2 \\int_{1}^{\\infty} \\frac{1}{1+u^2} du. $$$$ Z = 2 (\\mathrm{arctan}(\\infty) - \\mathrm{arctan}(1)) $$$$ Z = 2 (2\\pi/4 - \\pi/4) = 2(\\pi/4) = \\pi/2. $$We verify with a numerical integrator:\nright_riemann_sum \u0026lt;- function(f, a, b, n) { h \u0026lt;- (b-a)/n h*sum(f(a + (1:n)*h)) } When we apply the numerical integrator to the kernel $q$ and subtract $\\pi/2$ we obtain a result that is approximately $0$, confirming our earlier calculation:\nright_riemann_sum(q,-10,10,1000) - pi/2 ## [1] -9.080289e-05 $$ f(x) = \\frac{2}{\\pi} \\frac{e^x}{e^{2x}+1}. $$$$ F(x) = \\int_{-\\infty}^{x} f(s) ds = \\frac{2}{\\pi} (\\mathrm{arctan}(e^x) - \\mathrm{arctan}(0)) $$$$ F(x) = \\frac{2}{\\pi} \\mathrm{arctan}(e^x). $$pdf \u0026lt;- function(x) { 2/pi * q(x) } cdf \u0026lt;- function(x) { 2/pi * arctan(exp(x)) } Part (c) Generate a sample of $X$ using inverse transform method and find the Monte Carlo estimate of $\\sigma^2$.\nSolution $$ \\begin{align*} p \u0026= \\frac{2}{\\pi} \\mathrm{arctan}(e^x)\\\\ \\frac{\\pi}{2} p \u0026= \\mathrm{arctan}(e^x)\\\\ \\tan\\left(\\frac{\\pi}{2} p\\right) \u0026= e^x\\\\ x \u0026= \\log\\left(\\tan\\left(\\frac{\\pi}{2} p\\right)\\right). \\end{align*} $$$$ X = \\log\\left(\\tan\\left(\\frac{\\pi}{2} U\\right)\\right) $$ where $U \\sim \\mathrm{UNIF}(0,1)$.\nrx.transform \u0026lt;- function(n) { us \u0026lt;- runif(n) log(tan(pi/2*us)) } We estimate $\\sigma^2$ with:\nx \u0026lt;- rx.transform(10000) print(mean(x^2)) ## [1] 2.508885 Part (d) Repeat the estimation using importance sampling with standardized weights.\nSolution #\u0026#39; importance sampling #\u0026#39; #\u0026#39; estimates E{h(X)} by taking n sample points from g and then taking a #\u0026#39; weighted mean using the standardized weights. rx.importance \u0026lt;- function(n,h) { w = function(x) { out \u0026lt;- q(x)/g(x) out/sum(out) } ys \u0026lt;- ry(n) sum(w(ys)*h(ys)) } We apply the procedure to $h(x) = x^2$ to estimate $E(h(X))$:\nprint(rx.importance(10000,function(x) { x^2} )) ## [1] 2.437009 Problem 2 $$ f(x|\\theta_1,\\theta_2) \\propto x^{-1.5} \\exp\\left\\{-\\theta_1 x - \\frac{\\theta_2}{x} + \\psi(\\theta_1,\\theta_2)\\right\\} $$ where $\\psi(\\theta_1,\\theta_2) = 2\\sqrt{\\theta_1\\theta_2} + \\log(2\\theta_2)$. Estimate $E(X)$ using MCMC. You may take the proposal distribution as a $\\mathrm{Gamma}(\\sqrt{\\theta_2/\\theta_1},1)$.\nSolution Here is our implementation of the Metropolis-Hastings algorithm:\n# A sampling procedure from the pdf f using Metropolis-Hastings algorithm rf \u0026lt;- function(n, theta1, theta2, burn=0) { g \u0026lt;- function(x) { dgamma(x,shape=sqrt(theta2/theta1),rate=1) } rg \u0026lt;- function(n) { rgamma(n,shape=sqrt(theta2/theta1),rate=1) } ker \u0026lt;- function(x) { x^(-1.5)*exp(-theta1*x-theta2/x) } m \u0026lt;- n + burn xs \u0026lt;- vector(length = m) xs[1] \u0026lt;- rg(1) for (i in 2:m) { v \u0026lt;- rg(1) u \u0026lt;- xs[i-1] R \u0026lt;- ker(v) * g(u) / (ker(u) * g(v)) if (runif(1) \u0026lt;= R) { xs[i] \u0026lt;- v } else { xs[i] \u0026lt;- u } } xs[(burn+1):m] } We apply the algorithm to $\\theta_1 = 5$ and $\\theta_2 = 3$:\nn \u0026lt;- 100000 theta1 \u0026lt;- 3 theta2 \u0026lt;- 5 xs \u0026lt;- rf(n,theta1,theta2,burn=20000) Now, we estimate $E(X)$ with:\nprint(mean(xs)) ## [1] 1.28597 We have deduced that the true mean is given by $\\mu = \\sqrt{\\theta_2/\\theta_1}$, and so we see the algorithm provides a reasonable estimation.\nWe would like to plot the histogram with the density superimposed on top of it. So, we implement the density function with:\nf.make \u0026lt;- function(theta1,theta2) { k \u0026lt;- function(x) { x^(-1.5) * exp(-theta1*x - theta2/x) } Z \u0026lt;- right_riemann_sum(k,0,20,10000) function(x) { k(x) / Z } } f \u0026lt;- f.make(theta1,theta2) hist(xs,breaks=200,freq=F) ps \u0026lt;- seq(0,10,by=.01) lines(x=ps,y=f(ps)) Problem 3 Consider the data on coal-mining disasters from 1851 to 1962 (coal.txt data on blackboard). The rate of accidents per year appears to decrease around 1900, so we consider a change-point model for these data. Let $X_j$ be the number of accidents in year $j$. $X_j \\sim \\mathrm{Poisson}(_1)$, $j = 1, \\ldots, $, and $X_j \\sim \\mathrm{Poisson}(_2)$, $j =  + 1, \\ldots, 112$. The change-point occurs after the $$-th year in the series. This model has parameters are $, _1, _2$. Below are three sets of priors for a Bayesian analysis of this model. Assume prior $_i \\sim \\mathrm{Gamma}(3, 1)$ for $i = 1, 2$, and assume $$ follows a discrete uniform distribution over ${1, \\ldots, 111}$.\nPart (a) Derive the posterior distribution of $(, _1, _2)$.\nSolution $$ X_i \\sim f(x_i | \\lambda_1,\\lambda_2,\\theta) $$$$ f(x_i | \\lambda_1,\\lambda_2,\\theta) = \\frac{\\lambda_1^{x_i} e^{-\\lambda_1}}{x_i!} I(i \\leq \\theta) + \\frac{\\lambda_2^{x_i} e^{-\\lambda_2}}{x_i!} I(i \u003e \\theta). $$$$ L(\\lambda_1,\\lambda_2,\\theta|\\vec{x}) = \\prod_{i=1}^{\\theta} \\frac{\\lambda_1^{x_i} e^{-\\lambda_1}}{x_i!} \\prod_{\\theta+1}^{n} \\frac{\\lambda_2^{x_i} e^{-\\lambda_2}}{x_i!} $$$$ L(\\lambda_1,\\lambda_2,\\theta|\\vec{x}) \\propto \\lambda_1^{t(\\theta)} e^{-\\theta \\lambda_1} \\lambda_2^{t(n)-t(\\theta)} e^{-(n-\\theta) \\lambda_2}. $$ where $t(\\theta) = \\sum_{i=1}^{\\theta} x_i$.\n$$ f(\\theta,\\lambda_1,\\lambda_2|\\vec{x}) = f(\\vec{x}|\\theta,\\lambda_1,\\lambda_2)f(\\theta,\\lambda_1,\\lambda_2)/f(\\vec{x}) $$$$ f(\\theta,\\lambda_1,\\lambda_2|\\vec{x}) \\propto L(\\theta,\\lambda_1,\\lambda_2|\\vec{x})f(\\theta)f(\\lambda_1)f(\\lambda_2). $$ where $f(\\theta) \\propto I(0 \\leq \\theta \u0026lt; n)$ and $f(\\lambda_j) \\propto \\lambda_j^2 \\exp(-\\lambda_j)$.\n$$ f(\\lambda_j) \\propto \\lambda_j^2 e^{-\\lambda_j}. $$$$ f(\\theta,\\lambda_1,\\lambda_2|\\vec{x}) \\propto \\lambda_1^{t(\\theta)} e^{-\\theta \\lambda_1} \\lambda_2^{t(n)-t(\\theta)} e^{-(n-\\theta) \\lambda_2} \\lambda_1^2 e^{-\\lambda_1} \\lambda_2^2 e^{-\\lambda_2} $$ where $t(\\theta) = \\sum_{i=1}^{\\theta} x_i$, $1 \\leq \\theta \u0026lt; n$, and $\\lambda_1,\\lambda_2 \u0026gt; 0$.\nPart (b) Derive the conditional posterior distributions necessary to carry out Gibbs sampling for this change-point model.\nSolution $$ f(\\lambda_1|\\theta,\\lambda_2,\\vec{x}) \\propto \\lambda_1^{t(\\theta) + 2} e^{-(\\theta+1) \\lambda_1}, $$$$ \\lambda_1 \\sim \\mathrm{GAM}(t(\\theta)+1,\\theta+1). $$$$ f(\\lambda_2|\\theta,\\lambda_1,\\vec{x}) \\propto \\lambda_2^{t(n)-t(\\theta)+2} e^{-(n-\\theta+1) \\lambda_2}, $$$$ \\lambda_2 \\sim \\mathrm{GAM}(t(n) - t(\\theta) + 1,n-\\theta+1). $$$$ f(\\theta|\\lambda_1,\\lambda_2,\\vec{x}) \\propto \\lambda_1^{t(\\theta)} e^{-\\theta \\lambda_1} \\lambda_2^{-t(\\theta)} e^{\\theta \\lambda_2}. $$$$ f(\\theta|\\lambda_1,\\lambda_2,\\vec{x}) \\propto \\left(\\frac{\\lambda_1}{\\lambda_2}\\right)^{t(\\theta)} e^{(\\lambda_2 - \\lambda_1) \\theta} I(\\theta \\in \\{1,\\ldots,n-1\\}), $$ which is the kernel of a probability mass function parameterized by $\\lambda_1$ and $\\lambda_2$.\n$$ \\sum_{\\theta=1}^{k-1} f(\\theta|\\cdot) \u003c U \\leq \\sum_{\\theta=1}^{k} f(\\theta|\\cdot). $$Additional analysis Note that $\\theta$ has a prior that only assigns non-zero values to $\\theta \\in {1,\\ldots,n-1}$ where $n=112$ (there are $112$ data rows in the ``coal.txt\u0026rsquo;\u0026rsquo; data file). Thus, given a prior that assigns $0$ probability to the outcome $\\theta=n$, the conditional posterior distribution for $\\theta$ also assigns zero probability to $\\theta=n$. Intuitively, it makes sense that no amount of evidence is sufficient to overcome a prior of zero probability.\nFurthermore, recall that $\\theta$ is the change-point. If the change-point occurs at $\\theta=n$, then in fact there was no change-point and $X_i \\sim \\mathrm{POI}(\\lambda_1)$ for $i=1,\\ldots,n$. In other words, assigning $\\theta=n$ a prior probability of $0$ is equivalent to claiming there is a change point.\nWe may generalize this so that if we are given prior information that $\\theta \\notin \\mathbb{K}$, we may assign zero probability to that event in the prior, i.e., $\\sum_{k \\in \\mathbb{K}} f_{\\theta}(k) = 0$. Of course, we may assign a non-uniform prior over the support, as well. The posterior distribution $f_{\\theta|\\cdot}$ from a previous experiment is a likely candidate for such a prior.\nPart (c) Implement the Gibbs sampler. Use a suite of convergence diagnostics to evaluate the convergence and mixing of your sampler.\nSolution We load the data with:\nx \u0026lt;- read.table(\u0026#34;coal.txt\u0026#34;,header=T)[,2] N \u0026lt;- length(x) We implement the conditional samplers with:\nt \u0026lt;- function(theta) { sum(x[1:theta]) } rlambda1 \u0026lt;- function(n,theta) { rgamma(n,t(theta)+1,theta+1) } rlambda2 \u0026lt;- function(n,theta) { rgamma(n,t(N)-t(theta)+1,N-theta+1) } ktheta \u0026lt;- Vectorize(function(theta,lambda1,lambda2) { if (theta \u0026lt; 1 || theta \u0026gt;= N) { return(0) } (lambda1/lambda2)^t(theta)*exp(theta*(lambda2-lambda1)) },\u0026#34;theta\u0026#34;) ptheta \u0026lt;- function(theta,lambda1,lambda2) { Z \u0026lt;- sum(ktheta(1:(N-1),lambda1,lambda2)) ktheta(theta,lambda1,lambda2)/Z } rtheta = function(n,lambda1,lambda2) { sample(x=1:(N-1),n,replace=T,prob=ptheta(1:(N-1),lambda1,lambda2)) } rlambda1.prior \u0026lt;- function() { rgamma(1,shape=3,rate=1) } rlambda2.prior \u0026lt;- function() { rgamma(1,shape=3,rate=1) } rtheta.prior \u0026lt;- function() { sample(1:(N-1),1,replace=T) } We implement the Gibbs sampling with:\ngibbs \u0026lt;- function(n,burn=1000) { nn \u0026lt;- n+burn thetas \u0026lt;- matrix(nrow=nn,ncol=3) thetas[1,] \u0026lt;- c(rtheta.prior(),rlambda1.prior(),rlambda2.prior()) for (i in 1:(nn-1)) { theta.new \u0026lt;- rtheta(1,thetas[i,2],thetas[i,3]) lambda1.new \u0026lt;- rlambda1(1,theta.new) lambda2.new \u0026lt;- rlambda2(1,theta.new) thetas[i+1,] \u0026lt;- c(theta.new,lambda1.new,lambda2.new) } thetas \u0026lt;- thetas[(burn+1):nn,] theta.est \u0026lt;- mean(thetas[,1]) lambda1.est \u0026lt;- mean(thetas[,2]) lambda2.est \u0026lt;- mean(thetas[,3]) list(theta.dist=thetas, theta.est=theta.est, lambda1.est=lambda1.est, lambda2.est=lambda2.est) } n \u0026lt;- 5000 burn \u0026lt;- 0 res \u0026lt;- gibbs(n,burn) param.est \u0026lt;- c(res$theta.est,res$lambda1.est,res$lambda2.est) names(param.est) \u0026lt;- c(\u0026#34;theta\u0026#34;,\u0026#34;lambda1\u0026#34;,\u0026#34;lambda2\u0026#34;) knitr::kable(data.frame(param.est)) param.est theta 40.0884000 lambda1 3.0650183 lambda2 0.9216624 Now, we plot the marginals for the estimator.\npar(mfrow=c(1,3)) hist(res$theta.dist[,1],freq=F,main=\u0026#34;theta\u0026#34;,xlab=\u0026#34;\u0026#34;,breaks=50) hist(res$theta.dist[,2],freq=F,main=\u0026#34;lambda1\u0026#34;,xlab=\u0026#34;\u0026#34;,breaks=50) hist(res$theta.dist[,3],freq=F,main=\u0026#34;lambda2\u0026#34;,xlab=\u0026#34;\u0026#34;,breaks=50) plot(res$theta.dist[1:100,1],type=\u0026#34;l\u0026#34;,main=\u0026#34;\u0026#34;,ylab=\u0026#34;theta\u0026#34;) plot(res$theta.dist[1:100,2],type=\u0026#34;l\u0026#34;,main=\u0026#34;initial sample path\u0026#34;,ylab=\u0026#34;lambda1\u0026#34;) plot(res$theta.dist[1:100,3],type=\u0026#34;l\u0026#34;,main=\u0026#34;\u0026#34;,ylab=\u0026#34;lambda2\u0026#34;) plot(res$theta.dist[2000:2100,1],type=\u0026#34;l\u0026#34;,main=\u0026#34;\u0026#34;,ylab=\u0026#34;theta\u0026#34;) plot(res$theta.dist[2000:2100,2],type=\u0026#34;l\u0026#34;,main=\u0026#34;later sample path\u0026#34;,ylab=\u0026#34;lambda1\u0026#34;) plot(res$theta.dist[2000:2100,3],type=\u0026#34;l\u0026#34;,main=\u0026#34;\u0026#34;,ylab=\u0026#34;lambda2\u0026#34;) acf(res$theta.dist[,1],main=\u0026#34;theta\u0026#34;) acf(res$theta.dist[,2],main=\u0026#34;lambda1\u0026#34;) acf(res$theta.dist[,3],main=\u0026#34;lambda2\u0026#34;) They all satisfy normality (approximately symmetric around the mean), converge quickly, exhibit low autocorrelation (ACF decays quickly), and show good support (they vigorously jiggle around the mean).\nProblem 4 Compare bootstrapped CIs for the population 90th percentile to the large sample estimate as in the notes for (a) $\\mathrm{EXP}(1)$ data, (b) $N(0,1)$ data, (c) $U(0, 1)$ data, and (d) $\\chi^2(1)$ data. For sample sizes of $n = 100$ and replicate $B = 500$.\nSolution $$ F_n(x) = \\frac{1}{n} \\sum_{i=1}^{n} I(x_i \\leq x). $$$$ q = F^{-1}(p) $$ which may be estimated with $q_n = F^{-1}n(p) = x{[n p]}$.\nDelta method $$ q_n \\sim \\mathrm{AN}\\left(q, \\frac{p(1-p)}{n f^2(q)}\\right). $$Since the pdf $f$ is not known, we must estimate it with $f_n$ (note that we cannot simply take the derivative of $F_m$ since it is a step function). We use the built-in R function $\\mathrm{density}$ to estimate $f$.\n$$ \\mathrm{Var}(q_n) = \\frac{p(1-p)}{n f_n^2(q)} $$$$ q_n \\pm z_{1-\\alpha/2} \\sqrt{\\frac{p(1-p)}{n f_n^2(q_n)}}. $$We implement the confidence interval estimator for $q_n$ with the following:\nq.ci.delta \u0026lt;- function(samp,p,alpha,bw=\u0026#34;bcv\u0026#34;) { z \u0026lt;- qnorm(1-alpha/2) q.est \u0026lt;- quantile(samp,p) f \u0026lt;- density(samp,bw=bw,n=1,from=q.est,to=q.est)$y se \u0026lt;- sqrt(p*(1-p)/(n*f^2)) list(estimate=q.est,p=p,alpha=alpha,ci=c(q.est-z*se,q.est+z*se)) } Bootstrap method Next, we consider the Bootstrap method. The statistic for the Bootstrap method, the $p$-th quantile, is given by:\n# p-quantile statistic that we provide as input to the # bootstrap function q.stat \u0026lt;- function(p=0.9) { function(x,indices) { f \u0026lt;- quantile(x[indices],p) names(f) \u0026lt;- NULL f } } We implement the Bootstrap confidence interval estimator for $q_n$ with the following:\nq.ci.bs \u0026lt;- function(samp,p,alpha,B) { library(boot) b \u0026lt;- boot(samp, q.stat(p), B) ci \u0026lt;- boot.ci(b,conf=1-alpha,type=\u0026#34;perc\u0026#34;)$percent list(estimate=quantile(samp,p),p=p,alpha=alpha,ci=c(ci[4],ci[5])) } $$ q_n^{(1)},\\ldots,q_n^{(B)} $$ and then pick the $p$-th percentile.\nPart (a) Compute coverage probabilities of the two intervals and average interval length. (You need to run the intervals for $M$ times.)\nSolution To capture the data for each random variable, we encapsulate the process into a procedure that may be invoked for any function that models a random variable and whose first parameter denotes the sample size.\n#\u0026#39; Retrieve CI stats for the specified method and random variable #\u0026#39; #\u0026#39; @param q.star the true value for the p-th quantile #\u0026#39; @param rv the random variable generator, of type n -\u0026gt; R^n #\u0026#39; @param n size of sample to generate #\u0026#39; @param M number of trials #\u0026#39; @param type \u0026#34;bootstrap\u0026#34; or \u0026#34;delta\u0026#34; #\u0026#39; @param B number of bootstrap replicates (only relevant if type == \u0026#34;bootstrap\u0026#34;) #\u0026#39; @returns a vector of the relevant results ci.stats \u0026lt;- function(q.star, rv, p, n, M=250, type=\u0026#34;bootstrap\u0026#34;, B=500) { coverage.prop \u0026lt;- 0 avg.length \u0026lt;- 0 for (i in 1:M) { samp \u0026lt;- rv(n) res \u0026lt;- NULL if (type==\u0026#34;bootstrap\u0026#34;) { res \u0026lt;- q.ci.bs(samp,p,alpha,B) } else { res \u0026lt;- q.ci.delta(samp,p,alpha) } avg.length \u0026lt;- avg.length + (res$ci[2] - res$ci[1]) if (q.star \u0026gt;= res$ci[1] \u0026amp;\u0026amp; q.star \u0026lt;= res$ci[2]) { coverage.prop \u0026lt;- coverage.prop + 1 } } avg.length \u0026lt;- avg.length / M coverage.prop \u0026lt;- coverage.prop / M c(q.star,res$estimate,coverage.prop,avg.length) } Now, we use $\\mathrm{ci.stats}$ to generate and compute the data:\np \u0026lt;- 0.9 # p-th quantile alpha \u0026lt;- 0.05 # CI alpha level n \u0026lt;- 100 # sample size B \u0026lt;- 500 # bootstrap replicates M \u0026lt;- 500 # simulate and compute the data tab \u0026lt;- matrix(nrow=8,ncol=4) rownames(tab) \u0026lt;- c(\u0026#34;exp(1): delta\u0026#34;, \u0026#34;exp(1): bootstrap\u0026#34;, \u0026#34;N(0,1): delta\u0026#34;, \u0026#34;N(0,1): bootstrap\u0026#34;, \u0026#34;U(0,1): delta\u0026#34;, \u0026#34;U(0,1): bootstrap\u0026#34;, \u0026#34;X^2(1): delta\u0026#34;, \u0026#34;X^2(1): bootstrap\u0026#34;) colnames(tab) \u0026lt;- c(\u0026#34;q.star\u0026#34;, \u0026#34;q.est\u0026#34;, \u0026#34;coverage\u0026#34;, \u0026#34;average length\u0026#34;) tab[1,] \u0026lt;- ci.stats(qexp(p),rexp,p,n,M,\u0026#34;delta\u0026#34;) tab[2,] \u0026lt;- ci.stats(qexp(p),rexp,p,n,M,\u0026#34;bootstrap\u0026#34;,B) tab[3,] \u0026lt;- ci.stats(qnorm(p),rnorm,p,n,M,\u0026#34;delta\u0026#34;) tab[4,] \u0026lt;- ci.stats(qnorm(p),rnorm,p,n,M,\u0026#34;bootstrap\u0026#34;,B) tab[5,] \u0026lt;- ci.stats(qunif(p),runif,p,n,M,\u0026#34;delta\u0026#34;) tab[6,] \u0026lt;- ci.stats(qunif(p),runif,p,n,M,\u0026#34;bootstrap\u0026#34;,B) tab[7,] \u0026lt;- ci.stats(qchisq(p,df=1),function(n) { rchisq(n,df=1) },p,n,M,\u0026#34;delta\u0026#34;) tab[8,] \u0026lt;- ci.stats(qchisq(p,df=1),function(n) { rchisq(n,df=1) },p,n,M,\u0026#34;bootstrap\u0026#34;,B) Part (b) Summarizing your results in a table. Comment on your findings. Which is better?\nSolution knitr::kable(data.frame(tab)) q.star q.est coverage average.length exp(1): delta 2.302585 2.3482875 0.876 1.0330318 exp(1): bootstrap 2.302585 1.8352320 0.938 1.1304459 N(0,1): delta 1.281552 1.3145702 0.924 0.6211391 N(0,1): bootstrap 1.281552 1.1113686 0.944 0.6633263 U(0,1): delta 0.900000 0.8950180 0.970 0.1482522 U(0,1): bootstrap 0.900000 0.8892106 0.938 0.1217511 X^2(1): delta 2.705544 2.7834884 0.858 1.5984722 X^2(1): bootstrap 2.705544 2.0984550 0.944 1.8483615 Overall, the Bootstrap estimator of CI is more compatible with the claimed confidence interval.\n$$ 2 z_{1-\\alpha/2} \\sigma_q $$$$ \\sigma_q = \\sqrt{\\frac{p(1-p)}{n f^2(q^*)}}. $$Supplementary Material Problem 1 supplementary material: inverse transform method In problem 1, $Y$ is the double exponential random variable and we sampled from it by recognizing we can simply sample from the exponential and taking its negative with probability $0.5$.\n$$ \\frac{1}{Z} \\int_{-\\infty}^{\\infty} g(x) dx = 1, $$$$ \\int_{-\\infty}^{0} e^{x} dx + \\int_{0}^{\\infty} e^{-x} dx = Z, $$$$ f_Y(y) = \\frac{1}{2} \\exp(-|x|). $$g.density \u0026lt;- function(y) { 0.5*exp(-abs(y)) } $$ F_Y(y) = \\frac{1}{2}\\int_{-\\infty}^{y} \\exp(-|s|) ds. $$$$ F_Y(y) = \\frac{1}{2} \\int_{-\\infty}^{y} \\exp(s) ds = \\frac{1}{2}\\exp(y) $$$$ F_Y(y) = F_Y(0) + \\frac{1}{2} \\int_{0}^{y} \\exp(-s) ds = \\frac{1}{2} + \\frac{1}{2}(1 - \\exp(-y)), $$$$ F_Y(y) = \\begin{cases} \\frac{1}{2} \\exp(y) \u0026 y \\leq 0\\\\ 1 - \\frac{1}{2} \\exp(-y) \u0026 y \u003e 0. \\end{cases} $$$$ p = \\frac{1}{2} \\exp(y). $$$$ p = 1 - \\frac{1}{2} \\exp(-y). $$$$ y = -\\log(2-2p) $$$$ F^{-1}(p) = \\begin{cases} \\log(2p) \u0026 p \\in (0,0.5]\\\\ -\\log(2-2p) \u0026 p \\in (0.5,1). \\end{cases} $$ Thus, to sample from $Y$, we observe $u$ from $U(0,1)$ and, if $u \\leq 0.5$, we let $y = \\log(2u)$ and otherwise let $y = -\\log(2-2u)$.\nWe implement this sampler with:\nry.itm \u0026lt;- function(n) { ys \u0026lt;- numeric(n) for (i in 1:n) { u \u0026lt;- runif(1) if (u \u0026lt;= 0.5) { ys[i] \u0026lt;- log(2*u) } else { ys[i] \u0026lt;- -log(2-2*u)} } ys } Inverse transform method for sampling from random variable with kernel $g$ $$ \\frac{1}{Z} \\int_{-\\infty}^{\\infty} g(x) dx = 1, $$$$ \\int_{-\\infty}^{0} e^{x} dx + \\int_{0}^{\\infty} e^{-x} dx = Z, $$$$ f_Y(y) = \\frac{1}{2} \\exp(-|x|). $$g.density \u0026lt;- function(x) { 0.5*exp(-abs(x)) } $$ F_Y(y) = \\frac{1}{2}\\int_{-\\infty}^{y} \\exp(-|s|) ds. $$$$ F_Y(y) = \\frac{1}{2} \\int_{-\\infty}^{y} \\exp(s) ds = \\frac{1}{2}\\exp(y) $$$$ F_Y(y) = F_Y(0) + \\frac{1}{2} \\int_{0}^{y} \\exp(-s) ds = \\frac{1}{2} + \\frac{1}{2}(1 - \\exp(-y)), $$$$ F_Y(y) = \\begin{cases} \\frac{1}{2} \\exp(y) \u0026 y \\leq 0\\\\ 1 - \\frac{1}{2} \\exp(-y) \u0026 y \u003e 0. \\end{cases} $$$$ p = \\frac{1}{2} \\exp(y). $$$$ p = 1 - \\frac{1}{2} \\exp(-y). $$$$ y = -\\log(2-2p) $$$$ F^{-1}(p) = \\begin{cases} \\log(2p) \u0026 p \\in (0,0.5]\\\\ -\\log(2-2p) \u0026 p \\in (0.5,1). \\end{cases} $$ Thus, to sample from $Y$, we observe $u$ from $U(0,1)$ and, if $u \\leq 0.5$, we let $y = \\log(2u)$ and otherwise let $y = -\\log(2-2u)$.\nry \u0026lt;- function(n) { ys \u0026lt;- numeric(n) for (i in 1:n) { u \u0026lt;- runif(1) if (u \u0026lt;= 0.5) { ys[i] \u0026lt;- log(2*u) } else { ys[i] \u0026lt;- -log(2-2*u)} } ys } ",
        "summary": "This exam covers numerical integration, Monte Carlo simulation, acceptance-rejection sampling, importance sampling, and the Metropolis-Hastings algorithm.",
        "tags": null,
        "section": "probsets"
      },{
        "title": "computational-statistics-siue-stat-575-problem-set-3",
        "link": "http://localhost:1313/probsets/stat575/problem_set_3/",
        "date": "2021-07-10 00:00:00 +0000 UTC",
        "content": "Problem 1 $$ \\int_{-\\infty}^{\\infty} e^{-x^2} dx. $$Part (a) Evaluate the integral in closed form using $\\pi$.\nSolution $$ \\sqrt{2 \\pi \\sigma^2} \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\frac{1}{2 \\sigma^2}x^2} dx. $$$$ \\sqrt{\\pi} \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{\\pi}} e^{-x^2} dx $$ which is equivalent to $\\sqrt{\\pi} E_X(1) = \\sqrt{\\pi}$.\nPart (b) Estimate the above integral using Riemmans Rule. Give a estimate of $\\pi$. Does it at least provide a couple digits worth of accuracy?\nSolution $$ h \\sum_{i=1}^{n} f(a + h i) \\approx \\int_{a}^{b} f(x) dx $$ where $h = (b-a)/n$, which we straightforwardly implement with:\nright_riemann_sum \u0026lt;- function(f, a, b, n) { h \u0026lt;- (b - a)/n h * sum(f(a + (1:n) * h)) } $$ \\hat{\\pi}_{\\mathrm{riemann}} = \\mathrm{right-riemann\\_sum}(g,-r,r,n)^2. $$ where $g(x) = e^{-x^2}$, $(-r,r)$, $r \u0026gt; 0$, is the domain to numerically integrate over, and $n$ is the number of blocks in the partition. We implement this estimator with the following code:\nriemann_pi \u0026lt;- Vectorize(function(n, r) { right_riemann_sum(function(x) { exp(-x^2) }, -r, r, n)^2 }) We provide an estimate of $\\pi$ with:\nriemann_pi(10, 4) ## [1] 3.141595 The estimator provides $5$ decimals of accuracy based on Riemman\u0026rsquo;s rule with $n = 10$ over $(-4,4)$. This provides unusually good accuracy for the right-handed Riemann rule due to the fact that the integrand is symmetric about the origin and thus the overestimate of the integral over $(-4,0)$ is canceled by the underestimate over $(0,4)$.\n$$ \\lim_{n\\to\\infty,r \\to \\infty} \\mathrm{riemann\\_pi}(n,r) = \\pi. $$One may have the insight that, since $e^{-x^2}$ is symmetric about the origin, we can just sum over $[0,r]$ instead, which would obtain $\\sqrt{\\pi}/2$. Let us try:\n4 * right_riemann_sum(function(x) { exp(-x^2) }, 0, 4, 10)^2 ## [1] 1.88363 This is a very poor estimate of $\\pi$. Let us try with $n=100000$:\n4 * right_riemann_sum(function(x) { exp(-x^2) }, 0, 4, 1e+05)^2 ## [1] 3.141451 Remarkably, it still performs relatively poorly compared to $\\hat{\\pi}_{\\rm{riemann}}$.\nPart (c) Redo part (b) to estimate $\\pi$ using Gauss-Hermite quadrature. You may use the fastGHQuad function in R.\nSolution library(fastGHQuad) hermite_pi \u0026lt;- Vectorize(function(n) { aghQuad(function(x) { exp(-x^2) }, 0, 1.1, gaussHermiteData(n))^2 }) pi.hat.herm \u0026lt;- hermite_pi(10) pi.hat.herm ## [1] 3.14025 $$ \\epsilon^*_{\\mathrm{riemann}} = \\min_{n,r}(\\mathrm{riemann\\_pi}(n,r)) $$$$ \\epsilon^*_{\\mathrm{hermite}} = \\min_{n}(\\mathrm{hermite\\_pi}(n)). $$Here is the code that finds the argument that minimizes these estimators, along with their respective errors:\narg.min \u0026lt;- function(xs, f) { y.min \u0026lt;- Inf x.min \u0026lt;- NULL for (x in xs) { y \u0026lt;- f(x) if (y \u0026lt; y.min) { x.min \u0026lt;- x y.min \u0026lt;- y } } list(x.min = x.min, y.min = y.min) } Now, we try it:\nhermite.min \u0026lt;- arg.min(10:100, function(n) { abs(hermite_pi(n) - pi) }) riemann4.min \u0026lt;- arg.min(10:100, function(n) { abs(riemann_pi(n, 4) - pi) }) riemann5.min \u0026lt;- arg.min(10:100, function(n) { abs(riemann_pi(n, 5) - pi) }) riemann6.min \u0026lt;- arg.min(10:100, function(n) { abs(riemann_pi(n, 6) - pi) }) print(hermite.min) ## $x.min ## [1] 46 ## ## $y.min ## [1] 4.440892e-16 print(riemann4.min) ## $x.min ## [1] 100 ## ## $y.min ## [1] 1.002528e-07 print(riemann5.min) ## $x.min ## [1] 100 ## ## $y.min ## [1] 1.046851e-11 print(riemann6.min) ## $x.min ## [1] 24 ## ## $y.min ## [1] 4.440892e-16 $$ \\epsilon^*_{\\mathrm{hermite}} = \\epsilon^*_{\\mathrm{riemann}} = 4.440892 \\times 10^{-16}. $$ Interesting.\nProblem 2 $$ y_i = 3 x_i + \\epsilon_i, \\epsilon_i \\sim N(0,1). $$ In each Monte Carlo sample, first generate a vector of $x$ (you may pick $x$ from any distribution, say a normal or a uniform). Then generate $\\epsilon$ from $N(0, 1)$ and then $y$ according to the regression formula.\nUse $\\mathrm{lm}()$ to fit the regression model, and $\\mathrm{confint}()$ to get the $95%$ confidence interval for the slope parameter. Run the MC iterations for $10000$ times and get the proportion of CI that covers the true slope $_1 = 3$. Verify the proportion is close to $0.95$.\nSolution N \u0026lt;- 10000 covers \u0026lt;- 0 n \u0026lt;- 1000 for (i in 1:N) { x \u0026lt;- runif(n, -100, 100) e \u0026lt;- rnorm(n) y \u0026lt;- 3 * x + e fit \u0026lt;- lm(y ~ x) ci \u0026lt;- confint(fit) if (ci[2] \u0026lt;= 3 \u0026amp;\u0026amp; 3 \u0026lt;= ci[4]) covers \u0026lt;- covers + 1 } prop \u0026lt;- covers/N prop ## [1] 0.9513 As we can see, the proportion of confidence intervals that cover the true parameter value is approximately $95%$.\nProblem 3 Let $Y \\sim \\rm{Bernoulli}(0.7)$ and the conditional distribution of $X$ given $Y$ is $X | Y \\sim N(\\mu_Y,1)$, where $\\mu_0 = 2$ and $\\mu_1 = 2$.\nPart (a) Derive the marginal pdf of $X$.\nSolution $$ f_{X,Y}(x,y) = f_Y(y) f_{X|Y}(x|y) $$$$ f_{X,Y}(x,y) = (.7)^y(.3)^{1-y} \\left(I(y=0) \\phi(x+2) + I(y=1) \\phi(x-2)\\right). $$$$ f_X(x) = f_{X,Y}(x,0) + f_{X,Y}(x,1) $$$$ f_X(x) = 0.3 \\phi(x+2) + 0.7 \\phi(x-2). $$Clearly, this is a simple Gaussian mixture model.\nPart (b) Use iterated expectation and variance to find $E(X)$ and $\\mathrm{Var}(X)$ exactly.\nSolution $$ \\begin{align*} E(X) \u0026= E_Y(E(X|Y))\\\\ \u0026= E(X|y=0)f_Y(0) + E(X|y=1)f_Y(1)\\\\ \u0026= (-2)(0.3) + (2)0.7\\\\ \u0026= 0.8. \\end{align*} $$$$ \\begin{align*} \\mathrm{Var}(X) \u0026= E_Y(\\mathrm{Var}(X|Y)) + \\mathrm{Var}_Y(E(X|Y))\\\\ \u0026= E_Y(1) + \\mathrm{Var}(\\mu_Y)\\\\ \u0026= 1 + E_Y(\\mu_Y^2) - E_Y^2(\\mu_Y)\\\\ \u0026= 1 + \\mu_0^2(1-p) + \\mu_1^2 p - \\mu^2\\\\ \u0026= 1 + 4(0.3) + 4(0.7) - 0.8^2\\\\ \u0026= 4.36\\\\ \\end{align*} $$Part (c) Obtain a Monte Carlo sample of size $m = 10000$. Use this sample to compute (i) $E(X)$, (ii) $\\mathrm{Var}(X)$, (iii) $90$-th percentile of $X$.\nSolution First, we perform a MC simulation to obtain a sample from ${X_m}$:\nm \u0026lt;- 10000 p \u0026lt;- 0.7 mu_0 \u0026lt;- -2 mu_1 \u0026lt;- 2 xs \u0026lt;- vector(length = m) ys \u0026lt;- rbinom(m, 1, p) for (i in 1:m) { if (ys[i] == 0) xs[i] \u0026lt;- rnorm(1, mu_0) else xs[i] \u0026lt;- rnorm(1, mu_1) } Now, we just apply the necessary statistics to the sample to estimate the parameters.\nPart (i) The parameter $\\mu$ is estimated to be:\nmean(xs) ## [1] 0.7971801 Part (ii) The parameter $\\sigma^2$ is estimated to be:\nvar(xs) ## [1] 4.353838 Part (iii) The $90%$ percentile is estimated to be:\nquantile(xs, c(0.9)) ## 90% ## 3.07488 ",
        "summary": "This problem set covers numerical integration, Riemann sums, Gauss-Hermite quadrature, Monte Carlo simulation, and Gaussian mixture models.",
        "tags": null,
        "section": "probsets"
      },{
        "title": "computational-statistics-siue-stat-575-problem-set-1",
        "link": "http://localhost:1313/probsets/stat575/problem_set_1/",
        "date": "2021-07-01 00:00:00 +0000 UTC",
        "content": "Problem 1 Write your own code and find solution to the equation $x^3 + x - 4 = 0$ using Newtons method and the secant method. Compare the number of iterations needed for different starting values for the two methods.\nSolution: Newton\u0026rsquo;s method If we have some function $f : \\mathbb{R} \\mapsto \\mathbb{R}$ and we wish to find a root of $f$, i.e., an $x$ such that $f(x) = 0$, we may use Newton\u0026rsquo;s method.\n$$ L(f | x_0) \\coloneqq \\lambda x.f(x_0) + f'(x_0)(x-x_0). $$$$ L(f|x_0)(x) = 0, $$$$ f(x_0) + f'(x_0)(x-x_0) = 0. $$$$ x = x_0 - \\frac{f(x_0)}{f'(x_0)}. $$Hoping that $x$ results in a better approximation of the root of $f$ than $x_0$, we approximate $f$ with $L(f|x)$ and repeat the process.\n$$ x_{i+1} = x_i - \\frac{f(x_i)}{f'(x_i)}. $$ We continue this process until we obtain some stopping condition, e.g., $|x_{i+1} - x_i| \u0026lt; \\epsilon$.\n$$ x_{i+1} = x_i - \\frac{x_i^3+x_i-4}{3x_i^2+1}. $$We implement a general procedure for Newton\u0026rsquo;s method:\nnewton_method \u0026lt;- function(f,dfdx,x0,eps,debug=T) { n \u0026lt;- 0 repeat { x1 \u0026lt;- x0 - f(x0) / dfdx(x0) n \u0026lt;- n + 1 if (debug) { cat(\u0026#34;iteration=\u0026#34;,n,\u0026#34; x=\u0026#34;,x1,\u0026#34;\\n\u0026#34;) } if(abs(x1 - x0) \u0026lt; eps) { break } # stopping condition x0 \u0026lt;- x1 } list(root=x0,iter=n,eps=eps) } We take an initial guess of $x_0 = 1$ and $\\epsilon = 1 \\times 10^{-6}$ and run the following R code to solve for a root of $f$ using Newton\u0026rsquo;s method:\nf \u0026lt;- function(x) { x^3 + x - 4 } dfdx \u0026lt;- function(x) { 3*x^2 + 1 } eps \u0026lt;- 1e-6 x0 \u0026lt;- 1 result \u0026lt;- newton_method(f,dfdx,x0,eps) ## iteration= 1 x= 1.5 ## iteration= 2 x= 1.387097 ## iteration= 3 x= 1.378839 ## iteration= 4 x= 1.378797 ## iteration= 5 x= 1.378797 print(result) ## $root ## [1] 1.378797 ## ## $iter ## [1] 5 ## ## $eps ## [1] 1e-06 We obtain $x \\approx 1.3787967$ after $5$ iterations.\nSolution: Secant method $$ \\frac{f(x_{i+1}) - f(x_i)}{x_{i+1}-x_i}, $$$$ x_{i+2} = x_{i+1} - f(x_{i+1})\\frac{x_{i+1}-x_i}{f(x_{i+1}) - f(x_i)}, $$ which requires two initial values $x_0$ and $x_1$.\nWe define the secant method as a function given by:\nsecant_method \u0026lt;- function(f,x0,x1,eps,debug=T) { n \u0026lt;- 0 repeat { x2 \u0026lt;- x1 - f(x1) * (x1 - x0) / (f(x1) - f(x0)) n \u0026lt;- n + 1 if (debug) { cat(\u0026#34;iteration=\u0026#34;,n,\u0026#34; x=\u0026#34;,x2,\u0026#34;\\n\u0026#34;) } if(abs(x2-x1) \u0026lt; eps) { break } # stopping condition x0 \u0026lt;- x1 x1 \u0026lt;- x2 } list(root=x1,iter=n,eps=eps) } We let $x_0 = 0$, $x_1 = 1$, and keep everything else the same and run the secant method with the following R code:\nx0 \u0026lt;- 0 x1 \u0026lt;- 1 result \u0026lt;- secant_method(f,x0,x1,eps) ## iteration= 1 x= 2 ## iteration= 2 x= 1.25 ## iteration= 3 x= 1.337931 ## iteration= 4 x= 1.382262 ## iteration= 5 x= 1.378708 ## iteration= 6 x= 1.378797 ## iteration= 7 x= 1.378797 print(result) ## $root ## [1] 1.378797 ## ## $iter ## [1] 7 ## ## $eps ## [1] 1e-06 We obtain $x \\approx 1.3787965$ after $7$ iterations. Note that this is $2$ more iterations than Newton\u0026rsquo;s method.\nComparison of Newton\u0026rsquo;s method versus secant method We perform $n=100000$ trials to get a better view of how the two methods, Newton and secant, compare over many different initial guesses.\nWe generate the data with:\nn \u0026lt;- 100000 from \u0026lt;- 0 to \u0026lt;- 4 by \u0026lt;- (to-from)/n newt_sols \u0026lt;- vector(length=n) sec_sols \u0026lt;- vector(length=n) i \u0026lt;- 1 for (x0 in seq(from=from, to=to, by=by)) { newt_sols[i] \u0026lt;- newton_method(f,dfdx,x0,eps,F)$iter sec_sols[i] \u0026lt;- secant_method(f,x0,x0+1,eps,F)$iter i \u0026lt;- i + 1 } We summarize the results and report them with:\ncat(\u0026#34;mean iterations\\n\u0026#34;, \u0026#34;newton =\u0026gt; \u0026#34;, mean(newt_sols), \u0026#34;\\n\u0026#34;, \u0026#34;secant =\u0026gt; \u0026#34;, mean(sec_sols), \u0026#34;\\n\u0026#34;) ## mean iterations ## newton =\u0026gt; 5.819542 ## secant =\u0026gt; 7.231338 We see that Newton\u0026rsquo;s method, on average, requires $1.4117959$ fewer iterations before the stopping condition is satisfied.\nProblem 2 Poisson regression. The Ache hunting data set has $n = 47$ observations recording is the number of monkeys killed over a period of days with each hunter along with hunters age. It is of interest to estimate and quantify the monkey kill rate as a function of hunters age. Hunting prowess confers elevated status among the group, so a natural question is whether hunting ability improves with age, and at which age hunting ability is best.\n$$ \\mathit{monkeys}_i \\sim \\operatorname{Pois}\\left(\\exp(\\log \\mathit{days}_i + \\theta_1 + \\theta_2 \\mathit{age}_i + \\theta_3 \\mathit{age}_i^2)\\right). $$Feel free to use jacobian and hessian in the numDeriv R package. You may need a sets of crude starting values. I run a linear regression for the \u0026ldquo;empirical log-rates\u0026rdquo; and get starting values $(5.99, 0.167, 0.001)$. Feel free to use those. Compare your result with glm() function in R using\nglm(monkeys~age+I(age^2), family=\u0026#34;poisson\u0026#34;, offset=log(days), data=d) Solution We are given the following data:\nd \u0026lt;- read.table(\u0026#34;ache.txt\u0026#34;, header=T) n \u0026lt;- length(d$age) X \u0026lt;- cbind(rep(1,n), d$age, d$age^2) loglike \u0026lt;- function(theta) { sum(dpois(d$monkeys,exp(log(d$days)+X%*%theta),log=T)) } # print the data print(d) ## hunter age monkeys days ## 1 1 67 0 3 ## 2 2 66 0 89 ## 3 3 63 29 106 ## 4 4 60 2 4 ## 5 5 61 0 28 ## 6 6 59 2 73 ## 7 7 58 3 7 ## 8 8 57 0 13 ## 9 9 56 0 4 ## 10 10 56 3 104 ## 11 11 55 27 126 ## 12 12 54 0 63 ## 13 13 51 7 88 ## 14 14 50 0 7 ## 15 15 48 3 3 ## 16 16 49 0 56 ## 17 17 47 6 70 ## 18 18 42 1 18 ## 19 19 39 0 4 ## 20 20 40 7 83 ## 21 21 40 4 15 ## 22 22 39 1 19 ## 23 23 37 2 29 ## 24 24 35 2 48 ## 25 25 35 0 35 ## 26 26 33 0 10 ## 27 27 33 19 75 ## 28 28 32 9 63 ## 29 29 32 0 16 ## 30 30 31 0 13 ## 31 31 30 0 20 ## 32 32 30 2 26 ## 33 33 28 0 4 ## 34 34 27 0 13 ## 35 35 25 0 10 ## 36 36 22 0 16 ## 37 37 22 0 33 ## 38 38 21 0 7 ## 39 39 20 0 33 ## 40 40 18 0 8 ## 41 41 17 0 3 ## 42 42 17 0 13 ## 43 43 17 0 3 ## 44 44 56 0 62 ## 45 45 62 1 4 ## 46 46 59 1 4 ## 47 47 20 0 11 $$ X = \\begin{pmatrix} 1 \u0026 a_1 \u0026 a_1^2\\\\ 1 \u0026 a_2 \u0026 a_2^2\\\\ \\vdots \u0026 \\vdots \u0026 \\vdots\\\\ 1 \u0026 a_n \u0026 a_n^2\\\\ \\end{pmatrix}, $$$$ \\vec{\\theta} = \\begin{pmatrix} \\theta_1\\\\ \\theta_2\\\\ \\theta_3 \\end{pmatrix}, $$$$ \\vec{m} = \\begin{pmatrix} m_1\\\\ m_2\\\\ \\vdots\\\\ m_n \\end{pmatrix}. $$$$ M_i \\sim \\mathrm{POI}(\\exp(\\log d_i + X \\vec{\\theta})). $$ where $M_i$ is the random response variable for $i=1,\\ldots,n$.\nWe generalize the univariate Newton\u0026rsquo;s method in Problem 1 to the multivariate case. We implement the multivariate Newton-Raphson method with numerical hessian and jacobian with the following R code:\nlibrary(numDeriv) newton_raphson_method \u0026lt;- function(x0,f,eps) { n \u0026lt;- 0 x1 \u0026lt;- x0 repeat { x1 \u0026lt;- x0 - solve(hessian(f,x0))%*%t(jacobian(f,x0)) n \u0026lt;- n + 1 if (n %% 7 == 0) { cat(\u0026#34;iteration=\u0026#34;,n,\u0026#34; theta=\u0026#34;,x1,\u0026#34;\\n\u0026#34;) } if (max(abs(x1 - x0)) \u0026lt; eps) { break } x0 \u0026lt;- x1 } list(root=x1,iter=n) } We use the multivariate Newton-Raphson method to find the MLE of $\\theta$ in the poisson regression model:\neps \u0026lt;- 1e-6 theta0 \u0026lt;- c(5.99, 0.167, 0.001) # starting values theta_mle \u0026lt;- newton_raphson_method(theta0,loglike,eps)$root ## iteration= 7 theta= -1.011118 0.1670372 0.000999693 ## iteration= 14 theta= -7.590761 0.153262 0.00111206 ## iteration= 21 theta= 1.438483 -0.2696712 0.003827084 ## iteration= 28 theta= -5.484246 0.1246477 -0.001203418 The MLE of $\\theta$ is given by:\ntheta_mle ## [,1] ## [1,] -5.484245903 ## [2,] 0.124647667 ## [3,] -0.001203418 We compare the results with the builtin method:\nglm(monkeys~age+I(age^2),family=\u0026#34;poisson\u0026#34;, offset=log(days),data=d)$coefficients ## (Intercept) age I(age^2) ## -5.484245904 0.124647667 -0.001203418 The hand-coded approach and the builtin approach obtain the same point estimate $\\hat\\theta = (-5.4842, 0.1246, -0.0012)\u0026rsquo;$.\nProblem 3 Logistic and Cauchy distributions are well-suited to the inverse transform method. For each of the following, generate $10,000$ random variables using the inverse transform. Compare your program with the built-in R functions rlogis() and rcauchy(), respectively:\nSolution: part (a) $$ F(x) = \\frac{1}{1+e^{-x}} $$$$ \\begin{align*} u \u0026= F(x)\\\\ u \u0026= \\frac{1}{1+e^{-x}}\\\\ x \u0026= \\log(u/(1-u)). \\end{align*} $$n \u0026lt;- 10000 us \u0026lt;- runif(n) d1 \u0026lt;- density(log(us/(1-us))) d2 \u0026lt;- density(rlogis(n)) plot(d1,col=\u0026#34;blue\u0026#34;,main=\u0026#34;comparison of density plots\u0026#34;) lines(d2,col=\u0026#34;red\u0026#34;) legend(x=\u0026#34;topright\u0026#34;,legend=c(\u0026#34;inverse method\u0026#34;,\u0026#34;built-in\u0026#34;),col=c(\u0026#34;blue\u0026#34;,\u0026#34;red\u0026#34;), pch=c(\u0026#34;-\u0026#34;,\u0026#34;-\u0026#34;)) Solution: part (b) $$ F(x) = \\frac{1}{2} + \\frac{1}{\\pi} \\operatorname{arctan(x)} $$$$ \\begin{align*} u \u0026= F(x)\\\\ u \u0026= \\frac{1}{2} + \\frac{1}{\\pi} \\operatorname{arctan(x)}\\\\ x \u0026= \\tan(\\pi(u-1/2)). \\end{align*} $$n \u0026lt;- 1000 us \u0026lt;- runif(n) d1 \u0026lt;- tan(pi*(us-0.5)) d2 \u0026lt;- rcauchy(n=n) d1 \u0026lt;- d1[d1 \u0026gt; -20 \u0026amp; d1 \u0026lt; 20] d2 \u0026lt;- d2[d2 \u0026gt; -20 \u0026amp; d2 \u0026lt; 20] c1 \u0026lt;- rgb(0,0,255, max = 255, alpha = 50, names = \u0026#34;blue\u0026#34;) c2 \u0026lt;- rgb(255,0,0, max = 255, alpha = 50, names = \u0026#34;red\u0026#34;) par(mfrow=c(1,2)) hist(d1,col=c1,freq=F,breaks=50,main=\u0026#34;inverse-transform method vs built-in\u0026#34;) hist(d2,col=c2,add=T,freq=F,breaks=50) legend(x=\u0026#34;topright\u0026#34;,legend=c(\u0026#34;inv\u0026#34;,\u0026#34;builtin\u0026#34;),col=c(\u0026#34;blue\u0026#34;,\u0026#34;red\u0026#34;),pch=c(\u0026#34;-\u0026#34;,\u0026#34;-\u0026#34;)) plot(density(d1), col=\u0026#34;blue\u0026#34;,main=\u0026#34;density plot\u0026#34;) lines(density(d2), col=\u0026#34;red\u0026#34;) legend(x=\u0026#34;topright\u0026#34;,legend=c(\u0026#34;inv\u0026#34;,\u0026#34;builtin\u0026#34;),col=c(\u0026#34;blue\u0026#34;,\u0026#34;red\u0026#34;),pch=c(\u0026#34;-\u0026#34;,\u0026#34;-\u0026#34;)) Problem 4 Generating $10,000$ random variables from $\\operatorname{Geometric}(p)$ distribution based off Bernoulli trials.\nSolution A random variable $X \\sim \\operatorname{Geometric(p)}$ is given by the number of i.i.d. trials needed to have a success where success occurs with probability $p$.\nThus, we may simulate this distribution with the following R code:\n# simulate n realizes of geometric(p) rgeo \u0026lt;- function(n,p) { outcomes \u0026lt;- vector(length=n) for (i in 1:n) { trials \u0026lt;- 0 while (T) { trials \u0026lt;- trials + 1 if (rbinom(1,1,p) == 1) { break } } outcomes[i] \u0026lt;- trials } outcomes } When we use this function to draw a sample of $n=10000$ geoemtrically distributed random variables with $p=0.2$, we obtain:\np \u0026lt;- .2 n \u0026lt;- 10000 sample \u0026lt;- rgeo(n,p) cat(\u0026#34;the mean should be approximate 1/p =\u0026#34;, 1/p, \u0026#34; and we obtain a mean of \u0026#34;, mean(sample)) ## the mean should be approximate 1/p = 5 and we obtain a mean of 4.9587 Problem 5 $$ f(x) = \\frac{2}{\\sqrt{2 \\pi}} e^{-x^2/2} , x \u003e 0. $$For the candidate pdf, choose the exponential density with rate $1$. Verify that your method works via a plot of the true density, and a histogram of the generated values.\nSolution $$ \\operatorname{dhalfnormal}(x) = \\frac{2}{\\sqrt{2 \\pi}} e^{-x^2/2}, x \u003e 0. $$We model this density with the following R code:\n# density for standard half-normal dhalfnormal \u0026lt;- function(x) { 2/sqrt(2*pi)*exp(-x^2/2) } $$ c = \\max \\left\\{ \\frac{\\operatorname{dhalfnormal}(x)}{\\operatorname{dexp}(x|\\lambda=1)} | x \\in \\mathbb{R} \\right\\}, $$ which is found to be approximately $c = 1.315489247$.\nWe implement the standard half-normal sampler, $\\operatorname{rhalfnormal}$, using the acceptance-rejection sampling technique with the following R code:\n# accept-rejection sampling for standard half-normal # using exp(rate=1) rhalfnormal \u0026lt;- function(N) { c \u0026lt;- 1.315489247 xs \u0026lt;- vector(length=N) k \u0026lt;- 1 while (T) { x \u0026lt;- rexp(n=1) if (runif(n=1) \u0026lt; dhalfnormal(x)/(c*dexp(x))) { xs[k] \u0026lt;- x k \u0026lt;- k + 1 if (k == N) { break } } } xs } We simulate drawing $n=100000$ samples from the standard half-normal distribution and plotting a histogram of the sample with its density overload in red on top of it with the following R code:\nn \u0026lt;- 100000 sample \u0026lt;- rhalfnormal(n) hist(sample,freq=F,breaks=50,main=\u0026#34;standard half-normal\u0026#34;) curve(dhalfnormal(x),add=TRUE,col=\u0026#34;red\u0026#34;) We see that the histogram is compatible with being drawn from the overload density.\nProblem 6 $$ f(x) \\propto 3 e^{-0.5(x+2)^2} + 7 e^{-0.5(x-2)^2} $$ The normalizing constant is $25.066$. For your proposal $g()$, use a $N(0, 2^2)$ distribution. Verify that your method works via a plot of the true normalized density, and a histogram of the generated values.\nSolution $$ \\operatorname{ker-bimodal}(x) = 3 e^{-0.5(x+2)^2} + 7 e^{-0.5(x-2)^2}, $$$$ \\operatorname{dbimodal}(x) = \\frac{\\operatorname{ker}(x)}{C}. $$We model these two functions with the following R code:\n# density for biomodal density kerbimodal \u0026lt;- function(x) { 3*exp(-0.5*(x+2)^2) + 7*exp(-0.5*(x-2)^2) } kerbimodal.C \u0026lt;- 25.0663 dbimodal \u0026lt;- function(x) { kerbimodal(x) / kerbimodal.C } $$ c = \\max \\left\\{ \\frac{\\operatorname{ker-bimodal}(x)}{g(x|\\mu=0,\\sigma^2=2^2)} | x \\in \\mathbb{R} \\right\\}, $$ which is found to be approximately $c = 68.35212$.\nWe implement the bimodal sampler, $\\operatorname{rbimodal}$, using the acceptance-rejection sampling technique with the following R code:\n# accept-rejection sampling for bimodal distribution with density dbimodal # using normal(0,2^2). rbimodal \u0026lt;- function(N) { c \u0026lt;- 68.35212 xs \u0026lt;- vector(length=N) k \u0026lt;- 1 while (T) { x \u0026lt;- rnorm(n=1,mean=0,sd=2) if (runif(n=1) \u0026lt; kerbimodal(x)/(c*dnorm(x,mean=0,sd=2))) { xs[k] \u0026lt;- x if (k == N) { break } k \u0026lt;- k + 1 } } xs } We simulate drawing $n=100000$ samples from the bimodal distribution and plotting a histogram of the sample with its density overload in red on top of it with the following R code:\nn \u0026lt;- 100000 sample \u0026lt;- rbimodal(n) hist(sample,freq=F,breaks=50,main=\u0026#34;bimodal\u0026#34;) curve(dbimodal(x),add=TRUE,col=\u0026#34;red\u0026#34;) We see that the histogram is compatible with being drawn from the overload density.\n",
        "summary": "This problem set contains solutions to problems involving Newton\u0026rsquo;s method, the secant method, Poisson regression, and various sampling techniques.",
        "tags": null,
        "section": "probsets"
      },{
        "title": "known_plaintext_attack_time_series_analysis",
        "link": "http://localhost:1313/ghprojects/known_plaintext_attack_time_series_analysis/",
        "date": "2021-04-30 03:43:19 +0000 UTC",
        "content": "known_plaintext_attack_time_series_analysis No description available.\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nLanguages Used: TeX, C++, R\nREADME Time series analysis of a confidentiality measure for an Encrypted search system We derive a confidentiality measure against an adversary deploying a known-plaintext attack on the search agents Encrypted searches. We perform a time series analysis on a theoretical adversary in order to derive an estimator of the forecast distribution on the confidentiality measure, which may be used to inform policies such as when and how frequently a password change may be called for to maintain a minimum level of confidentiality.\nkeywords: time series analysis, known-plaintext attack, encrypted search, confidentiality measure, estimation\n",
        "summary": "\u003ch1 id=\"known_plaintext_attack_time_series_analysis\"\u003eknown_plaintext_attack_time_series_analysis\u003c/h1\u003e\n\u003cp\u003eNo description available.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/known_plaintext_attack_time_series_analysis\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: TeX, C++, R\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003ch1 id=\"time-series-analysis-of-a-confidentiality-measure-for-an-encrypted-search-system\"\u003eTime series analysis of a confidentiality measure for an Encrypted search system\u003c/h1\u003e\n\u003cp\u003eWe derive a confidentiality measure against an adversary deploying a known-plaintext attack on the search agents Encrypted searches.\nWe perform a time series analysis on a theoretical adversary in order to derive an estimator of the forecast distribution\non the confidentiality measure, which may be used to inform policies such as when and how frequently a password change may\nbe called for to maintain a minimum level of confidentiality.\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "queelius",
        "link": "http://localhost:1313/ghprojects/queelius/",
        "date": "2021-02-14 21:17:44 +0000 UTC",
        "content": "queelius Config files for my GitHub profile.\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nREADME Im Alex Towell and I can be reached at lex@metafunctor.com. I have two masters degrees from SIUE: Computer Science and Mathematics/Statistics. Im interested encrypted search and homomorphic encryption, oblivious and probabilitistic data structures and algorithms, machine learning and statistics, AI, and programming. Im looking to collaborate on papers (some partially complete). Here are some ideas, but I\u0026rsquo;m open to other opportunities: Oblivious, privacy-preserving algebraic data types for confidential computation on untrusted systems, with analysis informed by information and probability theory. The data types are algebraic in nature because I have been researching ways to compose them to facilitate building larger oblivious programs from smaller oblivious components, the essence of programming. Probabilistic algorithms and probabilistic algebraic data types primarily concerned with specifying a type of approximation error (normally due to rate distortion) which I tentatively refer to as the Bernoulli Model. Probabilistic data structures that model set-indicator functions, like the Bloom filter, are a well-known special case, but I seek to significantly generalize the results and propagate information about the approximation error through a family of monadic constructions. I have been pursuing derivations of the expected lower-bounds on the space complexity of these approximate Bernoulli types in addition to practical near-optimal data structures that model them. Related to my Computer Science thesis, I have also applied the above results to an approximate Boolean algebra for encrypted search. Reliability engineering and applying statistical inference and learning to predict likely breakdowns (and its causes) of critical systems. It concerns reliability theory and my publication titled \u0026ldquo;Estimating how confidential encrypted searches are using moving average bootstrap method\u0026rdquo; concerns reliability engineering. My master\u0026rsquo;s paper \u0026ldquo;Reliability Estimation in Series Systems: Maximum Likelihood Techniques for Right-Censored and Masked Failure Data\u0026rdquo; is also related. An information-theoretic model of an optimal adversary (provides a lower-bound on confidientiality in some cases) who, with some probability of success, compromises the confidentiality of an encrypted search system by observing a time series of inputs and outputs. Decentralized \u0026ldquo;trust machines\u0026rdquo; (technological solutions to securing trust that does not rely on central authorities), Research on oblivious, privacy-preserving computations is one of the tools in automating trust, but I\u0026rsquo;m also interested in technologies like Blockchain. ",
        "summary": "\u003ch1 id=\"queelius\"\u003equeelius\u003c/h1\u003e\n\u003cp\u003eConfig files for my GitHub profile.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/queelius\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eIm Alex Towell and I can be reached at \u003ca href=\"mailto:lex@metafunctor.com\"\u003elex@metafunctor.com\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003eI have two masters degrees from SIUE: Computer Science and Mathematics/Statistics.\u003c/li\u003e\n\u003cli\u003eIm interested encrypted search and homomorphic encryption, oblivious and probabilitistic data structures and algorithms, machine learning and statistics, AI, and programming.\u003c/li\u003e\n\u003cli\u003eIm looking to collaborate on papers (some partially complete). Here are some ideas, but I\u0026rsquo;m open to other opportunities:\n\u003cul\u003e\n\u003cli\u003eOblivious, privacy-preserving algebraic data types for confidential computation on untrusted systems, with analysis informed by information and probability theory. The data types are algebraic in nature because I have been researching ways to compose them to facilitate building larger oblivious programs from smaller oblivious components, the essence of programming.\u003c/li\u003e\n\u003cli\u003eProbabilistic algorithms and probabilistic algebraic data types primarily concerned with specifying a type of approximation error (normally due to rate distortion) which I tentatively refer to as the Bernoulli Model.\n\u003cul\u003e\n\u003cli\u003eProbabilistic data structures that model set-indicator functions, like the Bloom filter, are a well-known special case, but I seek to significantly generalize the results and propagate information about the approximation error through a family of monadic constructions.\u003c/li\u003e\n\u003cli\u003eI have been pursuing derivations of the expected lower-bounds on the space complexity of these approximate Bernoulli types in addition to practical near-optimal data structures that model them.\u003c/li\u003e\n\u003cli\u003eRelated to my Computer Science thesis, I have also applied the above results to an approximate Boolean algebra for encrypted search.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eReliability engineering and applying statistical inference and learning to predict likely breakdowns (and its causes) of critical systems.\n\u003cul\u003e\n\u003cli\u003eIt concerns reliability theory and my publication titled \u0026ldquo;Estimating how confidential encrypted searches are using moving average bootstrap method\u0026rdquo; concerns reliability engineering.\u003c/li\u003e\n\u003cli\u003eMy master\u0026rsquo;s paper \u0026ldquo;Reliability Estimation in Series Systems: Maximum Likelihood Techniques for Right-Censored and Masked Failure Data\u0026rdquo; is also related.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eAn information-theoretic model of an optimal adversary (provides a lower-bound on confidientiality in some cases) who, with some probability of success, compromises the confidentiality of an encrypted search system by observing a time series of inputs and outputs.\u003c/li\u003e\n\u003cli\u003eDecentralized \u0026ldquo;trust machines\u0026rdquo; (technological solutions to securing trust that does not rely on central authorities), Research on oblivious, privacy-preserving computations is one of the tools in automating trust, but I\u0026rsquo;m also interested in technologies like Blockchain.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c!---\nqueelius/queelius is a  special  repository because its `README.md` (this file) appears on your GitHub profile.\nYou can click the Preview link to take a look at your changes.\n---\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "homomorphic_computational_extensions",
        "link": "http://localhost:1313/ghprojects/homomorphic_computational_extensions/",
        "date": "2020-12-18 00:13:12 +0000 UTC",
        "content": "homomorphic_computational_extensions Homomorphic computational extensions\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nLanguages Used: C++\nGitHub Pages\nREADME Homomorphic computational extensions Alex Towell 3/5/2022\nWe consider homomorphisms which are based on computational concerns which are used to transform inefficient or lossy computations over some original domain T into a conceptually equivalent group T* over a restricted set of operations.\nIf the original problem can be solved using these restricted operations, then we may transform T into T* and efficiently perform the computations. Sometimes, the entire solution cannot be transformed back to T, but the restricted set of functions or operations may still be sufficient, e.g., evaluating a + c \u0026lt; b + c even though a+c or b+c may not be in the domain of T.\nSee the documentation for more.\nGiven the depth and specificity of your project, the README.md for your GitHub repository should reflect the theoretical underpinnings and overarching conceptual framework guiding the development of mathematical objects like lg\u0026lt;T\u0026gt;. Here\u0026rsquo;s a draft that captures the essence of your work, using appropriate mathematical notation and terminology to cater to an informed audience.\nConceptual Framework for Computational Homomorphisms Overview This repository explores the development and implementation of mathematical objects designed to address computational inefficiencies, precision loss, and the potential for overflow and underflow in numerical computations. Central to our approach is the application of homomorphisms from algebraic structures like rings and groups into computationally efficient domains, facilitating operations that are inherently problematic in the original computational basis.\nTheoretical Foundation Our work is rooted in the mathematical concepts of rings, groups, homomorphisms, and approximate algorithms. By leveraging these foundational principles, we aim to transform operations over some domain \\(D\\) into a conceptually equivalent group \\(G\\) over a restricted set of operations. This transformation, guided by computational homomorphisms, allows for the efficient execution of operations that are either inefficient or prone to loss in the original domain.\nComputational Homomorphisms Given a type \\(T\\) that models a ring or group with operations \\(\\oplus\\) and \\(\\otimes\\), we define a transformation into a domain \\(D'\\) where these operations can be efficiently computed through a restricted computational basis \\(B\\). This transformation not only aims to preserve the algebraic structure but also to mitigate computational issues such as overflow, underflow, and significant precision loss.\nImplementation of Homomorphic Objects Having laid the theoretical foundation, here we proceed to briefly cover a few choice imlementations of the concept. These impleentations are not exhaustive, but work well together to demonstrate the concept and its potential.\nLog Domain Implementation: lg\u0026lt;T\u0026gt; The lg\u0026lt;T\u0026gt; class maps multiplication operations into addition within the logarithmic domain, effectively addressing computational limitations in the original domain. We simply map a value to its logarithm, and then define a restricted computational basis for this value type. In particular, we allow for comparison predicates, multiplication (which is addition under the hood), division (which is subtraction under the hood), and exponentiation (which is multiplication under the hood).\nThe lg\u0026lt;T\u0026gt; class is designed to facilitate efficient computations by leveraging the properties of logarithms to transform multiplication operations into addition. This transformation not only mitigates the risk of overflow and underflow but also enables the use of efficient addition-based operations within the log domain.\nauto a = lg\u0026lt;double\u0026gt;(3); // store: log(3) auto b = lg\u0026lt;double\u0026gt;(4); // store: log(4) auto c = a * b // c = lg\u0026lt;double\u0026gt;{12} // store: log(3) + log(4) = log(12) auto d = lg\u0026lt;double\u0026gt;(100) // store: log(100) auto e = d / c // store: log(100) - log(12) = log(100/12) = log(8.33) assert(a \u0026lt; b) assert(e \u0026lt; d) If we have a lot of values to multiply, we can map them all to their logarithms and then efficiently do the equivalent computation in the log-domain. This also avoids underflows or overflows that may occur in the original domain.\nTo get at the stored logarthm, we provide a method value():\nauto x = a.value() // returns log(3) This is not normally what you want, and it may even leak the abstraction, but we provide it anyway.\nstd::cout \u0026lt;\u0026lt; a.value(); // outputs \u0026#34;exp(\u0026#34; \u0026lt;\u0026lt; a.value() \u0026lt;\u0026lt; \u0026#34;)\\n\u0026#34;; So, lg\u0026lt;T\u0026gt;(x) maps x to the log-domain. We can then map the result back to the original domain T by simply exponentiating the stored value. We provide a conversion operator to do this: operator T().\nstd::cout \u0026lt;\u0026lt; a; // outputs \u0026#34;exp(\u0026#34; \u0026lt;\u0026lt; a.value() \u0026lt;\u0026lt; \u0026#34;)\u0026#34;; std::cout \u0026lt;\u0026lt; (double)a; // outputs 3.0 We may not be able to map the value back to the original domain, although often we can because only the intermedate results of the computation may have caused an overflow or underflow in the origional domain, but the final result may not. In this case, we can simply map the final result in lg\u0026lt;T\u0026gt; back to the original domain T to retrieve the exact result.\nWe also efficiently support exponentiation and a few other operations:\nauto f = exp(a) // f = e^a, in `a` we stored log(3), in `f` we store: exp(log(3)) = 3 Notice that exponentiation may result in an overflow or underflow in the transformed log-domain. For instance, if we have stored the result of a very large number that doesn\u0026rsquo;t fit into the origional domain but it does fit in the log domain, then exponentiating it may result undoes the transformation, resulting in an overflow or underflow again. This is fine \u0026ndash; lg\u0026lt;T\u0026gt; is designed to make multiplication and division efficient, and it does so without causing overflows or underflows, but it does not guarantee that exponentiation will not cause overflows or underflows.\nWe can also not efficiently support addition or subtraction in the log-domain:\nauto g = a + b Howe do we implement this? Conceptually, we can do the following:\nTake the exponetial of the values stored in a andn b:\nexp(log(3)) * exp(log(4)) = 3 * 4 = 12\nStore the result: lg\u0026lt;double\u0026gt;(12)\nHowever, both step 1 and step 2 can result in overflows or underflows. We can detect whether it will result in an overflow or underflow prior to doing the operation, so we see that addition and subtraction are partial functions in the log-domain. We can still define them, but they may not be defined for all inputs. More importantly, even if we can do the operation without an overflow or underflow, it is not a very efficient operation. Thus, we have chosen to restrict the computational basis of lg\u0026lt;T\u0026gt; to only support multiplication, division, predicates,\nWe also support logarithms and exponentiation:\nauto h = log(a) // we already store log(3) in `a`, so we store: // log(log(3)) or log((double)a) auto i = exp(a) // we already store log(3) in `a`, so we store: // exp(log(3)) = (double)a. Exponential Domain Implementation: exp\u0026lt;T\u0026gt; Previously, in lg\u0026lt;T\u0026gt;, we mapped x to log(x) and then defined multiplication in terms of lg\u0026lt;T\u0026gt; as addition in the log-domain. We can also map x to exp(x) and then define addition in terms of expo\u0026lt;T\u0026gt; as multiplication in the exp-domain:\nauto a = expo\u0026lt;double\u0026gt;(3); // store: exp(3) auto b = expo\u0026lt;double\u0026gt;(4); // store: exp(4) auto c = a + b // c = expo\u0026lt;double\u0026gt;{12} // store: exp(3) * exp(4) Log-Exp-Sum If we have lg\u0026lt;T\u0026gt; and exp\u0026lt;T\u0026gt;, then we can define log_exp_sum\u0026lt;T\u0026gt; which is a type that\nApproximate Algorithms Here, we also see an opportunity to explore the development of approximate algorithms that can model computations outside of its restricted computational basis \\(B\\). It can do so without converting back to the original domain \\(D\\), but often with some loss of precision or efficiency.\nIn the log-exp-sum basis, we can do so-called softmax or softmin operations, which approximate the maximum or minimum of a set of numbers, respectively. These operations are useful in machine learning and optimization algorithms, and can be computed efficiently in the log-exp-sum basis.\nWe can wrap the output of such an approximate algorithm in a type that can support estimating the error of the approximation, and can be converted back to the original domain \\(D\\). Different kinds of opoerations may thus be performed on the result of this approximate algorithm, such as comparing it to another value, or adding it to another value, while propagating and updating the error estimates, e.g., a \u0026lt; b where either a or b is the result of the softmax operation. In this case, since softmax result provides an upper bound on the maximum of the set of numbers, we know that if a is a softmax result (and the true value of the operation is latent) and b is exact, then if a \u0026lt; b is true, then we know that the latent value of the softmax result is less than b, and so it should return true with probability of being incorrect 0 and false with probability of being incorrect that is a funtion of the error estimate of a. If both a and b are softmax results, then both softmax values represent latent values and the error estimate becomes more complicated, but can still be estimated.\nWe formalize the value of the operation a \u0026lt; b with the error estimate as a type bernoulli\u0026lt;bool\u0026gt; which we formalize elsewhere in anohher C++ library, bernoulli_data_types. See the documentation for more.\nFuture Directions Our ongoing work will focus on expanding the library of mathematical objects and exploring their applications across various computational domains. We are particularly interested in the potential for these objects to enhance computational efficiency, precision, and robustness in fields ranging from numerical analysis to artificial intelligence.\nContributions We welcome contributions from researchers and practitioners interested in advancing the state of computational mathematics through the exploration of homomorphic transformations and their applications. Whether through theoretical insights, new mathematical objects, or practical implementations, your contributions can help shape the future of computational efficiency and precision.\n",
        "summary": "\u003ch1 id=\"homomorphic_computational_extensions\"\u003ehomomorphic_computational_extensions\u003c/h1\u003e\n\u003cp\u003eHomomorphic computational extensions\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/homomorphic_computational_extensions\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: C++\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://queelius.github.io/homomorphic_computational_extensions/\"\u003eGitHub Pages\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003ch1 id=\"homomorphic-computational-extensions\"\u003eHomomorphic computational extensions\u003c/h1\u003e\n\u003cp\u003eAlex Towell\n3/5/2022\u003c/p\u003e\n\u003cp\u003eWe consider homomorphisms which are based on computational concerns which are used to\ntransform inefficient or lossy computations over some original domain \u003ccode\u003eT\u003c/code\u003e into a\nconceptually equivalent group \u003ccode\u003eT*\u003c/code\u003e over a restricted set of operations.\u003c/p\u003e\n\u003cp\u003eIf the original problem can be solved using these restricted operations, then we may\ntransform \u003ccode\u003eT\u003c/code\u003e into \u003ccode\u003eT*\u003c/code\u003e and efficiently perform the computations.\nSometimes, the entire solution cannot be transformed back to \u003ccode\u003eT\u003c/code\u003e, but the restricted\nset of functions or operations may still be sufficient, e.g., evaluating\n\u003ccode\u003ea + c \u0026lt; b + c\u003c/code\u003e even though \u003ccode\u003ea+c\u003c/code\u003e or \u003ccode\u003eb+c\u003c/code\u003e may not be in the domain of \u003ccode\u003eT\u003c/code\u003e.\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "algebraic_cipher_types",
        "link": "http://localhost:1313/ghprojects/algebraic_cipher_types/",
        "date": "2019-12-21 17:56:50 +0000 UTC",
        "content": "algebraic_cipher_types Algebraic cipher types\nGitHub Link\nStars: 1 | Forks: 0 | Open Issues: 0\nLanguages Used: C++, CMake, Python, Makefile\nREADME algebraic_cipher_types_code Algebraic cipher types\n",
        "summary": "\u003ch1 id=\"algebraic_cipher_types\"\u003ealgebraic_cipher_types\u003c/h1\u003e\n\u003cp\u003eAlgebraic cipher types\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/algebraic_cipher_types\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 1 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: C++, CMake, Python, Makefile\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003ch1 id=\"algebraic_cipher_types_code\"\u003ealgebraic_cipher_types_code\u003c/h1\u003e\n\u003cp\u003eAlgebraic cipher types\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "encrypted_search_probabilistic_estimator_conf",
        "link": "http://localhost:1313/ghprojects/encrypted_search_probabilistic_estimator_conf/",
        "date": "2019-01-15 18:39:47 +0000 UTC",
        "content": "encrypted_search_probabilistic_estimator_conf Encrypted Search: A Probabilistic Estimator of Confiidentiality\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nLanguages Used: HTML, TeX, C++, CSS, JavaScript, Roff\nGitHub Pages\nREADME Encrypted Search: A Probabilistic Estimator of Confidentiality This repository contains research on measuring the confidentiality of encrypted search systems against an adversary that observes hidden queries to infer plaintext queries.\nThis paper is written in Bookdown and provides output options for PDF (pdfbook) and HTML (gitbook).\nAbstract We propose a confidentiality measure for plaintext queries against an adversary that observes corresponding hidden queries. An adversary employs a plaintext attack to infer a mapping from hidden to plaintext queries. We apply the estimator to an encrypted search system that maintains a minimum confidentiality level. A bootstrap method estimates the sampling distribution of confidentiality over query histories. This provides a probabilistic assessment of confidentiality, like the chance that an adversary infers over 70% of queries. We also propose mapping entropy to a lower bound on confidentiality.\nContents pdfbook/paper.pdf: PDF version of the full paper gitbook/index.html: HTML version of the full paper docs/: Copy of gitbook directory, for GitHub Page hosting at: \u0026hellip; src/: C++ simulation of Zipf study. data/: Experimental results on confidentiality (Zipf simulation) ",
        "summary": "\u003ch1 id=\"encrypted_search_probabilistic_estimator_conf\"\u003eencrypted_search_probabilistic_estimator_conf\u003c/h1\u003e\n\u003cp\u003eEncrypted Search: A Probabilistic Estimator of Confiidentiality\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/encrypted_search_probabilistic_estimator_conf\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: HTML, TeX, C++, CSS, JavaScript, Roff\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://queelius.github.io/encrypted_search_probabilistic_estimator_conf/\"\u003eGitHub Pages\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003ch2 id=\"encrypted-search-a-probabilistic-estimator-of-confidentiality\"\u003eEncrypted Search: A Probabilistic Estimator of Confidentiality\u003c/h2\u003e\n\u003cp\u003eThis repository contains research on measuring the confidentiality of encrypted\nsearch systems against an adversary that observes hidden queries to infer plaintext queries.\u003c/p\u003e\n\u003cp\u003eThis paper is written in Bookdown and provides output options for PDF (pdfbook)\nand HTML (gitbook).\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "cipher_maps",
        "link": "http://localhost:1313/ghprojects/cipher_maps/",
        "date": "2019-01-14 16:34:53 +0000 UTC",
        "content": "cipher_maps No description available.\nGitHub Link\nStars: 0 | Forks: 0 | Open Issues: 0\nLanguages Used: TeX\nREADME Universal function Bernoulli approximators Oblivious maps A set is an unordered collection of distinct elements, typically from some implicitly understood universe. A countable set is a finite set or a countably infinite set. A finite set has a finite number of elements, such as , and a countably infinite set can be put in one-to-one correspondence with the set of natural numbers, . The cardinality of a set , denoted by , is a measure on the number of elements in the set, e.g., .\nA map represents a many-to-one relationship. A map that associates elements in to elements in has a type denoted by . For a map of type , we denote the input and the output. Typically, it is relatively easy to find which output is associated with a given input, but the inverse operation, determining which inputs are associated with a given output is computationally harder. Of course, this is not necessarily the case, and mathematically the map is just a one-to-many relation over .\nFor instance, Table depicts a function over a finite domain of elements, where each input is associated with a single output , i.e., .\nThe input does not need to be a simple set like natural numbers, but rather can be any type of set, such as a set of pairs as given in .\nSince we are interested in constructing maps in computer memory, we must have some way to represent them. One technique may be given by the following table.\nThe oblivious map is given by the following definition. \\begin{definition} The oblivious Bernoulli map is a specialization of the Bernoulli map. We denote an oblivious map of by where is the subset of the computational basis of which provides. An oblivious Bernoulli map satisifes the following conditions:\nThe function is a Bernoulli map of .\nIf an element of is not in the domain of definition, is a random oracle over A particular mapping may only be learned by applying to .\nIn an oblivious map, a mapping (row in the table) is only learned upon request.\nObserve that is an oblivious value. Typically, we are also interested in functions in which the domain and codomain also represent oblivious values, i.e.,\nwhere , , and .\nIt may be the case that is a set of oblivious integers that, say, only supports testing equality and addition. Of course, once we have addition, we may also implement multiplication, powers, and many other operations.\nBy , the space complexity of the Bernoulli map with an error rate is given by the following theorem.\nAbstract data type A type is a set and the elements of the set are called the values of the type. An abstract data type is a type and a set of operations on values of the type. For example, the integer abstract data type is the set of all integers and a set of standard operations (computational basis) such as addition, subtraction, and multiplication.\nA data structure is a particular way of organizing data and may implement one or more abstract data types. An immutable data structure has static state; once constructed, its state does not change until it is destroyed. Let model the concept of a Bernoulli approximation of . Then,\nReturns a value in .\n.\nReturns the error rate of applied to , i.e.,\nfor every .\n",
        "summary": "\u003ch1 id=\"cipher_maps\"\u003ecipher_maps\u003c/h1\u003e\n\u003cp\u003eNo description available.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/cipher_maps\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 0 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: TeX\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003ch1 id=\"universal-function-bernoulli-approximators\"\u003eUniversal function Bernoulli approximators\u003c/h1\u003e\n\u003ch1 id=\"oblivious-maps\"\u003eOblivious maps\u003c/h1\u003e\n\u003cp\u003eA set is an unordered collection of distinct elements, typically from\nsome implicitly understood universe. A countable set is a \u003cem\u003efinite set\u003c/em\u003e\nor a \u003cem\u003ecountably infinite set\u003c/em\u003e. A \u003cem\u003efinite set\u003c/em\u003e has a finite number of\nelements, such as\n\u003cimg src=\"https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D\u0026amp;space;%5Cbg_white\u0026amp;space;%5C%7B%201%2C%203%2C%205%20%5C%7D\" alt=\"\\{ 1, 3, 5 \\}\" title=\"{ 1, 3, 5 }\"\u003e,\nand a \u003cem\u003ecountably infinite set\u003c/em\u003e can be put in one-to-one correspondence\nwith the set of natural numbers,\n\u003cimg src=\"https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D\u0026amp;space;%5Cbg_white\u0026amp;space;%5C%7B1%2C2%2C3%2C4%2C5%2C%5Cldots%5C%7D\" alt=\"\\{1,2,3,4,5,\\ldots\\}\" title=\"{1,2,3,4,5,\\ldots}\"\u003e.\nThe cardinality of a set\n\u003cimg src=\"https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D\u0026amp;space;%5Cbg_white\u0026amp;space;%5Cmathbb%7BA%7D\" alt=\"\\mathbb{A}\" title=\"\\mathbb{A}\"\u003e,\ndenoted by\n\u003cimg src=\"https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D\u0026amp;space;%5Cbg_white\u0026amp;space;%7C%5Cmathbb%7BA%7D%7C\" alt=\"|\\mathbb{A}|\" title=\"|\\mathbb{A}|\"\u003e,\nis a measure on the number of elements in the set, e.g.,\n\u003cimg src=\"https://latex.codecogs.com/png.image?%5Cdpi%7B110%7D\u0026amp;space;%5Cbg_white\u0026amp;space;%7C%5C%7Ba%2Cb%5C%7D%7C%3D2\" alt=\"|\\{a,b\\}|=2\" title=\"|{a,b}|=2\"\u003e.\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "rd_ph_filter",
        "link": "http://localhost:1313/ghprojects/rd_ph_filter/",
        "date": "2019-01-14 12:52:04 +0000 UTC",
        "content": "rd_ph_filter No description available.\nGitHub Link\nStars: 1 | Forks: 0 | Open Issues: 0\nNo README available for this project.\n",
        "summary": "\u003ch1 id=\"rd_ph_filter\"\u003erd_ph_filter\u003c/h1\u003e\n\u003cp\u003eNo description available.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/rd_ph_filter\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 1 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cem\u003eNo README available for this project.\u003c/em\u003e\u003c/p\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "cipher_trapdoor_sets",
        "link": "http://localhost:1313/ghprojects/cipher_trapdoor_sets/",
        "date": "2019-01-14 12:49:37 +0000 UTC",
        "content": "cipher_trapdoor_sets No description available.\nGitHub Link\nStars: 1 | Forks: 0 | Open Issues: 0\nLanguages Used: Jupyter Notebook, TeX, Mathematica, C++\nREADME Cipher sets over trapdoors ",
        "summary": "\u003ch1 id=\"cipher_trapdoor_sets\"\u003ecipher_trapdoor_sets\u003c/h1\u003e\n\u003cp\u003eNo description available.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/cipher_trapdoor_sets\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 1 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: Jupyter Notebook, TeX, Mathematica, C++\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003ch1 id=\"cipher-sets-over-trapdoors\"\u003eCipher sets over trapdoors\u003c/h1\u003e",
        "tags": ["GitHub","project"],
        "section": "ghprojects"
      },{
        "title": "bernoulli_data_type",
        "link": "http://localhost:1313/ghprojects/bernoulli_data_type/",
        "date": "2019-01-14 09:29:11 +0000 UTC",
        "content": "bernoulli_data_type Bernoulli data type\nGitHub Link\nStars: 2 | Forks: 0 | Open Issues: 0\nLanguages Used: Mathematica, TeX, Jupyter Notebook, C++, HTML, JavaScript, CSS, Gnuplot, Shell, Makefile, R\nGitHub Pages\nREADME This is a repo that I will use to develop my Bernoulli data type concept, which is a general framework for understanding and constructing a lot of interesting new data types and compuational trade-offs. It can also be used as a foundation for constructing oblivious programs as a composition of oblivious data types / obvious functions.\nI doubt any of it will compile \u0026ndash; I actually hadn\u0026rsquo;t looked at this in years, while I battled sickness and cancer, but now that I\u0026rsquo;m feeling better, I\u0026rsquo;m revisting some old projects. Look at my repo for other things I\u0026rsquo;m working on, and https://metafunctor.com for my personal web site.\nHere are some markdown files in the repo. I\u0026rsquo;ve throw it all into Doxygen, but I haven\u0026rsquo;t had time to make it work properly yet. Here are the files:\nBernoulli Map for info on the most generic type, which can be used to in theory model any computable function. We also show how even traditional algorithms, like the Miller-Rabin primality test, can be understood in th framework of the Bernoulli model. The random approximate values over algebraic types I\u0026rsquo;m not sure if this is correct. The markdown files I have should be more up to date and more correct, so stick with this for grokking the concept. This PDF is more for historical purposes, and to show how I was thinking about it at the time. Bernoulli Bool for an example of the simplest Bernoulli type, useful for understanding. Bernoulli Set for information on the most common kind of Bernoulli data type. The Bloom filtr is a special case. Here are some PDF files related to this: Bernoulli sets: a model for modeling sets with random errors and corresponding random binary classification measures. A lot of the material in this section is obsolete, but there is still a lot of good information here. An algebra of random approximate sets with derivations of higher-order random approximate sets induced by set-theoretic operations on random approximate sets with corresponding random binary classification measures. Again, a lot of obsolete content. Much of this comes prior to my generalization of the result for Bernoulli types, and before I had a proper appreciation for the correct definition. However, as a separate result, if we ignore some of the details, it has a lot of interesting information. Codec for more information codecs. I will eventually use this to describe how to automatically generate any Bernoulli map, including Cipher maps (Oblivious data type). The idea will be to use the universal Bernoulli map constructor Regular Type for more information about regular types, and how the Bernoulli model fails this basic requirement in many ways. It\u0026rsquo;s not intended as a criticism, because in some ways it\u0026rsquo;s desirable (say in the oblivious type use-case), only to explain why some predicates like equality are not necessarily accurate (equality itself return a Bernoulli Boolean). See the API Documentation for more details, but there isn\u0026rsquo;t much there yet. I\u0026rsquo;ll be working on the code + doxygen comments soon.\n",
        "summary": "\u003ch1 id=\"bernoulli_data_type\"\u003ebernoulli_data_type\u003c/h1\u003e\n\u003cp\u003eBernoulli data type\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/queelius/bernoulli_data_type\"\u003eGitHub Link\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eStars\u003c/strong\u003e: 2 | \u003cstrong\u003eForks\u003c/strong\u003e: 0 | \u003cstrong\u003eOpen Issues\u003c/strong\u003e: 0\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eLanguages Used\u003c/strong\u003e: Mathematica, TeX, Jupyter Notebook, C++, HTML, JavaScript, CSS, Gnuplot, Shell, Makefile, R\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://queelius.github.io/bernoulli_data_type/\"\u003eGitHub Pages\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"readme\"\u003eREADME\u003c/h2\u003e\n\u003cp\u003eThis is a repo that I will use to develop my Bernoulli data type concept, which is a general framework for understanding and constructing\na lot of interesting new data types and compuational trade-offs. It can also be used as a foundation for constructing oblivious programs\nas a composition of oblivious data types / obvious functions.\u003c/p\u003e",
        "tags": ["GitHub","project","GitHub Project"],
        "section": "ghprojects"
      },{
        "title": "github-project",
        "link": "http://localhost:1313/tags/github-project/",
        "date": "2019-01-14 09:29:11 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "confidentiality",
        "link": "http://localhost:1313/tags/confidentiality/",
        "date": "2017-01-01 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "encrypted-search",
        "link": "http://localhost:1313/tags/encrypted-search/",
        "date": "2017-01-01 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "estimating-how-confidential-encrypted-searches-are-using-moving-average-bootstrap-method",
        "link": "http://localhost:1313/publications/mab/",
        "date": "2017-01-01 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": ["encrypted search","bootstrap","moving average","frequency attack","security","confidentiality"],
        "section": "publications"
      },{
        "title": "frequency-attack",
        "link": "http://localhost:1313/tags/frequency-attack/",
        "date": "2017-01-01 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "moving-average",
        "link": "http://localhost:1313/tags/moving-average/",
        "date": "2017-01-01 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "security",
        "link": "http://localhost:1313/tags/security/",
        "date": "2017-01-01 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "encrypted-search-enabling-standard-information-retrieval-techniques-for-several-new-secure-index-types-while-preserving-confidentiality-against-an-adversary-with-access-to-query-histories-and-secure-index-contents",
        "link": "http://localhost:1313/publications/cs-thesis/",
        "date": "2015-05-01 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": ["Encrypted search","Secure index","Information retrieval","Confidentiality","Thesis","SIUe"],
        "section": "publications"
      },{
        "title": "secure-index",
        "link": "http://localhost:1313/tags/secure-index/",
        "date": "2015-05-01 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "thesis",
        "link": "http://localhost:1313/tags/thesis/",
        "date": "2015-05-01 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "tags"
      },{
        "title": "about-me",
        "link": "http://localhost:1313/about/",
        "date": "0001-01-01 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "about"
      },{
        "title": "essays",
        "link": "http://localhost:1313/essays/",
        "date": "0001-01-01 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": ""
      },{
        "title": "search",
        "link": "http://localhost:1313/search/",
        "date": "0001-01-01 00:00:00 +0000 UTC",
        "content": "",
        "summary": "",
        "tags": null,
        "section": "search"
      }]
  