<!DOCTYPE html>
<html lang="en-us" dir="ltr">
  <head><script src="/metafunctor/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=metafunctor/livereload" data-no-instant defer></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <script src="https://unpkg.com/lunr/lunr.js"></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>ngram-projections | metafunctor</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="ngram-projections
GitHub Link
Stars: 0 | Forks: 0 | Open Issues: 0
Languages Used: Python, Jupyter Notebook
README
Autoregressive Models: Inductive Biases and Projections
This paper investigates how inductive biases, particularly projections onto training data, can be utilized in autoregressive (AR) models to improve out-of-distribution (OOD) generalization.
Our approach consists of the following steps:


Infini-gram Model Exploration: We begin by considering the infinite-gram model, which uses suffix arrays to efficiently handle arbitrary input (context) lengths. Infinite-gram models are noteworthy due to their ability to scale to any Markov order. For reference, see the paper Infini-gram: An Engine for n-gram / ∞-gram Language Modeling with Trillion-Token Corpora by Jiacheng Liu et al. (https://huggingface.co/papers/2401.17377). A brute-force approach could involve storing the training data as-is and searching for the longest matching suffix in the input sequence.">
    <meta name="generator" content="Hugo 0.145.0">
    
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    
      <meta name="author" content = "Alex Towell">
    

    
<link rel="stylesheet" href="/metafunctor/ananke/css/main.min.css" >



  
    <link rel="stylesheet" href="/metafunctor/css/custom.css">
  


    


    
      <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
<script>
  MathJax = {
    tex: {
      displayMath: [['\\[', '\\]'], ['$$', '$$']],  
      inlineMath: [['\\(', '\\)'], ['$', '$']]      
    }
  };
</script>
        
    
    
      

    

    

    
      <link rel="canonical" href="http://localhost:1313/metafunctor/ghprojects/ngram-projections/">
    

    <meta property="og:url" content="http://localhost:1313/metafunctor/ghprojects/ngram-projections/">
  <meta property="og:site_name" content="metafunctor">
  <meta property="og:title" content="ngram-projections">
  <meta property="og:description" content="ngram-projections GitHub Link Stars: 0 | Forks: 0 | Open Issues: 0 Languages Used: Python, Jupyter Notebook
README Autoregressive Models: Inductive Biases and Projections This paper investigates how inductive biases, particularly projections onto training data, can be utilized in autoregressive (AR) models to improve out-of-distribution (OOD) generalization.
Our approach consists of the following steps:
Infini-gram Model Exploration: We begin by considering the infinite-gram model, which uses suffix arrays to efficiently handle arbitrary input (context) lengths. Infinite-gram models are noteworthy due to their ability to scale to any Markov order. For reference, see the paper Infini-gram: An Engine for n-gram / ∞-gram Language Modeling with Trillion-Token Corpora by Jiacheng Liu et al. (https://huggingface.co/papers/2401.17377). A brute-force approach could involve storing the training data as-is and searching for the longest matching suffix in the input sequence.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="ghprojects">
    <meta property="article:published_time" content="2024-06-21T11:50:22+00:00">
    <meta property="article:modified_time" content="2024-06-21T11:50:22+00:00">
    <meta property="article:tag" content="GitHub">
    <meta property="article:tag" content="Project">

  <meta itemprop="name" content="ngram-projections">
  <meta itemprop="description" content="ngram-projections GitHub Link Stars: 0 | Forks: 0 | Open Issues: 0 Languages Used: Python, Jupyter Notebook
README Autoregressive Models: Inductive Biases and Projections This paper investigates how inductive biases, particularly projections onto training data, can be utilized in autoregressive (AR) models to improve out-of-distribution (OOD) generalization.
Our approach consists of the following steps:
Infini-gram Model Exploration: We begin by considering the infinite-gram model, which uses suffix arrays to efficiently handle arbitrary input (context) lengths. Infinite-gram models are noteworthy due to their ability to scale to any Markov order. For reference, see the paper Infini-gram: An Engine for n-gram / ∞-gram Language Modeling with Trillion-Token Corpora by Jiacheng Liu et al. (https://huggingface.co/papers/2401.17377). A brute-force approach could involve storing the training data as-is and searching for the longest matching suffix in the input sequence.">
  <meta itemprop="datePublished" content="2024-06-21T11:50:22+00:00">
  <meta itemprop="dateModified" content="2024-06-21T11:50:22+00:00">
  <meta itemprop="wordCount" content="366">
  <meta itemprop="keywords" content="GitHub,Project">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="ngram-projections">
  <meta name="twitter:description" content="ngram-projections GitHub Link Stars: 0 | Forks: 0 | Open Issues: 0 Languages Used: Python, Jupyter Notebook
README Autoregressive Models: Inductive Biases and Projections This paper investigates how inductive biases, particularly projections onto training data, can be utilized in autoregressive (AR) models to improve out-of-distribution (OOD) generalization.
Our approach consists of the following steps:
Infini-gram Model Exploration: We begin by considering the infinite-gram model, which uses suffix arrays to efficiently handle arbitrary input (context) lengths. Infinite-gram models are noteworthy due to their ability to scale to any Markov order. For reference, see the paper Infini-gram: An Engine for n-gram / ∞-gram Language Modeling with Trillion-Token Corpora by Jiacheng Liu et al. (https://huggingface.co/papers/2401.17377). A brute-force approach could involve storing the training data as-is and searching for the longest matching suffix in the input sequence.">

	
  </head>

  <body class="ma0 avenir bg-near-white">

    <header id="site-header" style="padding: 0.5rem 1rem; background: #fff; border-bottom: 1px solid #eaeaea;">
    <div style="max-width: 1200px; margin: 0 auto; display: flex; align-items: center; justify-content: space-between;">
      <h1 style="font-size: 1.5rem; margin: 0;">metafunctor</h1>
      
        <span style="color: #666; font-size: 0.9rem;">by Alex Towell</span>
      
    </div>
  </header>
  
    <main class="pb7" role="main">
      
<section class="project-section" style="padding: 2rem; background-color: #f9f9f9;">
  <div class="container" style="max-width: 1200px; margin: 0 auto;">
    
    <div style="display: grid; grid-template-columns: 2fr 1fr; gap: 2rem;">
      
      
      <div>
        
        <header style="margin-bottom: 2rem;">
          <h1 style="font-size: 2.5rem; font-weight: 700; color: #333;">ngram-projections</h1>
          <p style="color: #555; font-size: 1.1rem; margin-bottom: 0.5rem;">
             | June 21, 2024 | <a href="mailto:" style="color: #007acc;"></a>
          </p>

          
          <div style="overflow: hidden;">
            
            <p style="font-size: 1.25rem; color: #666;"></p>
          </div>
        </header>

        
        
        <section style="margin-bottom: 1rem;">
          <div style="display: flex; gap: 1rem; flex-wrap: wrap;">
            
            <a href="https://github.com/queelius/ngram-projections" target="_blank" style="padding: 0.75rem 1.5rem; background-color: #007acc; color: white; border-radius: 5px; text-decoration: none; transition: background-color 0.3s ease; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
              GitHub
            </a>
            
            
            <a href="https://twitter.com/intent/tweet?text=ngram-projections&url=http%3a%2f%2flocalhost%3a1313%2fmetafunctor%2fghprojects%2fngram-projections%2f" target="_blank" style="padding: 0.75rem .75rem; background-color: #1DA1F2; color: white; border-radius: 5px; text-decoration: none; transition: background-color 0.3s ease;">
              <i class="fab fa-twitter"></i>
            </a>

            
            <a href="https://www.linkedin.com/sharing/share-offsite/?url=http%3a%2f%2flocalhost%3a1313%2fmetafunctor%2fghprojects%2fngram-projections%2f" target="_blank" style="padding: 0.75rem .75rem; background-color: #0077B5; color: white; border-radius: 5px; text-decoration: none; transition: background-color 0.3s ease;">
              <i class="fab fa-linkedin"></i>
            </a>

            
            <a href="https://www.facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fmetafunctor%2fghprojects%2fngram-projections%2f" target="_blank" style="padding: 0.75rem .75rem; background-color: #1877F2; color: white; border-radius: 5px; text-decoration: none; transition: background-color 0.3s ease;">
              <i class="fab fa-facebook"></i>
            </a>
          </div>
        </section>
        

        
        <section style="margin-bottom: 3rem;">
          <h2 style="font-size: 1.75rem; font-weight: 600; color: #007acc;">Project Description</h2>
          <p style="font-size: 1.1rem; color: #555; line-height: 1.8;">
            <h1 id="ngram-projections">ngram-projections</h1>
<p><a href="https://github.com/queelius/ngram-projections">GitHub Link</a>
<strong>Stars</strong>: 0 | <strong>Forks</strong>: 0 | <strong>Open Issues</strong>: 0
<strong>Languages Used</strong>: Python, Jupyter Notebook</p>
<h2 id="readme">README</h2>
<h1 id="autoregressive-models-inductive-biases-and-projections">Autoregressive Models: Inductive Biases and Projections</h1>
<p>This paper investigates how inductive biases, particularly projections onto training data, can be utilized in autoregressive (AR) models to improve out-of-distribution (OOD) generalization.</p>
<p>Our approach consists of the following steps:</p>
<ol>
<li>
<p><strong>Infini-gram Model Exploration</strong>: We begin by considering the infinite-gram model, which uses suffix arrays to efficiently handle arbitrary input (context) lengths. Infinite-gram models are noteworthy due to their ability to scale to any Markov order. For reference, see the paper <em>Infini-gram: An Engine for n-gram / ∞-gram Language Modeling with Trillion-Token Corpora</em> by Jiacheng Liu et al. (<a href="https://huggingface.co/papers/2401.17377)">https://huggingface.co/papers/2401.17377)</a>. A brute-force approach could involve storing the training data as-is and searching for the longest matching suffix in the input sequence.</p>
</li>
<li>
<p><strong>Projection-Based Inductive Biases</strong>: We explore a subset of inductive biases where inputs are projected onto the training data. Additionally, we consider mapping output tokens from the training data back onto the context to maintain coherence. For example, if the input is &ldquo;the king demanded&rdquo; and &ldquo;king&rdquo; is substituted with &ldquo;dictator,&rdquo; we could implement a token mapping to revert &ldquo;dictator&rdquo; to &ldquo;king&rdquo; in subsequent outputs. However, this approach introduces potential challenges in maintaining consistency.</p>
</li>
<li>
<p><strong>Exploring Variations and Extensions</strong>: In the default implementation, the model finds the longest matching suffix, exhibiting a recency bias. However, there are many possible variations to consider. Given the rich history of n-gram models, revisiting these concepts in the context of Infini-gram models and modern LLMs is worthwhile. While we do not expect to match the OOD generalization capabilities of models like GPT, we anticipate developing more sophisticated projection functions that surpass the simple longest-suffix matching approach.</p>
</li>
</ol>
<p>By framing OOD generalization as a projection problem, we propose strategies to optimize these projections using machine learning techniques. Additionally, we explore the integration of classical information retrieval methods and pre-trained language model embeddings to improve the semantic relevance of these projections.</p>
<p>We are also developing code for a Python library to experiment with various inductive biases. This library will enable running these simpler models alongside more powerful neural generative models like GPTs, where these models &ldquo;learn&rdquo; by simply accumulating more training data.</p>

          </p>
        </section>
      </div>

    
    


      
      <aside>
        
        
        
        <section style="margin-bottom: 1rem;">
          <h2 style="font-size: 1.5rem;">Related</h2>
          <div style="display: flex; flex-direction: column; gap: 1rem;">
            
            <a href="http://localhost:1313/metafunctor/projects/ngram-projections/">ngram-projections</a>
            
            <a href="http://localhost:1313/metafunctor/ghprojects/treeprog/">treeprog</a>
            
            <a href="http://localhost:1313/metafunctor/projects/treeprog/">treeprog</a>
            
            <a href="http://localhost:1313/metafunctor/projects/random_oracles/">random_oracles</a>
            
            <a href="http://localhost:1313/metafunctor/ghprojects/random_oracles/">random_oracles</a>
            
          </div>
        </section>
        

        
        
        <section style="margin-bottom: 1rem;">
          <h2 style="font-size: 1.5rem">Tags</h2>
          <div style="display: flex; gap: 0.5rem; flex-wrap: wrap;">
            
            <a href="/tags/github" style="display: inline-block; padding: 0.5rem 1rem; background-color: #f0f0f0; border-radius: 20px; font-size: 1rem; text-decoration: none; color: #007acc; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);">
              GitHub
            </a>
            
            <a href="/tags/project" style="display: inline-block; padding: 0.5rem 1rem; background-color: #f0f0f0; border-radius: 20px; font-size: 1rem; text-decoration: none; color: #007acc; box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);">
              project
            </a>
            
          </div>
        </section>
        
      </aside>

    </div>
  </div>

</section>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white white-70 dn dib-ns pv2 ph3 no-underline" href="http://localhost:1313/metafunctor/" >
    &copy;  metafunctor 2025 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

  </body>
</html>
